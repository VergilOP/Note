{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks \n",
    "In this exercise, we are going to use neural networks for a classification problem with two classes. Since there are only two classes, we do not need to use the softmax function on the neural network output. \n",
    "We are going to use the functionalities of `sklearn` and compare the output to our own implementation of a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noisy_circles = datasets.make_circles(n_samples=1000, factor=.5,\n",
    "                                      noise=.05, random_state=1)\n",
    "X = np.array(noisy_circles[0])\n",
    "y = noisy_circles[1]\n",
    "\n",
    "plt.scatter(X[y==1][:,0],X[y==1][:,1], color='b')\n",
    "plt.scatter(X[y==0][:,0],X[y==0][:,1], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f86b76566e804937b7073984cd0c6dcd",
     "grade": false,
     "grade_id": "cell-327b3b2936ff0a13",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**Task 1**\n",
    "\n",
    "Use a neural network to train a classifier given the above training data! You might want to read the description of the options of `MLPClassifier`. What we want is the neural network we discussed in the lecture, i.e. a neural network with one hidden layer using the sigmoid function as activation function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(\n",
    "    # probably needs some options...\n",
    "    # other values might work as well\n",
    "    random_state=1,\n",
    "    hidden_layer_sizes=(10,),\n",
    "    max_iter=200,\n",
    "    activation='logistic',\n",
    "    learning_rate_init=0.05\n",
    ")\n",
    "classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code to plot the decision boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def regions(X, y, classifier,colors,resolution=0.02, savename=None):\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    x2_min, x2_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                            np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.1, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    positive = X[y==1]\n",
    "    negative = X[y==0]\n",
    "    \n",
    "    xb,yb=positive[:,0],positive[:,1]\n",
    "    xm,ym=negative[:,0],negative[:,1]\n",
    "    plt.scatter(xb,yb,color=colors[1],alpha=0.4)\n",
    "    plt.scatter(xm,ym,color=colors[0],alpha=0.4)\n",
    "    if savename:\n",
    "        plt.savefig(savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions(X, y, classifier,['r','b'],resolution=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network implementation\n",
    "\n",
    "Here we will implement our own neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1.0+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the forward pass step for a neural network. The arguments are the input activations from the previous layer `inp`, a `nd x ni` matrix of `ni` activation values for each `nd` data samples in the training set. The weights `w` is a `no x (ni+1)` matrix for the coefficients of the linear combination, including the bias as the 0-th entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(inp,w):\n",
    "    nd, nf = inp.shape\n",
    "    Xaug = np.empty( (nd, nf+1))\n",
    "    Xaug[:,1:] = inp\n",
    "    Xaug[:,0] = np.ones(nd)\n",
    "    z = np.dot(Xaug,w.T)\n",
    "    os = sigmoid(z)\n",
    "    return os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "580ea1146a9206d39671ff2f01781511",
     "grade": true,
     "grade_id": "cell-4c1601deafbd1e0f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ni = 4\n",
    "no = 7\n",
    "nd = 10\n",
    "np.random.seed(1212)\n",
    "w = np.random.random(size=(no,ni+1))\n",
    "xin = np.random.random(size=(nd,ni))\n",
    "\n",
    "assert forwardPass(xin,w).shape == (nd,no)\n",
    "assert np.isclose(forwardPass(xin,w),np.array([[0.8251632 , 0.830996  , 0.76300723, 0.79702941, 0.77600105,\n",
    "        0.70190947, 0.83435626],\n",
    "       [0.8359558 , 0.90050819, 0.87740353, 0.82827155, 0.87798334,\n",
    "        0.74302696, 0.84477175],\n",
    "       [0.79126012, 0.83815963, 0.84205947, 0.74776205, 0.82513204,\n",
    "        0.74998091, 0.85470589],\n",
    "       [0.82888311, 0.8632446 , 0.8147688 , 0.80891073, 0.82186723,\n",
    "        0.7178646 , 0.83658403],\n",
    "       [0.80946807, 0.84474154, 0.86229083, 0.76895771, 0.84571173,\n",
    "        0.77088251, 0.87455304],\n",
    "       [0.74507238, 0.8140036 , 0.83894366, 0.68989384, 0.80849411,\n",
    "        0.74198462, 0.84545448],\n",
    "       [0.79937484, 0.87904302, 0.91647618, 0.77229595, 0.89669958,\n",
    "        0.79465015, 0.88390382],\n",
    "       [0.71600556, 0.86712487, 0.88545761, 0.7058548 , 0.85982823,\n",
    "        0.71534426, 0.81366481],\n",
    "       [0.73806877, 0.84043116, 0.81406962, 0.73176977, 0.80139834,\n",
    "        0.66464495, 0.79223601],\n",
    "       [0.72038023, 0.80686616, 0.83495421, 0.67903918, 0.80210236,\n",
    "        0.71812182, 0.83319276]])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7322725c4e8c74763e70fab8c85f076e",
     "grade": false,
     "grade_id": "cell-c7bc0608d20238f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Task 2**\n",
    "\n",
    "Verify your implementation of the forward pass using the trained model in the first part of the exercise as an example. You can use the classifier's `predict_proba` member function and the `coefs_` and `intercept_` data members,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the weights from the NN trained above \n",
    "# note that the weights are returned by the intercept (weight 0) and coefs (weights i where i=1,...,ni) data members\n",
    "w1,w2 = classifier.coefs_\n",
    "w1, w2 = np.array(w1), np.array(w2)\n",
    "i1,i2 = classifier.intercepts_\n",
    "\n",
    "# combine the coefs and intercept values to weight vectors\n",
    "w1ni, w1no = w1.shape\n",
    "w1all = np.empty((w1no, w1ni+1))\n",
    "w1all[:,0] = i1\n",
    "w1all[:,1:] = w1.T\n",
    "w2ni, w2no = w2.shape\n",
    "w2all = np.empty((w2no, w2ni+1))\n",
    "w2all[:,0] = i2\n",
    "w2all[:,1:] = w2.T\n",
    "\n",
    "# Use the following sample as your test samples\n",
    "Xtest = X[:3]\n",
    "\n",
    "# return the outputs for the test sample above for your implementation and the sklearn implementation\n",
    "# you should return an array with three values\n",
    "mySolution = 0 # your outputs go here\n",
    "skSolution = 0 # the sklearn outputs go here\n",
    "\n",
    "mySolution = forwardPass(forwardPass(Xtest,w1all),w2all)[:,0]\n",
    "skSolution = classifier.predict_proba(Xtest)[:,1]\n",
    "\n",
    "print (\"my implementation: \",mySolution)\n",
    "print( \"sklearn implementation: \", skSolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0baafe9d6b368cc34e099d02316d7e9",
     "grade": true,
     "grade_id": "cell-3734a41017cd8716",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(mySolution, np.array([0.99237515, 0.97956449, 0.00151048])).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
