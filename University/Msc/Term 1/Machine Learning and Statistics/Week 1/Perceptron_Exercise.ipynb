{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26abadea2cdf9d863717519cf3bb333d",
     "grade": false,
     "grade_id": "cell-dc7cbe8a9b702595",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Perceptron Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the famour iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = sklearn.datasets.load_iris()\n",
    "features = data_dic['data']\n",
    "targets = data_dic['target']\n",
    "c1 = features[targets==0]\n",
    "c2 = features[targets==1]\n",
    "c3 = features[targets==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad6e5a6f9f5fd80cd173069104cfb632",
     "grade": false,
     "grade_id": "cell-319446f6c6f20c57",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This will show the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1, ind2 = 0,1\n",
    "plt.scatter(c1[:,ind1],c1[:,ind2], color='red', marker='s', alpha=0.5, label=\"Setosa\")\n",
    "plt.scatter(c2[:,ind1],c2[:,ind2], color='blue', marker='x', alpha=0.5, label=\"Versicolour\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"sepal length [cm]\")\n",
    "plt.ylabel(\"sepal width [cm]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c348ea4d6a805c06616a89a580b3feee",
     "grade": false,
     "grade_id": "cell-021859f7bb1befce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is used to get a smaller sample to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subSample(nData):\n",
    "    X = np.empty((2*nData,2))\n",
    "    X[:nData] = c1[:nData,:2]\n",
    "    X[nData:] = c2[:nData,:2]\n",
    "    Y = np.empty(2*nData)\n",
    "    Y[:nData] = np.ones(nData)\n",
    "    Y[nData:] = -np.ones(nData)\n",
    "    return X,Y\n",
    "\n",
    "X, Y = subSample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61536b16aa0c05a7f2a3d457bf13b02b",
     "grade": false,
     "grade_id": "cell-d0a9d8a0233385a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25bffbdeb8783db4eb3b011802db700c",
     "grade": false,
     "grade_id": "cell-96536402f756dcff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is the decision function $\\phi$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x):\n",
    "    if x<=0:\n",
    "        return -1.0\n",
    "    else:\n",
    "        return 1.0\n",
    "    \n",
    "phi = np.vectorize(phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b32f14807bbf94d1375f99f63351aa74",
     "grade": false,
     "grade_id": "cell-2cca13ed1424c392",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the function to make a prediction for an input vector `x` and a weight vector `w`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOne(x, w):\n",
    "    z = np.dot(x,w[1:]) + w[0]\n",
    "    return phi(z)\n",
    "    # your function should return either -1. or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictOne(np.array([0.0,0.0]) , np.array([0.1,3.2,7.4])) == 1.0\n",
    "assert predictOne(np.array([0.0,0.0]), np.array([-0.1,3.2,7.4])) == -1.0\n",
    "assert predictOne(np.array([0.3,-0.7]), np.array([0.1,3.2,7.4])) == -1.0\n",
    "assert predictOne(np.array([0.3,0.7]), np.array([0.1,3.2,7.4])) == 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7fce14df25c5153934719555aba8bd7",
     "grade": false,
     "grade_id": "cell-1e4d406f0b5167dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the same function but with an array of values. `X` here will be a `n_d` x `n_f` array, where `n_d` is the number of data points and `n_f` is the number of input per data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMany(X, w):\n",
    "    nd, nf = X.shape\n",
    "    Xaugmented = np.empty((nd,nf + 1))\n",
    "    Xaugmented[:,0] = np.ones( (nd,) )\n",
    "    Xaugmented[:,1:] = X\n",
    "    return phi(np.dot(Xaugmented,w))\n",
    "    # your function should return a list/array of n_d values -1 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.array([\n",
    "    [0.0, 0.0],\n",
    "    [0.3,-0.7],\n",
    "    [0.3,0.7]\n",
    "])\n",
    "assert all(abs(elem) == 1 for elem in predictMany(testX, [0.1,3.2,7.4])), 'Your array should only contain elements with absoulte value 1.'\n",
    "assert (predictMany(testX, [0.1,3.2,7.4]) == np.array([1,-1,1])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b521c363648cd7d109995ae791cc981e",
     "grade": false,
     "grade_id": "cell-c23fdd938000409c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement the function that returns the updated weight vector according to the perceptron algorithm after running over the entire input data `X`, with labels `Y`, current weight vector `w` and learning rate `eta`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(X,Y,w,eta):\n",
    "    neww = np.array(w)\n",
    "    for x,y in zip(X,Y):\n",
    "        predicted = predictOne(x,neww)\n",
    "        update = eta * (y - predicted)/2.0\n",
    "        if update!=0.0:\n",
    "            neww[1:] += update * x\n",
    "            neww[0] += update\n",
    "    return neww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.array([(-1,),(-2,),(5,),(7,)])\n",
    "Ytest = np.array([ -1, -1, 1, 1])\n",
    "wtest = np.array([ 1.5 , 1.0])\n",
    "assert (update(Xtest,Ytest,wtest,0.1) == np.array([1.4, 1.1])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `fit` that updates the perceptron parameters until a solution is found and returns the number of steps needed to converge and the value of the weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,Y,w0,eta):\n",
    "    current_w = np.array(w0)\n",
    "    n_steps = 0\n",
    "    while True:\n",
    "        pred = predictMany(X, current_w)\n",
    "        if (pred == Y).all():\n",
    "            return n_steps, current_w\n",
    "        current_w = update(X,Y,current_w,eta)\n",
    "        n_steps += 1\n",
    "    # your function should return n_steps (as a number) and w (as an array)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = np.array([[5.1, 3.5], [4.9, 3. ], [4.7, 3.2], [4.6, 3.1], [5. , 3.6], [7. , 3.2], [6.4, 3.2], [6.9, 3.1],\n",
    "       [5.5, 2.3], [6.5, 2.8]])\n",
    "Ytest = np.array([ 1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.])\n",
    "\n",
    "# these values already fit the data, so we should no do any step and return the original weight vector\n",
    "test_n, test_w = fit(Xtest,Ytest,[0.2, -0.59, 0.92],0.1)\n",
    "assert len(fit(Xtest,Ytest,[0.2, -0.59, 0.92],0.1)) == 2, 'Your function needs two return values'\n",
    "assert isinstance(test_n, int), 'First return value should be an integer'\n",
    "assert isinstance(test_w, (list, tuple, np.ndarray)), 'Second return value should be an array/list/tuple'\n",
    "\n",
    "assert test_n == 0\n",
    "assert (test_w == [ 0.2 , -0.59,  0.92]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this test requires some iterations\n",
    "test_n, test_w = fit(Xtest,Ytest,[0.0, 0.0, 0.0],0.1)\n",
    "assert test_n == 10\n",
    "assert np.isclose(test_w , [ 0.2 , -0.59,  0.92]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a84fffb49ec5d31a47006b4d16cc9a10",
     "grade": false,
     "grade_id": "cell-41ee6d2d40a90a26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Using scikit-learn\n",
    "\n",
    "This is an example on how to use the perceptron implementation in scikit-learn. Use it to investigate things like \n",
    "- does it help to randomize the input\n",
    "- what is the effect of changing eta? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "# let's use a larger sample\n",
    "X, Y = subSample(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is uses the `Perceptron` class. Using the `max_iter=1` and `warm_start=True` options we ensure that each time the `fit` function is called only one step is performed. This will result in warning saying we have not converged, but that's ok, this is what we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Perceptron(\n",
    "    max_iter=1 , \n",
    "    warm_start=True, \n",
    "    shuffle=False, \n",
    "    eta0=0.5)\n",
    "for i in range(20):\n",
    "    clf.fit(X, Y)\n",
    "    print (clf.intercept_,clf.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
