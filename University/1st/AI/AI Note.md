<!-- TOC start -->

- [AI Note](#ai-note)
  * [1. Machine Learning Basics](#1-machine-learning-basics)
    + [1.1 Categories of machine learning](#11-categories-of-machine-learning)
    + [1.2 Supervised learning workflow](#12-supervised-learning-workflow)
    + [1.3 Model evaluation](#13-model-evaluation)
  * [2. Hierarchical Clustering](#2-hierarchical-clustering)
    + [2.1 Clustering concepts](#21-clustering-concepts)
    + [2.2 Hierarchical clustering](#22-hierarchical-clustering)
  * [3. K-means](#3-k-means)
    + [3.1 K-means](#31-k-means)
  * [4. GMM/EM](#4-gmmem)
    + [4.1 Gaussian mixture models(GMMs)](#41-gaussian-mixture-modelsgmms)
    + [4.2 Expectation-Maximization(EM Algorithm)](#42-expectation-maximizationem-algorithm)
    + [4.3 Summary](#43-summary)
  * [5. DBSCAN](#5-dbscan)
    + [5.1 Density-based Clustering - DBSCAN](#51-density-based-clustering---dbscan)
    + [5.2 The algorithm](#52-the-algorithm)
  * [6. Supervised Learning](#6-supervised-learning)
    + [6.1 Supervised Learning](#61-supervised-learning)
    + [6.2 Training data](#62-training-data)
    + [6.3 Terminology in Supervised Learning](#63-terminology-in-supervised-learning)
    + [6.4 Applications of supervised learning](#64-applications-of-supervised-learning)
  * [7. Linear Regression](#7-linear-regression)
    + [7.1 Regression](#71-regression)
    + [7.2 Univariate linear regression](#72-univariate-linear-regression)
    + [7.3 Loss functions (or cost functions)](#73-loss-functions-or-cost-functions)
    + [7.4 what we want to do](#74-what-we-want-to-do)
    + [7.5 Gradient Descent](#75-gradient-descent)
    + [7.6 Gradient](#76-gradient)
  * [8. Logistic Regression](#8-logistic-regression)
    + [8.1 Logistic regression](#81-logistic-regression)
    + [8.2 Model formulation](#82-model-formulation)
    + [8.3 Cost function](#83-cost-function)
    + [8.4 Learning algorithm by gradient descent](#84-learning-algorithm-by-gradient-descent)
  * [9. Neural Networks](#9-neural-networks)
    + [9.1 Neural Networks](#91-neural-networks)
    + [9.2 Overfitting](#92-overfitting)
  * [10. Evaluation & Hyperparameter Tuning](#10-evaluation--hyperparameter-tuning)
    + [10.1 Recap](#101-recap)
    + [10.3 Evaluating models for model choice](#103-evaluating-models-for-model-choice)
    + [10.4 The holdout validation method](#104-the-holdout-validation-method)
    + [10.5 k-fold Cross-validation](#105-k-fold-cross-validation)
    + [10.6 Leave-one-out validation](#106-leave-one-out-validation)
    + [10.7 Advantages & Disadvantages](#107-advantages--disadvantages)
  * [11. Naive Bayes](#11-naive-bayes)
    + [11.1 Fundamental concepts in Probability Theory](#111-fundamental-concepts-in-probability-theory)
    + [11.2 Bayes' Theorem](#112-bayes-theorem)
    + [11.3 Naive Bayes for Categorical Independent Variables](#113-naive-bayes-for-categorical-independent-variables)
    + [11.4 Naive Bayes for Numerical Independent Variables](#114-naive-bayes-for-numerical-independent-variables)
  * [12. K-Nearest Neighbours](#12-k-nearest-neighbours)
    + [12.1 Notation](#121-notation)
    + [12.2 k-Nearest Neighbour](#122-k-nearest-neighbour)
    + [12.3 k-NN algorithm and pros/cons](#123-k-nn-algorithm-and-proscons)
    + [12.4 Summary](#124-summary)
  * [13. Uninformed Search](#13-uninformed-search)
    + [13.1 Asymptotic Analysis](#131-asymptotic-analysis)
    + [13.2 Search Problem Formulation](#132-search-problem-formulation)
    + [13.3 Breadth-First Search](#133-breadth-first-search)
    + [13.4 Depth-First Search](#134-depth-first-search)
    + [13.5 Variations of Depth-First Search](#135-variations-of-depth-first-search)
  * [14. Informed Search](#14-informed-search)
    + [14.1 Informed Search](#141-informed-search)
    + [14.2 A\* Search](#142-a-search)
    + [14.3 Summary](#143-summary)
  * [15. Introduction to Optimisation](#15-introduction-to-optimisation)
    + [15.1 Optimisation Problems](#151-optimisation-problems)
    + [15.2 Artificial Intelligence Optimisation Algorithms](#152-artificial-intelligence-optimisation-algorithms)
    + [15.3 Learning vs Optimisation](#153-learning-vs-optimisation)
  * [16. Optimisation Problem Formulation](#16-optimisation-problem-formulation)
    + [16.1 Formulating Optimisation Problems](#161-formulating-optimisation-problems)
    + [16.2 Summary](#162-summary)

<!-- TOC end -->

# AI Note

## 1. Machine Learning Basics

### 1.1 Categories of machine learning

- Supervised learning  
  æœ‰ç›‘ç£çš„å­¦ä¹ 

  > Labeled data  
  > æ ‡è®°æ•°æ®  
  > Predict outcome/future  
  > é¢„æµ‹ç»“æœ/æœªæ¥

  - Classification: predict categorical class labels  
    åˆ†ç±»:é¢„æµ‹åˆ†ç±»ç±»åˆ«æ ‡ç­¾
    - e.g. the handwritten digit (multi-class)  
      ä¾‹å¦‚ï¼Œæ‰‹å†™çš„æ•°å­—ï¼ˆå¤šç±»ï¼‰

  ![Classification_1.png](Images/Classification_1.png)

  - Regression: Prediction of continuous outcomes  
    å›å½’: å¯¹è¿ç»­ç»“æœçš„é¢„æµ‹
    - e.g. studentsâ€™ grade scores ä¾‹å¦‚å­¦ç”Ÿçš„æˆç»©

  ![Regression_1.png](Images/Regression_1.png)

- Unsupervised learning  
  æ— ç›‘ç£çš„å­¦ä¹ 

  > No labels/targets  
  > æ— æ ‡ç­¾/ç›®æ ‡  
  > Find hidden structure/insights in data  
  > åœ¨æ•°æ®ä¸­æ‰¾åˆ°éšè—çš„ç»“æ„/è§è§£

  - Clustering: Objectives within a cluster share a degree of
    similarity.  
    èšç±»: é›†ç¾¤å†…çš„ç›®æ ‡æœ‰ä¸€å®šç¨‹åº¦çš„ç›¸ä¼¼æ€§
    - e.g. product recommendation  
      ä¾‹å¦‚äº§å“æ¨è

  ![Clustering_1.png](Images/Clustering_1.png)

  - Dimensionality Reduction:  
    é™ç»´
    - reduce data sparsity  
      é™ä½æ•°æ®ç¨€ç–æ€§
    - reduce computational cost  
      é™ä½è®¡ç®—æˆæœ¬

  ![Dimensionality Reduction_1 .png](Images/Dimensionality%20Reduction_1%20.png)

- Reinforcement learning  
  å¼ºåŒ–å­¦ä¹ 
  - Decision process  
    åˆ¤å®šè¿‡ç¨‹
  - Reward system  
    åé¦ˆç³»ç»Ÿ
  - Learn series of actions  
    å­¦ä¹ ä¸€ç³»åˆ—åŠ¨ä½œ
  - Applications: chess, video games, some robots, self-driving cars  
    åº”ç”¨ç¨‹åºï¼šå›½é™…è±¡æ£‹ï¼Œç”µå­æ¸¸æˆï¼Œä¸€äº›æœºå™¨äººï¼Œè‡ªåŠ¨é©¾é©¶æ±½è½¦

![Reinforcement learning_1.png](Images/Reinforcement%20learning_1.png)

### 1.2 Supervised learning workflow

![Supervised learning workflow_1.png](Images/Supervised%20learning%20workflow_1.png)  
![Supervised learning workflow_2.png](Images/Supervised%20learning%20workflow_2.png)

!Note: Training Data is used to build up the model and Test DAta is used
to test the model

![Some algorithms_1.png](Images/Some%20algorithms_1.png)

### 1.3 Model evaluation

- misclassification error  
  é”™è¯¯åˆ†ç±»é”™è¯¯

![Model evaluation_1.png](Images/Model%20evaluation_1.png)

- other metrics  
  å…¶ä»–æŒ‡æ ‡
  - Accuracy (1-Error)
  - ROC, AUC
  - Precision, Recall
  - F-measure, G-mean
  - (Cross) Entropy
  - Likelihood
  - Squared Error/MSE
  - R2

## 2. Hierarchical Clustering

### 2.1 Clustering concepts

- Segment data into clusters, such that there is  
  å°†æ•°æ®åˆ†å‰²æˆé›†ç¾¤ï¼Œè¿™æ ·æœ‰
  - high intra-cluster similarity  
    é«˜èšç±»å†…ç›¸ä¼¼æ€§
  - low inter-cluster similarity  
    ä½èšç±»é—´ç›¸ä¼¼æ€§
- informally, finding natural groupings among objects  
  éæ­£å¼åœ°ï¼Œåœ¨ç‰©ä½“ä¹‹é—´å¯»æ‰¾è‡ªç„¶çš„åˆ†ç»„ã€‚

- Clustering set-up  
  èšç±»è®¾ç½®
  - Our data are: D = {x<sub>1</sub>, . . . , x<sub>N</sub>}.
  - Each data point is m-dimensional, i.e.  
    x<sub>i</sub> = <x<sub>i,1</sub>, . . . , x<sub>i,m</sub>>
  - Define a distance function (i.e. similarity measures) between data,  
    d(x<sub>i</sub>, x<sub>j</sub>)
  - Goal: segment xn into k groups  
    {z<sub>1</sub>, . . . , z<sub>N</sub>} where z<sub>i</sub> âˆˆ {1, . .
    . ,K}

- Similarity Measures
  - Between any two data samples p and q, we can calculate their
    distance d(p,q) using a number of measurements:  
    ![Similarity Measures_1.png](Images/Similarity%20Measures_1.png)

- Types of Clustering Algorithms  
  èšç±»ç®—æ³•çš„ç±»å‹
  - Partitional clustering, e.g. K-means, K-medoids  
    åˆ†åŒºèšç±»ï¼Œä¾‹å¦‚K-meansï¼ŒK-medoids
  - Hierarchical clustering  
    åˆ†å±‚èšç±»
    - Bottom-up(agglomerative)  
      è‡ªä¸‹è€Œä¸Šï¼ˆå‡èšï¼‰
    - Top-down  
      è‡ªä¸Šè€Œä¸‹
  - Density-based clustering, e.g. DBScan  
    åŸºäºå¯†åº¦çš„èšç±»ï¼Œä¾‹å¦‚DBScan
  - Mixture density based clustering åŸºäºæ··åˆå¯†åº¦çš„èšç±»
  - Fuzzy theory based, graph theory based, grid based, etc.  
    åŸºäºæ¨¡ç³Šç†è®ºã€åŸºäºå›¾è®ºç†è®ºã€åŸºäºç½‘æ ¼ç†è®ºç­‰

### 2.2 Hierarchical clustering

- Create a hierarchical decomposition of the set of objects using some
  criterion  
  ä½¿ç”¨æŸç§æ ‡å‡†åˆ›å»ºå¯¹è±¡é›†çš„åˆ†å±‚åˆ†è§£
- Produce a dendrogram  
  ç”Ÿæˆæ ‘çŠ¶å›¾

![Hierarchical clustering_1.png](Images/Hierarchical%20clustering_1.png)

- Agglomerative clustering illustration  
  å‡èšæ€§çš„èšç±»è¯´æ˜
  - Place each data point into its own singleton group  
    å°†æ¯ä¸ªæ•°æ®ç‚¹æ”¾åˆ°å®ƒè‡ªå·±çš„å•ä¾‹ç»„ä¸­
  - Repeat: iteratively merge the two closest groups  
    é‡å¤ï¼šè¿­ä»£åœ°åˆå¹¶ä¸¤ä¸ªæœ€è¿‘çš„ç»„
  - Until: all the data are merged into a single cluster  
    ç›´åˆ°ï¼šå°†æ‰€æœ‰æ•°æ®éƒ½åˆå¹¶ä¸ºå•ä¸ªé›†ç¾¤

- Output: a dendrogram  
  è¾“å‡ºï¼šæ ‘çŠ¶å›¾
- Reply on: a distance metric between clusters  
  å›å¤ï¼šé›†ç¾¤ä¹‹é—´çš„è·ç¦»åº¦é‡

![Agglomerative clustering illustration_1.png](Images/Agglomerative%20clustering%20illustration_1.png)

- Measuring Distance between clusters
  - Single linkage  
    å•è¿é”
    - the similarity of the closest pair  
      æœ€è¿‘çš„ä¸€å¯¹ä¹‹é—´çš„ç›¸ä¼¼æ€§

  ![Measuring Distance between clusters_1.png](Images/Measuring%20Distance%20between%20clusters_1.png)

  - Complete linkage  
    å®Œå…¨è¿é”
    - the similarity of the furthest pair æœ€è¿œçš„ä¸€å¯¹ä¹‹é—´çš„ç›¸ä¼¼æ€§

  ![Measuring Distance between clusters_2.png](Images/Measuring%20Distance%20between%20clusters_2.png)

  - Group average  
    ç»„å¹³å‡å€¼
    - the average similarity of all pairs  
      æ‰€æœ‰æˆå¯¹çš„å¹³å‡ç›¸ä¼¼åº¦
    - more widely used  
      æ›´å¹¿æ³›åœ°ä½¿ç”¨
    - robust against noise æŠ—å™ªå£°å¼º

  ![Measuring Distance between clusters_3.png](Images/Measuring%20Distance%20between%20clusters_3.png)

- Strengths, weaknesses, caveats  
  ä¼˜åŠ¿ã€å¼±ç‚¹å’Œæ³¨æ„äº‹é¡¹
  - Strengths  
    ä¼˜åŠ¿
    - provides deterministic results  
      æä¾›ç¡®å®šæ€§ç»“æœ
    - no need to specify number of clusters beforehand  
      ä¸éœ€è¦é¢„å…ˆæŒ‡å®šé›†ç¾¤çš„æ•°é‡
    - can create clusters of arbitrary shapes  
      å¯ä»¥åˆ›å»ºä»»æ„å½¢çŠ¶çš„é›†ç¾¤å—
  - Weakness  
    ç¼ºç‚¹
    - does not scale up for large datasets, time complexity at least
      O(n<sup>2</sup>)  
      ä¸å¯ä»¥æ‰©å±•åˆ°å¤§å‹æ•°æ®é›†ï¼Œæ—¶é—´å¤æ‚åº¦è‡³å°‘ä¸ºO(n<sup>2</sup>)
  - Caveats  
    æ³¨æ„äº‹é¡¹
    - Different decisions about group similarities can lead to vastly
      different dendrograms.  
      å…³äºç¾¤ä½“ç›¸ä¼¼æ€§çš„ä¸åŒå†³å®šå¯èƒ½ä¼šå¯¼è‡´æˆªç„¶ä¸åŒçš„æ ‘çŠ¶å›¾
    - The algorithm imposes a hierarchical structure on the data, even
      data for which such structure is not appropriate.
      è¯¥ç®—æ³•å¯¹æ•°æ®å¼ºåŠ äº†ä¸€ä¸ªåˆ†å±‚ç»“æ„ï¼Œå³ä½¿æ˜¯è¿™ç§ç»“æ„ä¸åˆé€‚çš„æ•°æ®

## 3. K-means

### 3.1 K-means

- Centroid-based: describe each cluster by its mean  
  åŸºäºè´¨å¿ƒçš„ï¼šç”¨å®ƒçš„å¹³å‡å€¼æ¥æè¿°æ¯ä¸ªèšç±»
- Goal: assign data to K.  
  ç›®æ ‡ï¼šå°†æ•°æ®åˆ†é…ç»™K
- Algorithm objective: minimize the within-cluster variances of all
  clusters.  
  ç®—æ³•ç›®æ ‡ï¼šæœ€å°åŒ–æ‰€æœ‰èšç±»çš„ç°‡å†…æ–¹å·®

- A non-deterministic method  
  éç¡®å®šæ€§æ–¹æ³•
- Finds a local optimal result (multiple restarts are often necessary)  
  æ‰¾åˆ°å±€éƒ¨æœ€ä¼˜ç»“æœï¼ˆé€šå¸¸éœ€è¦å¤šæ¬¡é‡å¯ï¼‰

- Algorithm description  
  ![Algorithm description_1.png](Images/Algorithm%20description_1.png)

## 4. GMM/EM

### 4.1 Gaussian mixture models(GMMs)

- Assume data was generated by a set of Gaussian distributions  
  å‡è®¾æ•°æ®æ˜¯ç”±ä¸€ç»„é«˜æ–¯åˆ†å¸ƒç”Ÿæˆçš„
- The probability density is a mixture of them æ¦‚ç‡å¯†åº¦æ˜¯å®ƒä»¬çš„æ··åˆç‰©
- Find the parameters of the Gaussian distributions and how much each
  distribution contributes to the data  
  æ‰¾å‡ºé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ä»¥åŠæ¯ä¸ªåˆ†å¸ƒå¯¹æ•°æ®çš„è´¡çŒ®ç¨‹åº¦
- This is a mixture model of Gaussian  
  è¿™æ˜¯ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒçš„æ··åˆæ¨¡å‹

- Generative Models  
  ç”Ÿæˆæ¨¡å‹
  - In supervised learning, we model the joint distribution  
    åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å»ºç«‹äº†è”åˆåˆ†å¸ƒçš„æ¨¡å‹  
    ![Generative Models_1.png](Images/Generative%20Models_1.png)
  - In unsupervised learning, we do not have labels z, we model  
    åœ¨æ— ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰æ ‡ç­¾zï¼Œæˆ‘ä»¬å»ºæ¨¡  
    ![Generative Models_2.png](Images/Generative%20Models_2.png)

- A GMM represents a distributions as  
  ä¸€ä¸ªGMMè¡¨ç¤ºä¸€ä¸ªåˆ†å¸ƒä¸º  
  ![GMMs_1.png](Images/GMMs_1.png)
- with Ï€<sub>k</sub> the mixing coefficients, where  
  ä¸Ï€<sub>k</sub>çš„æ··åˆç³»æ•°ï¼Œå…¶ä¸­  
  ![GMMs_2.png](Images/GMMs_2.png)
- GMM is a density estimator  
  GMMæ˜¯ä¸€ä¸ªå¯†åº¦ä¼°è®¡å™¨
- GMM is universal approximators of densities (if you have enough
  Gaussians)  
  GMMæ˜¯å¯†åº¦çš„é€šç”¨è¿‘ä¼¼å™¨ï¼ˆå¦‚æœä½ æœ‰è¶³å¤Ÿçš„é«˜æ–¯åˆ†å¸ƒï¼‰

- To have a model best fit data, we need to maximize the (log)
  likelihood  
  ä¸ºäº†å¾—åˆ°ä¸€ä¸ªæ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆæ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦æœ€å¤§åŒ–ï¼ˆå¯¹æ•°ï¼‰çš„å¯èƒ½æ€§  
  ![GMMs_3.png](Images/GMMs_3.png)
- Expectation: if we knew Ï€<sub>k</sub>, Âµ and âˆ‘ , we can get â€œsoftâ€
  Z<sub>k</sub> P(z<sup>(n)</sup>|x) - responsibility
- Maximization: if we know Z<sub>k</sub>, we can get Ï€<sub>k</sub>, Âµ
  and âˆ‘

- GMM model has 3 parameters in total to optimise:  
  GMMæ¨¡å‹å…±æœ‰3ä¸ªå‚æ•°è¿›è¡Œä¼˜åŒ–ï¼š
  - the mean vectors of each component(mu)  
    æ¯ä¸ªåˆ†é‡çš„å¹³å‡å‘é‡(mu)
  - the covariances matrices of each component(sigma)  
    æ¯ä¸ªåˆ†é‡çš„åæ–¹å·®çŸ©é˜µ(sigma)
  - the weights associated with each component(pi)  
    ä¸æ¯ä¸ªç»„ä»¶å…³è”çš„æƒé‡(pi)

  - Each iteration of the EM algorithm increases to likelihood of the
    data, unless you happen to be exactly at a local optimum.  
    EMç®—æ³•çš„æ¯æ¬¡è¿­ä»£éƒ½ä¼šå¢åŠ åˆ°æ•°æ®çš„å¯èƒ½æ€§ï¼Œé™¤éä½ ç¢°å·§æ°å¥½å¤„äºå±€éƒ¨æœ€ä¼˜çŠ¶æ€ã€‚

### 4.2 Expectation-Maximization(EM Algorithm)

- An optimization process that alternates between 2 steps:  
  åœ¨ä»¥ä¸‹ä¸¤ä¸ªæ­¥éª¤ä¹‹é—´äº¤æ›¿è¿›è¡Œçš„ä¼˜åŒ–è¿‡ç¨‹ï¼š
  - E-step: compute the posterior probability over z given the current
    model.  
    Eæ­¥ï¼šè®¡ç®—ç»™å®šå½“å‰æ¨¡å‹å¯¹zçš„åéªŒæ¦‚ç‡  
    ![EM_1.png](Images/EM_1.png)
  - M-step: Assuming data was really generated this way, change the
    parameters of each Gaussian to maximize the probability that it
    would generate the data it is currently responsible for.  
    mæ­¥ï¼šå‡è®¾æ•°æ®çœŸçš„æ˜¯ä»¥è¿™ç§æ–¹å¼ç”Ÿæˆçš„ï¼Œé‚£ä¹ˆå°±æ”¹å˜æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜å®ƒäº§ç”Ÿå®ƒç›®å‰è´Ÿè´£çš„æ•°æ®çš„æ¦‚ç‡
    ![EM_2.png](Images/EM_2.png)

- A general algorithm for optimizing many latent variable models (not
  just for GMMs).  
  ä¸€ç§ç”¨äºä¼˜åŒ–è®¸å¤šæ½œåœ¨å˜é‡æ¨¡å‹çš„é€šç”¨ç®—æ³•(ä¸ä»…ä»…æ˜¯ç”¨äºgmm)
- Iteratively computes a lower bound then optimizes it  
  è¿­ä»£åœ°è®¡ç®—ä¸€ä¸ªä¸‹ç•Œï¼Œç„¶åä¼˜åŒ–å®ƒ
- Converges but maybe to a local minima  
  æ”¶æ•›ï¼Œä½†å¯èƒ½ä¼šæ”¶æ•›åˆ°ä¸€ä¸ªå±€éƒ¨æœ€å°å€¼
- Can use multiple restarts  
  å¯ä»¥ä½¿ç”¨å¤šä¸ªé‡æ–°å¯åŠ¨

### 4.3 Summary

- Clustering  
  èšç±»
  - group similar data points  
    ç»„ç›¸ä¼¼çš„æ•°æ®ç‚¹
  - need a distance measure  
    éœ€è¦ä¸€ä¸ªè·ç¦»æµ‹é‡
- Agglomerative hierarchical clustering  
  å‡èšçš„å±‚æ¬¡èšç±»
  - successively merges similar groups of points  
    ä¾æ¬¡åˆå¹¶ç›¸ä¼¼çš„ç‚¹ç»„
  - build a dendrogram (binary tree)  
    æ„å»ºä¸€ä¸ªæ ‘çŠ¶å›¾ï¼ˆäºŒå‰æ ‘ï¼‰
  - different ways to measure distance between clusters  
    æµ‹é‡é›†ç¾¤ä¹‹é—´è·ç¦»çš„ä¸åŒæ–¹æ³•
- GMM using EM  
  GMMä½¿ç”¨EM
  - build a generative model based on Gaussian distributions  
    å»ºç«‹ä¸€ä¸ªåŸºäºé«˜æ–¯åˆ†å¸ƒçš„ç”Ÿæˆæ¨¡å‹
  - need to pre-define k (number of clusters)  
    éœ€è¦é¢„å…ˆå®šä¹‰kï¼ˆé›†ç¾¤çš„æ•°é‡ï¼‰
  - Using EM to find the best fit of the model  
    åˆ©ç”¨EMæ‰¾åˆ°æ¨¡å‹çš„æœ€ä½³æ‹Ÿåˆæ€§


## 5. DBSCAN

### 5.1 Density-based Clustering - DBSCAN

- Acronym for: Density-based spatial clustering of applications with
  noise  
  ç¼©å†™ï¼šåŸºäºå¯†åº¦çš„å¸¦æœ‰å™ªå£°çš„åº”ç”¨ç¨‹åºçš„ç©ºé—´èšç±»
- Clusters are dense regions in the data space separated by regions of
  lower sample density  
  èšç±»æ˜¯æ•°æ®ç©ºé—´ä¸­ç”±æ ·æœ¬å¯†åº¦è¾ƒä½çš„åŒºåŸŸåˆ†éš”çš„å¯†é›†åŒºåŸŸ
- A cluster is defined as a maximal set of density connected points  
  ä¸€ä¸ªç°‡è¢«å®šä¹‰ä¸ºå¯†åº¦è¿æ¥ç‚¹çš„æœ€å¤§é›†
- Discover clusters of arbitrary shape  
  å‘ç°ä»»æ„å½¢çŠ¶çš„ç°‡

- Define three exclusive types of points  
  å®šä¹‰ä¸‰ç§æ’ä»–æ€§ç±»å‹çš„ç‚¹
  - Core, Border (or Edge) and Noise (or outlier)  
    æ ¸å¿ƒã€è¾¹ç•Œï¼ˆæˆ–è¾¹ç¼˜ï¼‰å’Œå™ªå£°ï¼ˆæˆ–å¼‚å¸¸å€¼ï¼‰

> Core points -- dense region æ ¸å¿ƒç‚¹ï¼Œå¯†é›†åŒºåŸŸ  
> Noise -- sparse region å™ªå£°ç¨€ç–åŒº

![DBSCAN_1.png](Images/DBSCAN_1.png)

- Need two parameters  
  éœ€è¦ä¸¤ä¸ªå‚æ•°
  - a circle of epsilon radius  
    ä¸€ä¸ªåŠå¾„çš„åœ†
  - a circle containing at least minPts number of points  
    ä¸€ä¸ªè‡³å°‘åŒ…å«åˆ†é’Ÿæ•°ç‚¹çš„åœ†

- Three types of points

| core   | The point has at least minPts number of points within Eps<br>è¯¥ç‚¹åœ¨Epså†…è‡³å°‘æœ‰minPtsæ•°é‡çš„ç‚¹æ•°                                                            |
|:-------|:------------------------------------------------------------------------------------------------------------------------------------------------------|
| border | The point has fewer than minPts within Eps, but is in the neighbourhood (i.e. circle) of a core point<br>è¯¥ç‚¹åœ¨Epså†…æ¯”minptå°‘ï¼Œä½†åœ¨ä¸€ä¸ªæ ¸å¿ƒç‚¹çš„é™„è¿‘ï¼ˆå³åœ†åœˆï¼‰ |
| noise  | Any point that is not a core point or a border point. <br>ä»»ä½•ä¸æ˜¯æ ¸å¿ƒç‚¹æˆ–è¾¹ç•Œç‚¹çš„ä»»ä½•ç‚¹                                                                   |

![DBSCAN_3.png](Images/DBSCAN_3.png)

- Density-reachability  
  å¯†åº¦å¯è¾¾æ€§
  - Directly density-reachable: a point q is directly density-reachable
    from point p if p is a core point and q is in pâ€™s neighbourhood  
    ç›´æ¥å¯†åº¦å¯è¾¾ï¼šå¦‚æœpæ˜¯ä¸€ä¸ªæ ¸å¿ƒç‚¹ï¼Œå¹¶ä¸”qåœ¨pçš„é‚»åŸŸå†…ï¼Œåˆ™ä¸€ä¸ªç‚¹qä»ç‚¹pç›´æ¥å¯†åº¦å¯è¾¾

  ![DBSCAN_4.png](Images/DBSCAN_4.png)
  - q is directly density-reachable from p  
    qå¯ä»¥ä»pç›´æ¥å¾—åˆ°å¯†åº¦
  - p is not necessarily directly density-reachable from q  
    pä¸ä¸€å®šèƒ½ä»qä¸­ç›´æ¥è¾¾åˆ°å¯†åº¦
  - Density-reachability is asymmetric  
    å¯†åº¦-å¯è¾¾æ€§æ˜¯ä¸å¯¹ç§°çš„
  - Density-Reachable (directly and indirectly)  
    å¯†åº¦-å¯è¾¾æ€§ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰
    - A point p is directly density-reachable from p2  
      ä¸€ä¸ªç‚¹på¯ä»¥ä»p2ç›´æ¥é€šè¿‡å¯†åº¦åˆ°è¾¾
    - p2 is directly density-reachable from p1  
      p2å¯ä»¥ä»p1ç›´æ¥è¾¾åˆ°å¯†åº¦
    - p1 is directly density-reachable from q  
      p1å¯ä»¥ç›´æ¥ä»qè¾¾åˆ°å¯†åº¦
    - q -> p1 -> p2 -> p form a chain(p is the border)  
      q->p1->p2->på½¢æˆä¸€ä¸ªé“¾(pæ˜¯è¾¹ç•Œ)

  ![DBSCAN_5.png](Images/DBSCAN_5.png)
  - p is indirectly density-reachable from q  
    pæ˜¯ä»qé—´æ¥è¾¾åˆ°å¯†åº¦çš„
  - q is not density-reachable from p  
    qä¸èƒ½ä»på¾—åˆ°å¯†åº¦

### 5.2 The algorithm

1. Label all points as core, border or noise.  
   å°†æ‰€æœ‰ç‚¹æ ‡è®°ä¸ºæ ¸å¿ƒã€è¾¹ç•Œæˆ–å™ªå£°
2. Eliminate noise points. æ¶ˆé™¤å™ªå£°ç‚¹
3. For every core point p that has not been assigned to a cluster:  
   å¯¹äºæ²¡æœ‰åˆ†é…ç»™é›†ç¾¤çš„æ¯ä¸ªæ ¸å¿ƒç‚¹p  
   Create a new cluster with the point p and all the points that are
   density-reachable from p  
   ç”¨ç‚¹på’Œæ‰€æœ‰ä»på¯ä»¥è¾¾åˆ°å¯†åº¦çš„ç‚¹åˆ›å»ºä¸€ä¸ªæ–°çš„é›†ç¾¤
4. For border points belonging to more than 1 cluster, assign it to the
   cluster of the closest core point.  
   å¯¹äºå±äº1ä¸ªé›†ç¾¤çš„è¾¹ç•Œç‚¹ï¼Œå°†å…¶åˆ†é…ç»™æœ€è¿‘æ ¸å¿ƒç‚¹çš„é›†ç¾¤ã€‚

- Some key points
  - DBSCAN can find non-linearly separable clusters. (an advantage over
    K-means and GMM)  
    DBSCANå¯ä»¥æ‰¾åˆ°éçº¿æ€§å¯åˆ†çš„ç°‡ã€‚(ç›¸å¯¹äºK-meanså’ŒGMMçš„ä¼˜åŠ¿)
  - Resistant to noise  
    è€å™ªéŸ³
  - Not entirely deterministic: border points that are reachable from
    more than one cluster can be part of either cluster, depending on
    the implementation  
    ä¸å®Œå…¨ç¡®å®šæ€§çš„ï¼šä»å¤šä¸ªé›†ç¾¤å¯è®¿é—®çš„è¾¹ç•Œç‚¹å¯ä»¥æ˜¯ä»»æ„ä¸€ä¸ªé›†ç¾¤çš„ä¸€éƒ¨åˆ†ï¼Œè¿™å–å†³äºå®ç°

- K-means and EM rely on cluster initialisation, and EM also relies on
  gradient descent. Therefore, they are non-deterministic algorithms and
  may get struck at local optima  
  K-meanså’ŒEMä¾èµ–äºèšç±»åˆå§‹åŒ–ï¼Œè€ŒEMä¹Ÿä¾èµ–äºæ¢¯åº¦ä¸‹é™ã€‚å› æ­¤ï¼Œå®ƒä»¬æ˜¯éç¡®å®šæ€§çš„ç®—æ³•ï¼Œå¯èƒ½ä¼šè¾¾åˆ°å±€éƒ¨æœ€ä¼˜

- Gaussian mixture model trained using EM is a soft version of K-means,
  but these two algorithms do not necessarily produce the same cluster
  centres given the same data set.  
  ä½¿ç”¨EMè®­ç»ƒçš„é«˜æ–¯æ··åˆæ¨¡å‹æ˜¯K-meansçš„è½¯ç‰ˆæœ¬ï¼Œä½†è¿™ä¸¤ç§ç®—æ³•åœ¨ç›¸åŒçš„æ•°æ®é›†ä¸‹ä¸ä¸€å®šäº§ç”Ÿç›¸åŒçš„èšç±»ä¸­å¿ƒã€‚
- DBSCAN is capable to discover clusters of any shapes.  
  DBSCANèƒ½å¤Ÿå‘ç°ä»»ä½•å½¢çŠ¶çš„é›†ç¾¤
- Using Gaussian mixture model with Expectation-maximization
  optimization to cluster a data set, the result is non-deterministic
  and may get stuck in local optima.  
  åˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹å’ŒæœŸæœ›æœ€å¤§åŒ–ä¼˜åŒ–å¯¹æ•°æ®é›†è¿›è¡Œèšç±»ï¼Œç»“æœæ˜¯ä¸ç¡®å®šæ€§çš„ï¼Œå¯èƒ½ä¼šé™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

## 6. Supervised Learning

### 6.1 Supervised Learning

- One of the most prevalent forms of ML  
  MLæœ€æ™®éçš„å½¢å¼ä¹‹ä¸€
  - Teach a computer to do something, then let it use its knowledge to
    do it  
    æ•™ç”µè„‘å»åšæŸä»¶äº‹ï¼Œç„¶åè®©å®ƒç”¨è‡ªå·±çš„çŸ¥è¯†å»åš
- Other forms of ML  
  å…¶ä»–å½¢å¼çš„ML
  - Unsupervised learning  
    æ— ç›‘ç£å­¦ä¹ 
  - Reinforcement learning  
    å¼ºåŒ–å­¦ä¹ 

- Types of supervised learning  
  ç›‘ç£å­¦ä¹ çš„ç±»å‹
  - Regression  
    å›å½’
  - Classification  
    èšç±»
    - Binary
    - Multi-class

### 6.2 Training data

- Supervised learning needs annotated data for training:  
  ç›‘ç£å­¦ä¹ éœ€è¦åŸ¹è®­çš„æ³¨é‡Šæ•°æ®ï¼š  
  in the form of examples of (Input, Output) pairs  
  ä»¥ï¼ˆè¾“å…¥ã€è¾“å‡ºï¼‰å¯¹çš„ç¤ºä¾‹çš„å½¢å¼å‡ºç°
- After training completed  
  åŸ¹è®­å®Œæˆå
  - you present it with new Input that it hasn't seen before  
    ä½ ç”¨å®ƒä»¥å‰ä»æœªè§è¿‡çš„æ–°è¾“å…¥æ¥å‘ˆç°å®ƒ
  - It needs to predict the appropriate Output  
    å®ƒéœ€è¦é¢„æµ‹é€‚å½“çš„è¾“å‡º

### 6.3 Terminology in Supervised Learning

- Input = attribute(s) = feature(s) = independent variable
- Output = target = response = dependent variable
- function = hypothesis = predictor

### 6.4 Applications of supervised learning

- Handwriting recognition  
  æ‰‹å†™è¯†åˆ«
  - When you write an envelope, algorithms can automatically route
    envelopes through the post  
    å½“ä½ å†™ä¸€ä¸ªä¿¡å°æ—¶ï¼Œç®—æ³•å¯ä»¥è‡ªåŠ¨é€šè¿‡é‚®ä»¶å‘é€ä¿¡å°
- Computer vision & graphics  
  è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢
  - When you go out during lockdown, object detection & visual tracking
    algorithms can automatically detect compliance with the rules  
    å½“ä½ åœ¨é”å®šæœŸé—´å¤–å‡ºæ—¶ï¼Œç›®æ ‡æ£€æµ‹å’Œè§†è§‰è·Ÿè¸ªç®—æ³•å¯ä»¥è‡ªåŠ¨æ£€æµ‹åˆ°æ˜¯å¦ç¬¦åˆè§„åˆ™
- Bioinformatics  
  ç”Ÿç‰©
  - Algorithms can predict protein function from sequence  
    ç®—æ³•å¯ä»¥ä»åºåˆ—ä¸­é¢„æµ‹è›‹ç™½è´¨çš„åŠŸèƒ½
- Human-computer interaction  
  äººæœºäº’åŠ¨
  - Intrusion detection algorithms can recognise speech, gestures,
    intention  
    å…¥ä¾µæ£€æµ‹ç®—æ³•å¯ä»¥è¯†åˆ«è¯­éŸ³ã€æ‰‹åŠ¿ã€æ„å›¾

## 7. Linear Regression

### 7.1 Regression

- Regression means learning a function that captures the â€œtrendâ€ between
  input and output  
  å›å½’æ„å‘³ç€å­¦ä¹ ä¸€ä¸ªæ•è·è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„â€œè¶‹åŠ¿â€çš„å‡½æ•°
- We then use this function to predict target values for new inputs  
  ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥é¢„æµ‹æ–°è¾“å…¥çš„ç›®æ ‡å€¼

### 7.2 Univariate linear regression

- Visually, there appears to be a trend  
  ä»è§†è§‰ä¸Šçœ‹ï¼Œä¼¼ä¹æœ‰ä¸€ç§è¶‹åŠ¿
- A reasonable **model** seems to be the **class of linear functions
  (lines)**  
  ä¸€ä¸ªåˆç†çš„æ¨¡å‹ä¼¼ä¹æ˜¯ä¸€ç±»çº¿æ€§å‡½æ•°ï¼ˆçº¿ï¼‰
- We have one input attribute (year) - hence the name **univariate**  
  æˆ‘ä»¬æœ‰ä¸€ä¸ªè¾“å…¥å±æ€§ï¼ˆå¹´ä»½ï¼‰ï¼Œå› æ­¤å®ƒè¢«å‘½åä¸ºå•å˜é‡

![LinearRegression_1.png](Images/LinearRegression_1.png)

- Any line is described by this equation by specifying values for ğ‘¤1,
  ğ‘¤0.

### 7.3 Loss functions (or cost functions)

- We need a criterion that, given the data, for any given line will tell
  us how bad is that line.  
  æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ ‡å‡†ï¼Œç»™å®šæ•°æ®ï¼Œå¯¹äºä»»ä½•ç»™å®šçš„çº¿éƒ½ä¼šå‘Šè¯‰æˆ‘ä»¬è¿™æ¡çº¿æœ‰å¤šç³Ÿç³•
- Such criterion is called a loss function. It is a function of the free
  parameters!  
  è¿™ç§å‡†åˆ™è¢«ç§°ä¸ºæŸå¤±å‡½æ•°ã€‚å®ƒæ˜¯ä¸€ä¸ªè‡ªç”±å‚æ•°çš„å‡½æ•°
- Loss function = cost function = loss = cost = error function

![Loss functions_1.png](Images/Loss%20functions_1.png)

- Square loss(L2 loss)
  - The loss expresses an error, so it must be always non-negative  
    æŸå¤±è¡¨ç¤ºä¸€ä¸ªé”™è¯¯ï¼Œæ‰€ä»¥å®ƒå¿…é¡»æ€»æ˜¯æ˜¯éè´Ÿçš„
  - Square loss is a sensible choice to measure mismatch for regression  
    å¹³æ–¹æŸå¤±æ˜¯è¡¡é‡å›å½’ä¸åŒ¹é…çš„åˆç†é€‰æ‹©
  - Mean Square Error (MSE)å¹³å‡å¹³æ–¹è¯¯å·®(MSE)  
    ![Loss functions_2.png](Images/Loss%20functions_2.png)

![Loss functions_3.png](Images/Loss%20functions_3.png)

### 7.4 what we want to do

- Given training data  
  ![Loss functions_4.png](Images/Loss%20functions_4.png)
- Fit the model  
  ![Loss functions_5.png](Images/Loss%20functions_5.png)
- By minimising the cost function  
  ![Loss functions_6.png](Images/Loss%20functions_6.png)

- Every combination of w0 and w1 has an associated cost  
  w0å’Œw1çš„æ¯ä¸ªç»„åˆéƒ½æœ‰ä¸€ä¸ªç›¸å…³çš„æˆæœ¬
- To find the â€˜best fitâ€™ we need to find values for w0 and w1 such that
  the cost is minimum.  
  ä¸ºäº†æ‰¾åˆ°â€œæœ€ä½³æ‹Ÿåˆâ€ï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°w0å’Œw1çš„å€¼ï¼Œä»è€Œä½¿æˆæœ¬æœ€å°

### 7.5 Gradient Descent

- A general strategy to minimise cost functions  
  ä¸€ç§æœ€å°åŒ–æˆæœ¬å‡½æ•°çš„ä¸€èˆ¬ç­–ç•¥
- Goal: Minimise cost function ğ‘”(ğ‘¤), where ğ’˜ =(ğ‘¤0, ğ‘¤1, , â€¦)  
  ç›®æ ‡ï¼šæœ€å°åŒ–æˆæœ¬å‡½æ•°ï¼Œğ‘”(ğ‘¤)  
  ![Gradient Descent_1.png](Images/Gradient%20Descent_1.png)
- Î± is called â€œlearning rateâ€= â€œstep sizeâ€

- If the value of alpha is too high, Gradient Descent will never reach
  the minimum  
  å¦‚æœalphaçš„å€¼è¿‡é«˜ï¼Œæ¢¯åº¦ä¸‹é™å°†æ°¸è¿œä¸ä¼šè¾¾åˆ°æœ€å°å€¼

### 7.6 Gradient

- Partial derivative with respect to ğ‘¤0
  is![Gradient_1.png](Images/Gradient_1.png)It means the derivative
  function of ğ‘”(ğ‘¤0, ğ‘¤1) when ğ‘¤1 is treated as constant.
- Partial derivative with respect to ğ‘¤1
  is![Gradient_2.png](Images/Gradient_2.png)It means the derivative
  function of ğ‘”(ğ‘¤0, ğ‘¤1) when ğ‘¤0 is treated as constant.
- The vector of partial derivatives is called the gradient  
  åå¯¼æ•°çš„å‘é‡ç§°ä¸ºæ¢¯åº¦ ![Gradient_3.png](Images/Gradient_3.png)
- The negative of the gradient evaluated at a location (ğ‘¤0, ğ‘¤1) gives
  us the direction of the steepest descent from that location.  
  åœ¨ä¸€ä¸ªä½ç½®ï¼ˆğ‘¤0ï¼Œğ‘¤1ï¼‰ä¸Šè®¡ç®—çš„æ¢¯åº¦çš„è´Ÿå€¼ç»™å‡ºäº†ä»è¯¥ä½ç½®æœ€é™¡ä¸‹é™çš„æ–¹å‘

- Computing the gradient for our L2 loss  
  è®¡ç®—L2æŸå¤±çš„æ¢¯åº¦  
  ![Gradient_4.png](Images/Gradient_4.png)
- Algorithm for univariate linear regression using GD  
  åŸºäºGDçš„å•å˜é‡çº¿æ€§å›å½’ç®—æ³•  
  ![Gradient_5.png](Images/Gradient_5.png)

- Multivariate linear regression  
  å¤šå…ƒçº¿æ€§å›å½’  
  ![Gradient_6.png](Images/Gradient_6.png)

- Univariate nonlinear regression  
  å•å˜é‡éçº¿æ€§å›å½’  
  ![Gradient_7.png](Images/Gradient_7.png)

- Advantages of vector notation  
  çŸ¢é‡ç¬¦å·çš„ä¼˜ç‚¹
  - Vector notation in concise  
    å‘é‡ç¬¦å·ç®€æ˜
  - With the vectors ğ’˜ and ğ± populated appropriately (and differently
    in each case, as on the previous 2 slides), these models are still
    linear in the parameter vector.  
    ç”±äºå‘é‡ğ’˜å’Œğ±é€‚å½“å¡«å……ï¼ˆæ¯ç§æƒ…å†µä¸‹éƒ½ä¸åŒï¼Œå¦‚å‰ä¸¤ä¸ªå¹»ç¯ç‰‡ï¼‰ï¼Œè¿™äº›æ¨¡å‹åœ¨å‚æ•°å‘é‡ä¸­ä»ç„¶æ˜¯çº¿æ€§çš„ã€‚
  - The cost function is the L2 as before  
    æˆæœ¬å‡½æ•°å’Œå‰é¢ä¸€æ ·æ˜¯l2
  - So the gradient in both cases
    is:![Gradient_8.png](Images/Gradient_8.png)
  - Ready to be plugged into the general gradient descent algorithm  
    å‡†å¤‡å¥½è¢«æ’å…¥åˆ°ä¸€èˆ¬çš„æ¢¯åº¦ä¸‹é™ç®—æ³•ä¸­

- x is independent variables
- w is free parameters(weights)

- Note: The choice of learning rate alpha depends upon dataset and
  hypothesis function. Thus, without any further known details and given
  an arbitrary choice of alpha, it cannot be estimated whether gradient
  descent will converge or not.  
  æ³¨ï¼šå­¦ä¹ ç‡alphaçš„é€‰æ‹©å–å†³äºæ•°æ®é›†å’Œå‡è®¾å‡½æ•°ã€‚å› æ­¤ï¼Œå¦‚æœæ²¡æœ‰ä»»ä½•å·²çŸ¥ç»†èŠ‚å’Œç»™å®šä»»æ„é€‰æ‹©ï¼Œå°±ä¸èƒ½ä¼°è®¡æ¢¯åº¦ä¸‹é™æ˜¯å¦ä¼šæ”¶æ•›ã€‚

## 8. Logistic Regression

### 8.1 Logistic regression

- It is a linear model for classification (contrary to its name!)  
  å®ƒæ˜¯ä¸€ä¸ªåˆ†ç±»çš„çº¿æ€§æ¨¡å‹ï¼ˆä¸å®ƒçš„åå­—ç›¸åï¼ï¼‰

- In regression, the targets are real values  
  åœ¨å›å½’ä¸­ï¼Œç›®æ ‡æ˜¯çœŸå®çš„å€¼
- In classification, the targets are categories, and they are called
  labels  
  åœ¨åˆ†ç±»ä¸­ï¼Œç›®æ ‡æ˜¯ç±»åˆ«ï¼Œå®ƒä»¬è¢«ç§°ä¸ºæ ‡ç­¾

### 8.2 Model formulation

- We want to put a boundary between 2 classes  
  æˆ‘ä»¬æƒ³åœ¨ä¸¤ä¸ªç±»ä¹‹é—´è®¾ç½®ä¸€ä¸ªç•Œé™
- If x has a single attribute, we can do it with a point  
  å¦‚æœxæœ‰ä¸€ä¸ªå•ä¸€çš„å±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªç‚¹æ¥å®Œæˆå®ƒ  
  ![Logistic Regression_1.png](Images/Logistic%20Regression_1.png)
- If x has 2 attributes, we can do it with a line  
  å¦‚æœxæœ‰ä¸¤ä¸ªå±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€è¡Œæ¥åš  
  ![Logistic Regression_2.png](Images/Logistic%20Regression_2.png)
- If x has 3 attributes, we can do it with a plane  
  å¦‚æœxæœ‰3ä¸ªå±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªå¹³é¢æ¥åš
- If x has more than 3 attributes, we can do it with a hyperplane (canâ€™t
  draw it anymore)  
  å¦‚æœxæœ‰è¶…è¿‡3ä¸ªå±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸€ä¸ªè¶…å¹³é¢æ¥å®Œæˆå®ƒï¼ˆä¸èƒ½å†ç»˜åˆ¶å®ƒäº†ï¼‰
- If the classes are linearly separable, the training error will be 0  
  å¦‚æœè¿™äº›ç±»æ˜¯çº¿æ€§å¯åˆ†çš„ï¼Œåˆ™è®­ç»ƒè¯¯å·®å°†ä¸º0

![Model formulation_1.png](Images/Model%20formulation_1.png)

![Model formulation_2.png](Images/Model%20formulation_2.png)

- The sigmoid function takes a single argument (note, ğ’˜<sup>ğ‘‡</sup>ğ’™
  is one number).  
  så‹å‡½æ•°é‡‡ç”¨å•ä¸ªå‚æ•°ï¼ˆæ³¨æ„ï¼Œğ’˜<sup>ğ‘‡</sup>ğ’™æ˜¯ä¸€ä¸ªæ•°å­—ï¼‰
- It always returns a value between 0 and 1. The meaning of this value
  is the probability that the label is 1  
  å®ƒæ€»æ˜¯è¿”å›ä¸€ä¸ªä»‹äº0åˆ°1ä¹‹é—´çš„å€¼ã€‚è¿™ä¸ªå€¼çš„å«ä¹‰æ˜¯æ ‡ç­¾ä¸º1çš„æ¦‚ç‡  
  ![Model formulation_3.png](Images/Model%20formulation_3.png)
  - If this is smaller than 0.5 then we predict label 0  
    å¦‚æœè¿™å°äº0.5ï¼Œé‚£ä¹ˆæˆ‘ä»¬é¢„æµ‹æ ‡ç­¾ä¸º0
  - if this is larger than 0.5 then we predict label 1  
    å¦‚æœè¿™å¤§äº0.5ï¼Œé‚£ä¹ˆæˆ‘ä»¬é¢„æµ‹æ ‡ç­¾1
- There is a slim chance that the sigmoid outputs exactly 0.5. The set
  of all possible inputs for which this happens is called the decision
  boundary.  
  sigmoid è¾“å‡ºæ°å¥½ä¸º 0.5 çš„å¯èƒ½æ€§å¾ˆå°ã€‚æ‰€æœ‰å¯èƒ½çš„é›†åˆå‘ç”Ÿè¿™ç§æƒ…å†µçš„è¾“å…¥ç§°ä¸ºå†³ç­–è¾¹ç•Œ

### 8.3 Cost function

- each data point contributes a cost, and the overall cost function is
  the average of these  
  æ¯ä¸ªæ•°æ®ç‚¹è´¡çŒ®ä¸€ä¸ªæˆæœ¬ï¼Œæ€»ä½“æˆæœ¬å‡½æ•°æ˜¯è¿™äº›æˆæœ¬çš„å¹³å‡å€¼
- the cost is a function of the free parameters of the model  
  ä»£ä»·æ˜¯æ¨¡å‹çš„è‡ªç”±å‚æ•°çš„å‡½æ•°

![Cost function_1.png](Images/Cost%20function_1.png)

- Given training data  
  ![Cost function_2.png](Images/Cost%20function_2.png)
- Fit the model  
  ![Cost function_4.png](Images/Cost%20function_4.png)
- By minimising the cross-entropy cost function  
  ![Cost function_3.png](Images/Cost%20function_3.png)

- When the actual output y=0 and the prediction is 1, the logistic
  regression cost function assigns a cost of âˆ å½“å®é™…è¾“å‡º y=0 ä¸”é¢„æµ‹ä¸º 1
  æ—¶ï¼Œé€»è¾‘å›å½’æˆæœ¬å‡½æ•°åˆ†é…çš„æˆæœ¬ä¸º âˆ

### 8.4 Learning algorithm by gradient descent

- We use gradient descent (again!) to minimise the cost function, i.e.
  to find the best weight values.  
  æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼ˆå†æ¬¡å¦‚æ­¤ï¼ï¼‰ä½¿æˆæœ¬å‡½æ•°æœ€å°åŒ–ï¼Œå³æ‰¾åˆ°æœ€ä½³çš„æƒé‡å€¼
- The gradient vector is:  
  æ¢¯åº¦å‘é‡ä¸º  
  ![Learning algorithm by gradient descent_1.png](Images/Learning%20algorithm%20by%20gradient%20descent_1.png)  
  ![Learning algorithm by gradient descent_2.png](Images/Learning%20algorithm%20by%20gradient%20descent_2.png)

- Learning algorithm for logistic regression  
  ![Learning algorithm by gradient descent_3.png](Images/Learning%20algorithm%20by%20gradient%20descent_3.png)

- Nonlinear logistic regression: instead of linear function inside the
  exp in the sigmoid, we can use polynomial functions of the input
  attributes  
  éçº¿æ€§é€»è¾‘å›å½’ï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¾“å…¥å±æ€§çš„å¤šé¡¹å¼å‡½æ•°ï¼Œè€Œä¸æ˜¯så‹expä¸­çš„çº¿æ€§å‡½æ•°
- Multi-class logistic regression: uses a multi-valued version of
  sigmoid  
  å¤šç±»é€»è¾‘å›å½’ï¼šä½¿ç”¨å¤šå€¼ç‰ˆæœ¬çš„så‹ç®—æ³•

- Examples of application of logistic regression  
  é€»è¾‘å›å½’çš„åº”ç”¨ä¾‹å­
  - Face detection: classes consist of images that contain a face and
    images without a face
  - Sentiment analysis: classes consist of written product-reviews
    expressing a positive or a negative opinion
  - Automatic diagnosis of medical conditions: classes consist of
    medical data of patients who either do or do not have a specific
    disease

## 9. Neural Networks

### 9.1 Neural Networks

- Highly nonlinear models having many free parameters  
  å…·æœ‰è®¸å¤šè‡ªç”±å‚æ•°çš„é«˜åº¦éçº¿æ€§æ¨¡å‹
- Can be used for either regression and classification depending on the
  choice of loss function  
  å¯æ ¹æ®æŸå¤±å‡½æ•°çš„é€‰æ‹©è¿›è¡Œå›å½’å’Œåˆ†ç±»
- Can replace nonlinear regression and nonlinear logistic regression
  which are less practical  
  å¯ä»¥ä»£æ›¿ä¸å¤ªå®ç”¨çš„éçº¿æ€§å›å½’å’Œéçº¿æ€§é€»è¾‘å›å½’

1. Model formulation

- Sometimes called â€œarchitectureâ€  
  æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºâ€œå»ºç­‘â€
- Designing this for the problem at hand is the main challenge  
  é’ˆå¯¹å½“å‰çš„é—®é¢˜è®¾è®¡è¿™ä¸ªæ–¹æ¡ˆæ˜¯ä¸»è¦çš„æŒ‘æˆ˜

2. Cost function

- for regression: Mean square error between predictions and observed
  targets  
  å›å½’ï¼šé¢„æµ‹å’Œè§‚æµ‹ç›®æ ‡ä¹‹é—´çš„å‡æ–¹è¯¯å·®
- for classification: Logistic loss (also called cross-entropy)  
  ç”¨äºåˆ†ç±»ï¼šLogisticæŸå¤±ï¼ˆä¹Ÿç§°ä¸ºäº¤å‰ç†µï¼‰

3. Learning algorithm by gradient descent

- The update rules are non-trivial, because the models are much more
  complex  
  æ›´æ–°è§„åˆ™ä¸ç®€å•ï¼Œå› ä¸ºæ¨¡å‹è¦å¤æ‚å¾—å¤š
- It is performed by an algorithm called â€œBackpropagationâ€  
  å®ƒæ˜¯ç”±ä¸€ç§å«åšâ€œåå‘ä¼ æ’­â€çš„ç®—æ³•æ¥æ‰§è¡Œçš„
- Conceptually, each iteration of Backprop takes a gradient descent step  
  ä»æ¦‚å¿µä¸Šè®²ï¼Œæ¯ä¸€æ¬¡çš„åpropè¿­ä»£éƒ½é‡‡å–ä¸€ä¸ªæ¢¯åº¦ä¸‹é™æ­¥éª¤
- Implementations exist that are able to compute the grandient
  automatically  
  å­˜åœ¨ç€èƒ½å¤Ÿè‡ªåŠ¨è®¡ç®—å®ä¼Ÿå»ºç­‘çš„å®ç°
- To update the weights of the Neural Network  
  æ›´æ–°ç¥ç»ç½‘ç»œçš„æƒé‡

- use the Backpropagation algorithm and set a good learning rate (alpha)
  for it:  
  ç”¨åå‘ä¼ æ’­å¹¶ä¸”è®¾ç½®ä¸€ä¸ªå¥½çš„alphaå€¼
  - Train on the training data repeatedly, each time using a different
    value of alpha, and pick the version of the model for which the
    validation error is lowest.  
    é‡å¤è®­ç»ƒè®­ç»ƒæ•°æ®ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„ alpha å€¼ï¼Œå¹¶é€‰æ‹©éªŒè¯é”™è¯¯æœ€ä½çš„æ¨¡å‹ç‰ˆæœ¬ã€‚

- Building blocks of a feedforward neural net  
  å‰é¦ˆç¥ç»ç½‘ç»œçš„æ„ä»¶
  - Each node is one unit or neuron  
    æ¯ä¸ªèŠ‚ç‚¹æ˜¯ä¸€ä¸ªå•ä½æˆ–ç¥ç»å…ƒ
  - Each arrow is a connection with a weight  
    æ¯ä¸ªç®­å¤´éƒ½æ˜¯ä¸€ä¸ªå¸¦æœ‰ä¸€ä¸ªé‡é‡çš„è¿æ¥ç‚¹
  - Nodes are arranged in layers  
    èŠ‚ç‚¹è¢«åˆ†å±‚æ’åˆ—
    - One input layer
    - One output layer
    - Any number of hidden layers (0,1,2,â€¦)
  - Hidden & output nodes typically apply a sigmoid, or other activation
    function  
    éšè—å’Œè¾“å‡ºèŠ‚ç‚¹é€šå¸¸åº”ç”¨så‹èŠ‚ç‚¹æˆ–å…¶ä»–æ¿€æ´»å‡½æ•°

- Simplest neural net  
  æœ€ç®€å•çš„ç¥ç»ç½‘ç»œ
  - A neural net with 0 hidden layers is called a perceptron  
    ä¸€ä¸ªå…·æœ‰0ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œè¢«ç§°ä¸ºæ„ŸçŸ¥å™¨
  - If the activation function is the sigmoid, then this model is
    equivalent to a logistic regression  
    å¦‚æœæ¿€æ´»å‡½æ•°æ˜¯så‹çš„ï¼Œé‚£ä¹ˆè¿™ä¸ªæ¨¡å‹å°±ç­‰ä»·äºä¸€ä¸ªé€»è¾‘å›å½’  
    ![Neural Networks_1.png](Images/Neural%20Networks_1.png)
    - The type of computation performed by each non-input node is the
      same in multi-layer networks too.  
      åœ¨å¤šå±‚ç½‘ç»œä¸­ï¼Œæ¯ä¸ªéè¾“å…¥èŠ‚ç‚¹æ‰€æ‰§è¡Œçš„è®¡ç®—ç±»å‹ä¹ŸåŒæ ·ç›¸åŒ
    - The choice of activation function can be different  
      æ¿€æ´»å‡½æ•°çš„é€‰æ‹©å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒ

- Multi-layer perceptron  
  å¤šå±‚æ„ŸçŸ¥æœº
  - When we have one hidden layer, the model is called multi-layer
    perceptron  
    å½“æˆ‘ä»¬æœ‰ä¸€ä¸ªéšè—å±‚æ—¶ï¼Œè¯¥æ¨¡å‹è¢«ç§°ä¸ºå¤šå±‚æ„ŸçŸ¥å™¨
  - It is a truly non-linear model  
    è¿™æ˜¯ä¸€ä¸ªçœŸæ­£çš„éçº¿æ€§æ¨¡å‹
  - Weights = parameters
  - Number of hidden units, choice of activation function =
    hyperparameters
  - Number of output nodes = number of targets or labels we want to
    predict
  - MLP is more complex, hence it is more flexible  
    MLP æ›´å¤æ‚ï¼Œå› æ­¤æ›´çµæ´»
  - MLP can learn a nonlinear curve  
    MLP å¯ä»¥å­¦ä¹ éçº¿æ€§æ›²çº¿

- Deep neural networks  
  æ·±åº¦ç¥ç»ç½‘ç»œ
  - Very simply, deep learning is machine learning using neural networks
    that have multiple hidden layers  
    å¾ˆç®€å•ï¼Œæ·±åº¦å­¦ä¹ æ˜¯ä¸€ç§ä½¿ç”¨å…·æœ‰å¤šä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œçš„æœºå™¨å­¦ä¹ 
  - Number of hidden layers is another hyperparameter  
    éšè—å±‚çš„æ•°é‡æ˜¯å¦ä¸€ä¸ªè¶…å‚æ•°
  - Several hidden layers, several hidden nodes, several hyperparameters  
    å‡ ä¸ªéšè—å±‚ï¼Œå‡ ä¸ªéšè—èŠ‚ç‚¹ï¼Œå‡ ä¸ªè¶…å‚æ•°
  - Mean square error

### 9.2 Overfitting

- learning every irrelevant detail (noise) in a training data set will
  not help  
  åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å­¦ä¹ æ¯ä¸€ä¸ªä¸ç›¸å…³çš„ç»†èŠ‚ï¼ˆå™ªå£°ï¼‰æ˜¯æ²¡æœ‰å¸®åŠ©çš„
- Overfitting happens when the model is more complex than required  
  å½“æ¨¡å‹æ¯”è¦æ±‚çš„æ›´å¤æ‚æ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿‡æ‹Ÿåˆ
- The error on the test data increases across consecutive epochs whereas
  that on the training data reduces  
  æµ‹è¯•æ•°æ®ä¸Šçš„è¯¯å·®åœ¨è¿ç»­çš„æ—¶æœŸå†…å¢åŠ ï¼Œè€Œè®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®å‡å°‘

- Classification  
  ![Overfitting_1.png](Images/Overfitting_1.png)

- Regression  
  ![Overfitting_2.png](Images/Overfitting_2.png)

- Regularisation è§„åˆ™åŒ–
  - One way to guard against overfitting is regularisation  
    é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„ä¸€ç§æ–¹æ³•æ˜¯è§„åˆ™åŒ–
  - Add a penalty to the cost function to penalise more complex models  
    åœ¨æˆæœ¬å‡½æ•°ä¸­æ·»åŠ ä¸€ä¸ªæƒ©ç½šï¼Œä»¥æƒ©ç½šæ›´å¤æ‚çš„æ¨¡å‹
  - Prune the model  
    ä¿®å‰ªæ¨¡å‹

- Early stopping æ—©åœ
  - Stopping the training early is another effective way to guard
    against overfitting  
    æå‰åœæ­¢è®­ç»ƒæ˜¯é˜²æ­¢è¿‡åº¦æ‹Ÿåˆçš„å¦ä¸€ç§æœ‰æ•ˆæ–¹æ³•
  - After each gradient update (or Backprop cycle), the training cost
    will decrease until it reaches 0  
    åœ¨æ¯æ¬¡æ¢¯åº¦æ›´æ–°ï¼ˆæˆ–åå‘å¾ªç¯ï¼‰åï¼ŒåŸ¹è®­æˆæœ¬å°†ä¼šä¸‹é™ï¼Œç›´åˆ°è¾¾åˆ°0
  - Set aside a subset of the data (called hold-out set) to use only for
    monitoring the cost on previously unseen data  
    ç•™å‡ºä¸€ä¸ªæ•°æ®å­é›†ï¼ˆç§°ä¸ºä¿ç•™é›†ï¼‰ï¼Œä»…ç”¨äºç›‘è§†ä»¥å‰æœªè§è¿‡çš„æ•°æ®çš„æˆæœ¬
  - The error on hold-out set will decrease at first, but as training
    continues, it can start increasing  
    ä¿ç•™é›†ä¸Šçš„é”™è¯¯ä¸€å¼€å§‹ä¼šå‡å°‘ï¼Œä½†éšç€è®­ç»ƒçš„ç»§ç»­ï¼Œå®ƒå¯èƒ½ä¼šå¼€å§‹å¢åŠ 
  - Stop training when the error on hold-out set starts increasing  
    å½“åœ¨ä¿ç•™é›†ä¸Šçš„é”™è¯¯å¼€å§‹å¢åŠ æ—¶ï¼Œåœæ­¢è®­ç»ƒ


## 10. Evaluation & Hyperparameter Tuning

### 10.1 Recap

- Each supervised learning method consists of 3 ingredients:  
  æ¯ç§ç›‘ç£å­¦ä¹ æ–¹æ³•ç”±3ä¸ªç»„æˆéƒ¨åˆ†ç»„æˆ
  - Model: form of function we want to learn (has free parameters)  
    æ¨¡å‹ï¼šæˆ‘ä»¬æƒ³è¦å­¦ä¹ çš„å‡½æ•°å½¢å¼ï¼ˆæœ‰è‡ªç”±å‚æ•°ï¼‰
  - Cost function: given a training set, it measures the misfit of any
    particular function from the model  
    ä»£ä»·å‡½æ•°ï¼šç»™å®šä¸€ä¸ªè®­ç»ƒé›†ï¼Œå®ƒåº¦é‡æ¨¡å‹ä¸­ä»»ä½•ç‰¹å®šå‡½æ•°çš„ä¸æ‹Ÿåˆ
  - Training algorithm: gradient descent minimisation of the cost
    function  
    è®­ç»ƒç®—æ³•ï¼šä»£ä»·å‡½æ•°çš„æ¢¯åº¦ä¸‹é™æœ€å°åŒ–

- Hyperparameters are â€œhigher-levelâ€ free parameters  
  è¶…å‚æ•°æ˜¯â€œé«˜çº§â€è‡ªç”±å‚æ•°
  - In Neural Networks:  
    ç¥ç»ç½‘ç»œä¸­ï¼š
    - Depth (number of hidden layers)  
      æ·±åº¦ï¼ˆéšè—å›¾å±‚æ•°ï¼‰
    - Width (number of hidden neurons in a hidden layer)  
      å®½åº¦ï¼ˆéšè—å±‚ä¸­éšè—ç¥ç»å…ƒçš„æ•°é‡ï¼‰
    - Activation function (choice of nonlinearity in non-input nodes)  
      æ¿€æ´»å‡½æ•°ï¼ˆéè¾“å…¥èŠ‚ç‚¹ä¸­çš„éçº¿æ€§é€‰æ‹©ï¼‰
    - Regularisation parameter (way to trade off simplicity vs. fit to
      the data)  
      æ­£åˆ™åŒ–å‚æ•°ï¼ˆæƒè¡¡ç®€å•æ€§ä¸é€‚åˆæ•°æ®çš„æ–¹æ³•ï¼‰
  - In polynomial regression  
    å¤šé¡¹å¼å›å½’
    - Order of the polynomial (use of ğ‘¥, ğ‘¥<sub>2</sub>,
      ğ‘¥<sub>3</sub>, â€¦ , ğ‘¥<sub>ğ‘š</sub>)  
      å¤šé¡¹å¼çš„é¡ºåºï¼ˆä½¿ç”¨ğ‘¥, ğ‘¥<sub>2</sub>, ğ‘¥<sub>3</sub>, â€¦ ,
      ğ‘¥<sub>ğ‘š</sub>ï¼‰
  - In general  
    æ™®éåœ°
    - Model choice  
      æ¨¡å‹é€‰æ‹©

- Always split the available annotated data randomly into:  
  æ€»æ˜¯å°†å¯ç”¨çš„æ³¨é‡Šæ•°æ®éšæœºåˆ†æˆ
  - A training set- to be used for training â€“ i.e. estimating all the
    free parameters  
    ä¸€ä¸ªç”¨äºè®­ç»ƒçš„è®­ç»ƒé›†ï¼Œå³ä¼°è®¡æ‰€æœ‰çš„è‡ªç”±å‚æ•°
  - A test set - to be used to evaluate the trained predictor before
    deploying it  
    ä¸€ä¸ªæµ‹è¯•é›†-ç”¨äºåœ¨éƒ¨ç½²å®ƒä¹‹å‰è¯„ä¼°å·²è®­ç»ƒè¿‡çš„é¢„æµ‹å™¨

- Each hyperparameter value corresponds to a different model  
  æ¯ä¸ªè¶…å‚æ•°å€¼å¯¹åº”äºä¸€ä¸ªä¸åŒçš„æ¨¡å‹
- For this evaluation we can no longer use our cost function computed on
  training set â€“ why?  
  å¯¹äºè¿™ä¸ªè¯„ä¼°ï¼Œæˆ‘ä»¬ä¸èƒ½å†ä½¿ç”¨æˆ‘ä»¬å¯¹è®­ç»ƒé›†è®¡ç®—çš„æˆæœ¬å‡½æ•°-ä¸ºä»€ä¹ˆï¼Ÿ
  - The more complex (flexible) the model, the better it will fit the
    training data  
    æ¨¡å‹è¶Šå¤æ‚ï¼ˆè¶Šçµæ´»ï¼‰ï¼Œå°±è¶Šé€‚åˆè®­ç»ƒæ•°æ®
  - But the goal is to predict well on future data  
    ä½†å…¶ç›®æ ‡æ˜¯è¦å¾ˆå¥½åœ°é¢„æµ‹æœªæ¥çš„æ•°æ®
  - A model that has capacity to fit any training data will overfit  
    ä¸€ä¸ªèƒ½å¤Ÿæ‹Ÿåˆä»»ä½•è®­ç»ƒæ•°æ®çš„æ¨¡å‹å°†ä¼šè¢«è¿‡åº¦æ‹Ÿåˆ

- Even if the models only differ by one hyperparameter, they are
  different models.  
  å³ä½¿è¿™äº›æ¨¡å‹åªç›¸å·®ä¸€ä¸ªè¶…å‚æ•°ï¼Œå®ƒä»¬ä¹Ÿæ˜¯ä¸åŒçš„æ¨¡å‹ã€‚
- Choosing a particular value of a hyperparameter requires evaluating
  each model.  
  é€‰æ‹©ä¸€ä¸ªè¶…å‚æ•°çš„ç‰¹å®šå€¼éœ€è¦è¯„ä¼°æ¯ä¸ªæ¨¡å‹

### 10.3 Evaluating models for model choice

- The training set is annotated data (input, output) â€“ use for training
  within a chosen model  
  è®­ç»ƒé›†æ˜¯æ³¨é‡Šæ•°æ®ï¼ˆè¾“å…¥ã€è¾“å‡ºï¼‰-ç”¨äºåœ¨é€‰å®šçš„æ¨¡å‹å†…è¿›è¡Œè®­ç»ƒ
- The test set is also annotated data (input output) â€“ use for
  evaluating the performance of the trained predictor before deploying
  it  
  æµ‹è¯•é›†è¿˜åŒ…æ‹¬æ³¨é‡Šæ•°æ®ï¼ˆè¾“å…¥è¾“å‡ºï¼‰â€”â€”ç”¨äºåœ¨éƒ¨ç½²å®ƒä¹‹å‰è¯„ä¼°è®­ç»ƒè¿‡çš„é¢„æµ‹å™¨çš„æ€§èƒ½
- None of these can be used to choose the model!  
  è¿™äº›éƒ½ä¸èƒ½ç”¨æ¥é€‰æ‹©æ¨¡å‹ï¼

- Idea: To choose between models or hyperparameters, split out a subset
  from the training set = validation set  
  æƒ³æ³•ï¼šè¦åœ¨æ¨¡å‹æˆ–è¶…å‚æ•°ä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼Œä»è®­ç»ƒé›†=éªŒè¯é›†ä¸­åˆ†å‰²å‡ºä¸€ä¸ªå­é›†
- Methods:
  - Holdout validation  
    ä¿ç•™éªŒè¯
  - Cross-validation  
    äº¤å‰éªŒè¯
  - Leave-one-out validation  
    ç•™ä¸€éªŒè¯

![Evaluating models for model choice_1.png](Images/Evaluating%20models%20for%20model%20choice_1.png)

### 10.4 The holdout validation method

1. Randomly choose 30% of the data to form a validation set  
   éšæœºé€‰æ‹©30%çš„æ•°æ®å½¢æˆä¸€ä¸ªéªŒè¯é›†  
   ![The holdout validation method_1.png](Images/The%20holdout%20validation%20method_1.png)
2. The remainder is a training set  
   å‰©ä¸‹çš„æ˜¯ä¸€ä¸ªè®­ç»ƒé›†
3. Train your model on the training set  
   åœ¨è®­ç»ƒé›†ä¸­è®­ç»ƒä½ çš„æ¨¡å‹  
   ![The holdout validation method_2.png](Images/The%20holdout%20validation%20method_2.png)
   ![The holdout validation method_3.png](Images/The%20holdout%20validation%20method_3.png)
   ![The holdout validation method_4.png](Images/The%20holdout%20validation%20method_4.png)
4. Estimate the test performance on the validation set  
   ä¼°è®¡åœ¨éªŒè¯é›†ä¸Šçš„æµ‹è¯•æ€§èƒ½

- In regression, we compute the cost function (mean square error) on the
  examples of the validation set (instead of the training set)  
  åœ¨å›å½’è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åœ¨éªŒè¯é›†ï¼ˆè€Œä¸æ˜¯è®­ç»ƒé›†ï¼‰çš„ä¾‹å­ä¸Šè®¡ç®—ä»£ä»·å‡½æ•°ï¼ˆå‡æ–¹è¯¯å·®ï¼‰
- In classification, we donâ€™t compute the cross-entropy cost on the
  validation set, instead on validation set we compute the 0-1 error
  metric:  
  åœ¨åˆ†ç±»ä¸­ï¼Œæˆ‘ä»¬ä¸è®¡ç®—éªŒè¯é›†ä¸Šçš„äº¤å‰ç†µä»£ä»·ï¼Œè€Œæ˜¯åœ¨éªŒè¯é›†ä¸Šè®¡ç®—0-1çš„è¯¯å·®åº¦é‡ï¼š  
  ![The holdout validation method_5.png](Images/The%20holdout%20validation%20method_5.png)
  - There are also other metrics, besides Accuracy, that take account of
    the 2 types of error specific to classification (false positives and
    false negatives)  
    é™¤äº†å‡†ç¡®æ€§ä¹‹å¤–ï¼Œè¿˜æœ‰å…¶ä»–æŒ‡æ ‡è€ƒè™‘äº†åˆ†ç±»çš„ä¸¤ç§ç±»å‹çš„é”™è¯¯ï¼ˆå‡é˜³æ€§å’Œå‡é˜´æ€§ï¼‰

5. Choose the model with lowest validation error  
   é€‰æ‹©éªŒè¯è¯¯å·®æœ€å°çš„æ¨¡å‹
6. Re-train with the chosen model on joined train & validation set to
   obtain predictor  
   åœ¨è¿æ¥åˆ—è½¦å’ŒéªŒè¯é›†ä¸Šä½¿ç”¨æ‰€é€‰æ¨¡å‹è¿›è¡Œå†è®­ç»ƒï¼Œä»¥è·å¾—é¢„æµ‹å™¨
7. Estimate future performance of obtained predictor on the test set  
   åœ¨æµ‹è¯•é›†ä¸Šä¼°è®¡æ‰€è·å¾—çš„é¢„æµ‹å™¨çš„æœªæ¥æ€§èƒ½
8. Ready to deploy the predictor  
   å·²ç»å‡†å¤‡å¥½éƒ¨ç½²è¯¥é¢„æµ‹å™¨äº†

### 10.5 k-fold Cross-validation

- Split the training set randomly into k (equal sized) disjoint sets.
  (In this example, k=3)  
  å°†è®­ç»ƒé›†éšæœºåˆ†å‰²æˆkä¸ªï¼ˆå¤§å°ç›¸ç­‰ï¼‰çš„ä¸ç›¸äº¤é›†ã€‚(åœ¨æœ¬ä¾‹ä¸­ï¼Œk=3)
- Use k-1 of those together for training  
  å°†å…¶ä¸­çš„k-1ä¸€èµ·è¿›è¡ŒåŸ¹è®­
- Use the remaining one for validation.  
  ä½¿ç”¨å…¶ä½™çš„ä¸€ä¸ªæ¥è¿›è¡ŒéªŒè¯ã€‚
- Permute the k sets and repeat k times.  
  æ’åˆ—kä¸ªé›†åˆå¹¶é‡å¤kä¸ªæ—¶é—´ã€‚
- Average the performances on the k validation sets.  
  å¹³å‡åœ¨kä¸ªéªŒè¯é›†ä¸Šçš„æ€§èƒ½ã€‚

![Cross-validation_1.png](Images/Cross-validation_1.png)

- Randomly break the dataset into k partitions (here k=3)  
  å°†æ•°æ®é›†éšæœºåˆ†è§£ä¸ºkä¸ªåˆ†åŒº(è¿™é‡Œæ˜¯kä¸ª=3)  
  ![Cross-validation_2.png](Images/Cross-validation_2.png)
- For the blue partition: Train on all the points except the blue
  partition. Compute the validation error using the points in the blue
  partition  
  å¯¹äºè“è‰²åˆ†åŒºï¼šå¯¹é™¤è“è‰²åˆ†åŒºä»¥å¤–çš„æ‰€æœ‰ç‚¹è¿›è¡Œè®­ç»ƒã€‚ä½¿ç”¨è“è‰²åˆ†åŒºä¸­çš„ç‚¹æ¥è®¡ç®—éªŒè¯é”™è¯¯  
  ![Cross-validation_3.png](Images/Cross-validation_3.png)
- For the green partition: Train on all the points except the green
  partition. Compute the validation error using the points in the green
  partition.  
  å¯¹äºç»¿è‰²åˆ†åŒºï¼šå¯¹é™¤ç»¿è‰²åˆ†åŒºä»¥å¤–çš„æ‰€æœ‰ç‚¹è¿›è¡Œè®­ç»ƒã€‚ä½¿ç”¨ç»¿è‰²åˆ†åŒºä¸­çš„ç‚¹æ¥è®¡ç®—éªŒè¯é”™è¯¯ã€‚  
  ![Cross-validation_4.png](Images/Cross-validation_4.png)
- For the purple partition: Train on all the points except the purple
  partition. Compute the validation error using the points in the purple
  partition.  
  å¯¹äºç´«è‰²åˆ†åŒºï¼šå¯¹é™¤ç´«è‰²åˆ†åŒºä¹‹å¤–çš„æ‰€æœ‰ç‚¹è¿›è¡Œè®­ç»ƒã€‚ä½¿ç”¨ç´«è‰²åˆ†åŒºä¸­çš„ç‚¹æ¥è®¡ç®—éªŒè¯é”™è¯¯ã€‚  
  ![Cross-validation_5.png](Images/Cross-validation_5.png)
- Take the mean of these errors  
  å–è¿™äº›è¯¯å·®çš„å¹³å‡å€¼  
  ![Cross-validation_6.png](Images/Cross-validation_6.png)
  ![Cross-validation_7.png](Images/Cross-validation_7.png)
  ![Cross-validation_8.png](Images/Cross-validation_8.png)

### 10.6 Leave-one-out validation

- We leave out a single example for validation, and train on all the
  rest of the annotated data  
  æˆ‘ä»¬çœç•¥äº†ä¸€ä¸ªå¯ä¾›éªŒè¯çš„ç¤ºä¾‹ï¼Œå¹¶å¯¹æ‰€æœ‰å…¶ä½™çš„æ³¨é‡Šæ•°æ®è¿›è¡Œäº†è®­ç»ƒ
- For a total of N examples, we repeat this N times, each time leaving
  out a single example  
  å¯¹äºæ€»å…±Nä¸ªä¾‹å­ï¼Œæˆ‘ä»¬é‡å¤è¿™Næ¬¡ï¼Œæ¯æ¬¡éƒ½çœç•¥ä¸€ä¸ªä¾‹å­ Take the average of the
  validation errors as measured on the left-out points  
  å–åœ¨é—æ¼ç‚¹ä¸Šæµ‹é‡çš„éªŒè¯è¯¯å·®çš„å¹³å‡å€¼

- Same as N-fold cross-validation where N is the number of labelled
  points  
  ä¸Nå€äº¤å‰éªŒè¯ç›¸åŒï¼Œå…¶ä¸­Næ˜¯æ ‡è®°ç‚¹çš„æ•°é‡

### 10.7 Advantages & Disadvantages

|                    | Advantages                              | Disadvantages                                                                       |
|:-------------------|:----------------------------------------|:------------------------------------------------------------------------------------|
| Holdout validation | Computationally cheapest                | Most unreliable if sample size is not large enough                                  |
| 3-fold             | Slightly more reliable than holdout     | - Wastes 1/3-rd annotated data<br>- Computationally 3-times as expensive as holdout |
| 10-fold            | - Only wastes 10% <br>- Fairly reliable | - Wastes 10% annotated data <br>- Computationally 10-times as expensive as holdout  |
| Leave-one-out      | Doesn't waste data                      | Computationally most expensive                                                      |

- re-train the same network with a lot more training data  
  ç”¨æ›´å¤šçš„è®­ç»ƒæ•°æ®é‡æ–°è®­ç»ƒåŒä¸€ä¸ªç½‘ç»œ
  - The turning point in the validation error curve will occur at a
    later iteration than before.  
    éªŒè¯è¯¯å·®æ›²çº¿çš„è½¬æŠ˜ç‚¹å°†å‘ç”Ÿåœ¨æ¯”ä»¥å‰æ›´æ™šçš„è¿­ä»£ä¸­ã€‚
  - The training error curve and validation error curve will become more
    similar to each other.  
    è®­ç»ƒè¯¯å·®æ›²çº¿å’ŒéªŒè¯è¯¯å·®æ›²çº¿å°†å˜å¾—æ›´åŠ ç›¸ä¼¼

## 11. Naive Bayes

### 11.1 Fundamental concepts in Probability Theory

- Probabilistic model: a mathematical description of an uncertain
  situation. The two main elements of a probabilistic model are:  
  æ¦‚ç‡æ¨¡å‹ï¼šå¯¹ä¸ç¡®å®šæƒ…å†µçš„æ•°å­¦æè¿°ã€‚ä¸€ä¸ªæ¦‚ç‡æ¨¡å‹çš„ä¸¤ä¸ªä¸»è¦è¦ç´ æ˜¯ï¼š
  - The sample space Î©, which is the set of all possible outcomes  
    æ ·æœ¬ç©ºé—´Î©ï¼Œå®ƒæ˜¯æ‰€æœ‰å¯èƒ½ç»“æœçš„é›†åˆ
  - The probability law, which assigns to a set A of possible outcomes
    (called an event) a nonnegative number P(A) (called the probability
    of A)  
    æ¦‚ç‡å®šå¾‹ï¼Œå®ƒèµ‹äºˆAå¯èƒ½ç»“æœï¼ˆç§°ä¸ºäº‹ä»¶ï¼‰ä¸€ä¸ªéè´Ÿæ•°P(A)ï¼ˆç§°ä¸ºAçš„æ¦‚ç‡ï¼‰
- Every probabilistic model involves an underlying process, called the
  experiment, that produces exactly one of several possible outcomes  
  æ¯ä¸ªæ¦‚ç‡æ¨¡å‹éƒ½æ¶‰åŠåˆ°ä¸€ä¸ªæ½œåœ¨çš„è¿‡ç¨‹ï¼Œç§°ä¸ºå®éªŒï¼Œå®ƒæ°å¥½äº§ç”Ÿäº†å‡ ç§å¯èƒ½çš„ç»“æœä¸­çš„ä¸€ç§
- A subset of the sample space Î© is called an event  
  æ ·æœ¬ç©ºé—´Î©çš„ä¸€ä¸ªå­é›†è¢«ç§°ä¸ºäº‹ä»¶

- Probability Axioms æ¦‚ç‡å…¬ç†
  - Nonnegativity: P(A) â‰¥ 0, for every event A  
    éè´Ÿæ€§ï¼šP(A)â‰¥0ï¼Œå¯¹äºæ¯ä¸ªäº‹ä»¶A
  - Additivity: If A and B are two disjoint events, then the probability
    of their union satisfies: P(A âˆª B) = P(A) + P(B)  
    å¯åŠ æ€§ï¼šå¦‚æœAå’ŒBæ˜¯ä¸¤ä¸ªä¸ç›¸äº¤çš„äº‹ä»¶ï¼Œåˆ™å®ƒä»¬çš„å¹¶é›†çš„æ¦‚ç‡æ»¡è¶³ï¼šP(AâˆªB)=P(A)+P(B)
  - Normalisation: The probability of the entire sample space is equal
    to 1, namely P(Î©)= 1  
    å½’ä¸€åŒ–ï¼šæ•´ä¸ªæ ·æœ¬ç©ºé—´çš„æ¦‚ç‡ç­‰äº1ï¼Œå³P(Î©)= 1

- Random variables are usually indicated with uppercase letters, e.g., X
  or Temperature or Infection  
  éšæœºå˜é‡é€šå¸¸ç”¨å¤§å†™å­—æ¯è¡¨ç¤ºï¼Œå¦‚Xæˆ–æ¸©åº¦æˆ–æ„ŸæŸ“
- The values are indicated with lowercase letters, Xâˆˆ{ture,false}  
  è¿™äº›å€¼ç”¨å°å†™å­—æ¯è¡¨ç¤º,Xâˆˆ{ture,false}
- Vectors are usually indicated with bold letters or a small arrow above
  the letter  
  å‘é‡é€šå¸¸ç”¨ç²—ä½“å­—æ¯æˆ–å­—æ¯ä¸Šæ–¹çš„ä¸€ä¸ªå°ç®­å¤´è¡¨ç¤º
- PMF is usually indicated by the symbol p<sub>x</sub>(x)  
  MFé€šå¸¸ç”¨ç¬¦å·p<sub>x</sub>(x)è¡¨ç¤º

- An unconditional (or prior) probability distribution gives us the
  probabilities of all possible events without knowing anything else
  about the problem, e.g., the maximum value of two rolls of a 4-sided
  die  
  ä¸€ä¸ªæ— æ¡ä»¶ï¼ˆæˆ–å…ˆéªŒï¼‰æ¦‚ç‡åˆ†å¸ƒç»™æˆ‘ä»¬æ‰€æœ‰å¯èƒ½äº‹ä»¶çš„æ¦‚ç‡ï¼Œè€Œä¸çŸ¥é“é—®é¢˜çš„ä»»ä½•å…¶ä»–ä¸œè¥¿ï¼Œä¾‹å¦‚ï¼Œå››é¢æ¨¡å…·çš„ä¸¤å·çš„æœ€å¤§å€¼
- A conditional (or posterior) probability distribution gives us the
  probability of all possible events with some additional knowledge,
  e.g., the maximum value of two rolls of a 4-sided die knowing that the
  first roll is 3  
  ä¸€ä¸ªæ¡ä»¶ï¼ˆæˆ–åéªŒï¼‰æ¦‚ç‡åˆ†å¸ƒç»™äº†æˆ‘ä»¬æœ‰ä¸€äº›é™„åŠ çŸ¥è¯†çš„æ‰€æœ‰å¯èƒ½äº‹ä»¶çš„æ¦‚ç‡ï¼Œä¾‹å¦‚ï¼ŒçŸ¥é“ç¬¬ä¸€ä¸ªè¾Šçš„åŒé¢æ¨¡å…·çš„ä¸¤è¾Šçš„æœ€å¤§å€¼æ˜¯3

- A joint probability distribution is the probability distribution
  associated to all combinations of the values of two or more random
  variables  
  è”åˆæ¦‚ç‡åˆ†å¸ƒæ˜¯ä¸ä¸¤ä¸ªæˆ–å¤šä¸ªéšæœºå˜é‡çš„å€¼çš„æ‰€æœ‰ç»„åˆç›¸å…³è”çš„æ¦‚ç‡åˆ†å¸ƒ
- This is indicated by commas, e.g., P(X,Y)  
  è¿™æ˜¯ç”¨é€—å·è¡¨ç¤ºçš„ï¼Œä¾‹å¦‚ï¼ŒP(X,Y)
- We can calculate the joint probability distribution by using the
  product rule as in the following:  
  P(X,Y) = P(X|Y)P(Y) = P(Y|X)P(X)

- The mean (or expected value or expectation), also indicated by Î¼ of a
  random variable X with PMF p<sub>x</sub>(x) represents the centre of
  gravity of the PMF:  
  å¹³å‡å€¼ï¼ˆæˆ–æœŸæœ›å€¼æˆ–æœŸæœ›å€¼ï¼‰ï¼Œä¹Ÿç”±éšæœºæ•°çš„ Î¼ è¡¨ç¤ºå¸¦æœ‰ PMF p<sub>x</sub>(x) çš„å˜é‡
  X è¡¨ç¤º PMF çš„é‡å¿ƒï¼š  
  ![Probability Theory_1.png](Images/Probability%20Theory_1.png)
- The variance of a random variable X provides a measure of the
  dispersion around the mean:  
  ä¸€ä¸ªéšæœºå˜é‡Xçš„æ–¹å·®æä¾›äº†ä¸€ä¸ªåœ¨å‡å€¼å‘¨å›´çš„ç¦»æ•£åº¦çš„åº¦é‡  
  ![Probability Theory_2.png](Images/Probability%20Theory_2.png)
- The standard deviation is another measure of dispersion:  
  æ ‡å‡†åå·®æ˜¯ç¦»æ•£åº¦çš„å¦ä¸€ç§åº¦é‡æ–¹æ³•ï¼š  
  ![Probability Theory_3.png](Images/Probability%20Theory_3.png)

- Continuous Random Variables  
  è¿ç»­éšæœºå˜é‡
  - A random variable X is called continuous if its probability law can
    be described in terms of a nonnegative function fx. This function is
    called probability density function (PDF) and is the equivalent of
    the PMF for discrete random variables  
    å¦‚æœéšæœºå˜é‡ X çš„æ¦‚ç‡è§„å¾‹å¯ä»¥è¢«æè¿°ï¼Œåˆ™ç§°å…¶ä¸ºè¿ç»­å˜é‡ å°±éè´Ÿå‡½æ•° fx
    è€Œè¨€ã€‚è¿™ä¸ªå‡½æ•°ç§°ä¸ºæ¦‚ç‡å¯†åº¦ å‡½æ•° (PDF) å¹¶ä¸”ç­‰æ•ˆäºç¦»æ•£éšæœºå˜é‡çš„ PMF  
    ![Probability Theory_4.png](Images/Probability%20Theory_4.png)
  - Since we are dealing with continuous variables, there are an
    infinite number of values that X can take  
    å› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯è¿ç»­å˜é‡ï¼Œæ‰€ä»¥Xå¯ä»¥å–æ— æ•°ä¸ªå€¼
  - As for the discrete case, also for continuous random variables we
    can have unconditional, conditional and joint probability
    distributions  
    å¯¹äºç¦»æ•£æƒ…å†µï¼Œå¯¹äºè¿ç»­éšæœºå˜é‡ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ— æ¡ä»¶çš„ã€æ¡ä»¶çš„å’Œè”åˆæ¦‚ç‡åˆ†å¸ƒ

- A probability mass function for a categorical / ordinal random
  variable gives the probability of observing each of the possible
  values of this variable.  
  åˆ†ç±»/æœ‰åºéšæœºå˜é‡çš„æ¦‚ç‡è´¨é‡å‡½æ•°ç»™å‡ºäº†è§‚å¯Ÿè¯¥å˜é‡æ¯ä¸ªå¯èƒ½å€¼çš„æ¦‚ç‡

### 11.2 Bayes' Theorem

![Bayes' Theorem_1.png](Images/Bayes%27%20Theorem_1.png)
- The above equation is known as Bayesâ€™ Theorem (also Bayesâ€™ rule or
  Bayesâ€™ law)  
  ä¸Šè¿°æ–¹ç¨‹ç§°ä¸ºè´å¶æ–¯å®šç†ï¼ˆä¹Ÿç§°ä¸ºè´å¶æ–¯è§„åˆ™æˆ–è´å¶æ–¯å®šå¾‹ï¼‰

- Equivalent Terminology  
  ç­‰æ•ˆæœ¯è¯­
  - Input attribute, independent variable, input variable  
    è¾“å…¥å±æ€§ï¼Œè‡ªå˜é‡ï¼Œè¾“å…¥å˜é‡
  - Output attribute, dependent variable, output variable, label
    (classification)  
    è¾“å‡ºå±æ€§ã€å› å˜é‡ã€è¾“å‡ºå˜é‡ã€æ ‡ç­¾ï¼ˆåˆ†ç±»ï¼‰
  - Predictive model, classifier (classification), or hypothesis
    (statistical learning)  
    é¢„æµ‹æ¨¡å‹ã€åˆ†ç±»å™¨ï¼ˆåˆ†ç±»ï¼‰æˆ–å‡è®¾ï¼ˆç»Ÿè®¡å­¦ä¹ ï¼‰
  - Learning a model, training a model, building a model  
    å­¦ä¹ æ¨¡å‹ï¼Œè®­ç»ƒæ¨¡å‹ï¼Œå»ºç«‹æ¨¡å‹
  - Training examples, training data  
    åŸ¹è®­ç¤ºä¾‹ã€åŸ¹è®­æ•°æ®
  - Example, observation, data point, instance (more frequently used for
    test examples)  
    ç¤ºä¾‹ã€è§‚å¯Ÿã€æ•°æ®ç‚¹ã€å®ä¾‹ï¼ˆé€šå¸¸ç”¨äºæµ‹è¯•ç¤ºä¾‹ï¼‰
  - P(a,b) = P(a and b) = P(a âˆ§ b)

- More than 1 Independent Variable  
  1å¤šä¸ªè‡ªå˜é‡  
  ![Bayes' Theorem_2.png](Images/Bayes%27%20Theorem_2.png)
  - P represents the probability calculated based on the frequency
    tables  
    Pè¡¨ç¤ºæ ¹æ®é¢‘ç‡è¡¨è®¡ç®—å‡ºçš„æ¦‚ç‡
  - c represents a class  
    cè¡¨ç¤ºä¸€ä¸ªç±»
  - a<sub>i</sub> represents the value of independent variable
    x<sub>i</sub> âˆˆ {1, â€¦ , n}  
    a<sub>i</sub>è¡¨ç¤ºè‡ªå˜é‡x<sub>i</sub>âˆˆ{1ï¼Œ...ï¼Œn}çš„å€¼
  - n is the number of independent variables  
    næ˜¯è‡ªå˜é‡çš„æ•°é‡
  - Î± is the normalisation factor  
    Î±æ˜¯æ­£å¸¸åŒ–å› å­

![Bayes' Theorem_3.png](Images/Bayes%27%20Theorem_3.png)

### 11.3 Naive Bayes for Categorical Independent Variables

- For increasing numbers of independent variables, all possible
  combinations must be considered:  
  å¯¹äºå¢åŠ è‡ªå˜é‡çš„æ•°é‡ï¼Œå¿…é¡»è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„ç»„åˆ  
  ![Categorical Independent Variables_1.png](Images/Categorical%20Independent%20Variables_1.png)
- For a domain described by n Boolean variables, we would need an input
  table of size O(2<sup>n</sup>) and it would take O(2<sup>n</sup>) to
  process the table  
  å¯¹äºç”± n ä¸ªå¸ƒå°”å˜é‡æè¿°çš„åŸŸï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¤§å°ä¸º O(2<sup>n</sup>)
  çš„è¾“å…¥è¡¨ï¼Œå¤„ç†è¯¥è¡¨éœ€è¦ O(2<sup>n</sup>)

- Assumption: each input variable is conditionally independent of any
  other input variables given the output  
  å‡è®¾ï¼šæ¯ä¸ªè¾“å…¥å˜é‡éƒ½æœ‰æ¡ä»¶åœ°ç‹¬ç«‹äºç»™å®šè¾“å‡ºçš„ä»»ä½•å…¶ä»–è¾“å…¥å˜é‡
- Independence: A is independent of B when the following equality holds
  (i.e., B does not alter the probability that A has occurred):  
  ç‹¬ç«‹æ€§ï¼šå½“ä¸‹åˆ—ç­‰å¼æ—¶ï¼ŒA ç‹¬ç«‹äº B æˆç«‹ï¼ˆå³ B ä¸ä¼šæ”¹å˜ A å‘ç”Ÿçš„æ¦‚ç‡ï¼‰ï¼š  
  P(A|B) = P(A)

- Conditional independence: x<sub>1</sub> is conditionally independent
  of x<sub>2</sub> given y when the following equality holds  
  æ¡ä»¶ç‹¬ç«‹ï¼šx<sub>1</sub> æ¡ä»¶ç‹¬ç«‹äºç»™å®šçš„ x<sub>2</sub> y å½“ä¸‹åˆ—ç­‰å¼æˆç«‹æ—¶  
  P(x<sub>1</sub>|x<sub>2</sub>,y) = P(x<sub>1</sub>,y)

![Categorical Independent Variables_2.png](Images/Categorical%20Independent%20Variables_2.png)

- Summary
  - NaÃ¯ve Bayes Learning Algorithm  
    æœ´ç´ è´å¶æ–¯å­¦ä¹ ç®—æ³•
    - Create frequency tables for each independent variable and the
      corresponding values for the frequency of an event  
      ä¸ºæ¯ä¸ªè‡ªå˜é‡åˆ›å»ºé¢‘ç‡è¡¨å’Œäº‹ä»¶é¢‘ç‡çš„ç›¸åº”å€¼
    - Count the number of training examples of each class with each
      independent variable  
      ç”¨æ¯ä¸ªè‡ªå˜é‡è®¡ç®—æ¯ä¸ªç±»çš„è®­ç»ƒç¤ºä¾‹çš„æ•°é‡
    - Apply Laplace smoothing  
      åº”ç”¨æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘
  - NaÃ¯ve Bayes Model  
    æœ´ç´ è´å¶æ–¯æ¨¡å‹
    - Consists of the frequency tables obtained from Bayesâ€™ Theorem
      under the conditional independence assumption (with or without
      Laplace smoothing)  
      ç”±åœ¨æ¡ä»¶ç‹¬ç«‹å‡è®¾ä¸‹ï¼ˆæœ‰æ— æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼‰çš„è´å¶æ–¯å®šç†å¾—åˆ°çš„é¢‘ç‡è¡¨ç»„æˆ
  - NaÃ¯ve Bayes prediction for an instance (X=a, Y=?)  
    å¯¹ä¸€ä¸ªå®ä¾‹çš„æœ´ç´ è´å¶æ–¯é¢„æµ‹(X=aï¼ŒY=ï¼Ÿ)
    - We use Bayesâ€™ Theorem under the conditional independence
      assumption  
      æˆ‘ä»¬åœ¨æ¡ä»¶ç‹¬ç«‹å‡è®¾ä¸‹ä½¿ç”¨è´å¶æ–¯å®šç†

### 11.4 Naive Bayes for Numerical Independent Variables

- We use the frequency table for the categorical independent variables  
  æˆ‘ä»¬ä½¿ç”¨é¢‘ç‡è¡¨ä½œä¸ºåˆ†ç±»è‡ªå˜é‡
- We use the parameter table for the numerical independent variables  
  æˆ‘ä»¬ä½¿ç”¨å‚æ•°è¡¨çš„æ•°å€¼è‡ªå˜é‡

- Pros and Cons of NaÃ¯ve Bayes  
  æœ´ç´ è´å¶æ–¯ç†è®ºçš„åˆ©å¼Š
  - Pros
    - Easy to implement and fast to predict a class from training data
      (online learning)  
      æ˜“äºå®ç°å’Œå¿«é€Ÿåœ°ä»åŸ¹è®­æ•°æ®é¢„æµ‹ä¸€ä¸ªè¯¾ç¨‹ï¼ˆåœ¨çº¿å­¦ä¹ ï¼‰
    - Performs well in multi-class prediction  
      åœ¨å¤šç±»é¢„æµ‹ä¸­è¡¨ç°è‰¯å¥½
    - Good for categorical variables in general  
      ä¸€èˆ¬äºåˆ†ç±»å˜é‡
  - Cons
    - Data that are not observed require smoothing techniques to be
      applied  
      æ²¡æœ‰è§‚å¯Ÿåˆ°çš„æ•°æ®éœ€è¦åº”ç”¨å¹³æ»‘æŠ€æœ¯
    - For numerical variables, Gaussian distribution is assumed (strong
      assumption)  
      å¯¹äºæ•°å€¼å˜é‡ï¼Œå‡è®¾ä¸ºé«˜æ–¯åˆ†å¸ƒï¼ˆå¼ºå‡è®¾ï¼‰
    - Not good for regression problems  
      ä¸åˆ©äºå›å½’é—®é¢˜

## 12. K-Nearest Neighbours

### 12.1 Notation

- Probabilistic models  
  æ¦‚ç‡æ¨¡å‹
  - Variables are denoted by uppercase letters  
    å˜é‡ç”¨å¤§å†™å­—æ¯è¡¨ç¤º
  - Values that a variable can take are denoted by lowercase letters  
    ä¸€ä¸ªå˜é‡å¯ä»¥å–çš„å€¼ç”¨å°å†™å­—æ¯è¡¨ç¤º
  - Vectors are denoted by letters in bold  
    å‘é‡ç”¨ä»¥ç²—ä½“è¡¨ç¤ºçš„å­—æ¯è¡¨ç¤º

- Nonparametric Models  
  éå‚æ•°æ¨¡å‹
  - A nonparametric model is a model that cannot be characterised by a
    bounded set of parameters  
    éå‚æ•°æ¨¡å‹æ˜¯ä¸€ç§ä¸èƒ½ç”±ä¸€ç»„æœ‰ç•Œçš„å‚æ•°æ¥æè¿°çš„æ¨¡å‹
    - For instance, suppose that each prediction we make will consider
      all training examples, including the one from the previous
      prediction(s)  
      ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æ‰€åšçš„æ¯ä¸ªé¢„æµ‹éƒ½å°†è€ƒè™‘æ‰€æœ‰çš„è®­ç»ƒä¾‹å­ï¼ŒåŒ…æ‹¬å‰ä¸€ä¸ªé¢„æµ‹(s)
    - The set of examples grows over time, thus nonparametric  
      ä¸€ç»„ä¾‹å­éšç€æ—¶é—´çš„å¢é•¿ï¼Œå› æ­¤æ˜¯éå‚æ•°çš„
  - This approach is also called instance- or memory-based learning  
    è¿™ç§æ–¹æ³•ä¹Ÿè¢«ç§°ä¸ºåŸºäºå®ä¾‹æˆ–åŸºäºè®°å¿†çš„å­¦ä¹ 
    - The simplest method for instance-based learning is table lookup  
      åŸºäºå®ä¾‹çš„å­¦ä¹ ä¸­æœ€ç®€å•çš„æ–¹æ³•æ˜¯è¡¨æŸ¥æ‰¾
    - For table lookup, we put all training examples in a table, and
      when looking for a value, we return the corresponding value  
      å¯¹äºè¡¨æŸ¥æ‰¾ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰è®­ç»ƒç¤ºä¾‹æ”¾åœ¨ä¸€ä¸ªè¡¨ä¸­ï¼Œåœ¨å¯»æ‰¾ä¸€ä¸ªå€¼æ—¶ï¼Œæˆ‘ä»¬è¿”å›ç›¸åº”çš„å€¼
    - Problem: if the value does not exist, then a default value is
      returned  
      é—®é¢˜ï¼šå¦‚æœè¯¥å€¼ä¸å­˜åœ¨ï¼Œåˆ™è¿”å›ä¸€ä¸ªé»˜è®¤å€¼

### 12.2 k-Nearest Neighbour

![k-Nearest Neighbour_1.png](Images/k-Nearest%20Neighbour_1.png)

- Distance Metrics  
  è·ç¦»åº¦é‡
  - Consider a problem with n dimensions, x<sup>\[q\]</sup> being the
    new example  
    è€ƒè™‘ä¸€ä¸ªnç»´çš„é—®é¢˜ï¼Œx<sup>\[q\]</sup>æ˜¯ä¸€ä¸ªæ–°çš„ä¾‹å­
  - The Minkowski distance (or L<sup>p</sup> norm) is defined as  
    Minkowski è·ç¦»ï¼ˆæˆ– L<sup>p</sup> èŒƒæ•°ï¼‰å®šä¹‰ä¸º  
    ![k-Nearest Neighbour_2.png](Images/k-Nearest%20Neighbour_2.png)
  - In general, the Euclidean distance is used, namely when p = 2  
    ä¸€èˆ¬é‡‡ç”¨æ¬§å¼è·ç¦»ï¼Œå³p=2æ—¶  
    ![k-Nearest Neighbour_3.png](Images/k-Nearest%20Neighbour_3.png)

### 12.3 k-NN algorithm and pros/cons

- Input: training examples x<sup>\[i\]</sup> âˆˆ x and their corresponding
  class y<sup>\[i\]</sup> , a new query example x<sup>\[q\]</sup>,
  number of neighbours k  
  è¾“å…¥ï¼šè®­ç»ƒæ ·æœ¬ x<sup>\[i\]</sup> âˆˆ x åŠå…¶å¯¹åº”çš„ç±» y<sup>\[i\]</sup> ï¼Œ
  ä¸€ä¸ªæ–°çš„æŸ¥è¯¢ç¤ºä¾‹ x<sup>\[q\]</sup>ï¼Œé‚»å±…æ•° k
- Output: prediction of the new query example x<sup>\[q\]</sup>  
  è¾“å‡ºï¼šæ–°æŸ¥è¯¢ç¤ºä¾‹ x<sup>\[q\]</sup> çš„é¢„æµ‹
- For each training example x<sup>\[i\]</sup> âˆˆ x  
  å¯¹äºæ¯ä¸ªè®­ç»ƒæ ·ä¾‹ x<sup>\[i\]</sup> âˆˆ x
  - Calculate the distance between the training example
    x<sup>\[i\]</sup> and the new query example x<sup>\[q\]</sup>  
    è®¡ç®—è®­ç»ƒæ ·ä¾‹ x<sup>\[i\]</sup> ä¸æ–°æŸ¥è¯¢ä¹‹é—´çš„è·ç¦» ç¤ºä¾‹ x<sup>\[q\]</sup>
  - Keep the best k distances (the shortest distance) in a data
    structure T  
    åœ¨æ•°æ®ç»“æ„Tä¸­ä¿æŒæœ€ä½³çš„kä¸ªè·ç¦»ï¼ˆæœ€çŸ­çš„è·ç¦»ï¼‰
- Return the majority vote (or average/median) of the class
  y<sup>\[i\]</sup> for the first k entries of T  
  è¿”å›ç±» y<sup>\[i\]</sup> çš„å¤šæ•°ç¥¨ï¼ˆæˆ–å¹³å‡å€¼/ä¸­ä½æ•°ï¼‰ T çš„å‰ k ä¸ªæ¡ç›®

- Different numeric attributes may have different scales  
  ä¸åŒçš„æ•°å­—å±æ€§å¯èƒ½æœ‰ä¸åŒçš„å°ºåº¦
- For example, if x<sub>1</sub> is in \[0,1\] and x<sub>2</sub> is in
  \[1, 10\], x<sub>2</sub> will affect the distance more  
  ä¾‹å¦‚ï¼Œå¦‚æœ x<sub>1</sub> åœ¨ \[0,1\] ä¸­å¹¶ä¸” x<sub>2</sub> åœ¨ \[1, 10\]
  ä¸­ï¼Œåˆ™ x<sub>2</sub > ä¼šå½±å“ è·ç¦»æ›´å¤š
- To avoid this problem, we normalise the numeric input attributes of
  all data as in the following  
  ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†æ‰€æœ‰æ•°æ®çš„æ•°å€¼è¾“å…¥å±æ€§è¿›è¡Œè§„èŒƒåŒ–ï¼Œå¦‚ä¸‹æ‰€ç¤º  
  ![k-NN algorithm_1.png](Images/k-NN%20algorithm_1.png)
- Another approach (see book) is to calculate mean Î¼<sub>j</sub> and
  standard deviation Ïƒ<sub>j</sub> for each dimension j as:
  (x<sub>j</sub><sup>\[i\]</sup> âˆ’ Î¼<sub>j</sub>)/Ïƒ<sub>j</sub>  
  å¦ä¸€ç§æ–¹æ³•ï¼ˆè§ä¹¦ï¼‰æ˜¯è®¡ç®—å¹³å‡ Î¼<sub>j</sub> å’Œ æ¯ä¸ªç»´åº¦ j çš„æ ‡å‡†å·®
  Ïƒ<sub>j</sub> ä¸ºï¼š (x<sub>j</sub><sup>\[i\]</sup> -
  Î¼<sub>j</sub>)/Ïƒ<sub>j</sub>

- For numeric input attributes, e.g., age in \[0, 100\], we calculate
  the distance as shown in previous examples  
  å¯¹äºæ•°å€¼è¾“å…¥å±æ€§ï¼Œä¾‹å¦‚\[0,100\]ä¸­çš„å¹´é¾„ï¼Œæˆ‘ä»¬è®¡ç®—è·ç¦»å¦‚å‰é¢æ‰€ç¤ºæ‰€ç¤º
- For ordinal input attributes, e.g., sunny in {yes, no}, we can convert
  the values to numeric values: yes = 1, no = 0  
  å¯¹äºé¡ºåºè¾“å…¥å±æ€§ï¼Œä¾‹å¦‚ï¼Œé˜³å…‰åœ¨{æ˜¯ï¼Œå¦}ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›å€¼è½¬æ¢ä¸ºæ•°å€¼ï¼šæ˜¯çš„=1ï¼Œæ²¡æœ‰=0
- For categorical input attributes, e.g., phone_brand in {samsung,
  apple, nokia}, we can use the following approach:  
  å¯¹äºåˆ†ç±»è¾“å…¥å±æ€§ï¼Œä¾‹å¦‚ï¼Œåœ¨{ä¸‰æ˜Ÿã€è‹¹æœã€è¯ºåŸºäºš}ä¸­çš„phone_brandï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ï¼š
  - If the value of the query example is the same as the value for
    example i then their difference is 0. Formally, if
    x<sub>j</sub><sup>\[q\]</sup> = x<sub>j</sub><sup>\[i\]</sup> , then
    x<sub>j</sub><sup>\[q\]</sup> âˆ’ x<sub>j</sub><sup>\[i\]</sup> = 0  
    å¦‚æœæŸ¥è¯¢ç¤ºä¾‹çš„å€¼ä¸ ä¾‹å¦‚ i é‚£ä¹ˆå®ƒä»¬çš„å·®æ˜¯ 0ã€‚å½¢å¼ä¸Šï¼Œå¦‚æœ
    x<sub>j</sub><sup>\[q\]</sup> = x<sub>j</sub><sup>\[i\]</sup> ï¼Œç„¶å
    x<sub>j</sub><sup>\[q\]</sup> - x<sub>j</sub><sup>\[i\]</sup> = 0
  - Otherwise, their difference is 1. Formally, if
    x<sub>j</sub><sup>\[q\]</sup> â‰  x<sub>j</sub><sup>\[i\]</sup> , then
    x<sub>j</sub><sup>\[q\]</sup> âˆ’ x<sub>j</sub><sup>\[i\]</sup> = 1  
    å¦åˆ™ï¼Œå®ƒä»¬çš„å·®æ˜¯ 1ã€‚å½¢å¼ä¸Šï¼Œå¦‚æœ x<sub>j</sub><sup>\[q\]</sup> â‰ 
    x<sub>j</sub><sup>\[i\]</sup> ï¼Œç„¶å x<sub>j</sub><sup>\[q\]</sup> -
    x<sub>j</sub><sup>\[i\]</sup> = 1

### 12.4 Summary

- k-NN Learning Algorithm  
  K-NNå­¦ä¹ ç®—æ³•
  - The algorithm does not have proper training  
    è¯¥ç®—æ³•æ²¡æœ‰ç»è¿‡é€‚å½“çš„è®­ç»ƒ
  - We simply store all training data, which increase over time  
    æˆ‘ä»¬åªæ˜¯å­˜å‚¨æ‰€æœ‰çš„è®­ç»ƒæ•°æ®ï¼Œå®ƒä»¬ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œå¢åŠ 
  - We normalise by calculating the minimum and maximum in the training
    data  
    æˆ‘ä»¬é€šè¿‡è®¡ç®—è®­ç»ƒæ•°æ®ä¸­çš„æœ€å°å€¼å’Œæœ€å¤§å€¼æ¥è¿›è¡Œå½’ä¸€åŒ–

- k-NN Model  
  k-NNæ¨¡å‹
  - All training data, the values of the numeric input attributes  
    æ‰€æœ‰çš„è®­ç»ƒæ•°æ®ï¼Œæ•°å€¼è¾“å…¥å±æ€§çš„å€¼

- k-NN prediction for an instance (x<sup>\[i\]</sup>, y = ?)  
  å®ä¾‹çš„ k-NN é¢„æµ‹ (x<sup>\[i\]</sup>, y = ?)
  - Find the k nearest neighbours whose distance to x<sup>\[i\]</sup> is
    the smallest  
    æ‰¾åˆ°åˆ° x<sup>\[i\]</sup> è·ç¦»æœ€å°çš„ k ä¸ªæœ€è¿‘é‚»
  - For classification problems, majority vote. For regression problems,
    average/median  
    å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œå¤šæ•°æŠ•ç¥¨ã€‚å¯¹äºå›å½’é—®é¢˜ï¼Œå¹³å‡å€¼/ä¸­å€¼

- Pros
  - Training is simple and fast: just store training data  
    åŸ¹è®­éå¸¸ç®€å•è€Œå¿«é€Ÿï¼šåªéœ€å­˜å‚¨åŸ¹è®­æ•°æ®
  - Find the class of the new example based on most similar examples
    present in the training data  
    æ ¹æ®è®­ç»ƒæ•°æ®ä¸­æœ€ç›¸ä¼¼çš„ä¾‹å­æ‰¾åˆ°æ–°ä¾‹å­çš„ç±»

- Cons
  - It uses large space in memory: we need to store all data  
    å®ƒä½¿ç”¨äº†å¾ˆå¤§çš„å†…å­˜ç©ºé—´ï¼šæˆ‘ä»¬éœ€è¦å­˜å‚¨æ‰€æœ‰çš„æ•°æ®
  - Running the algorithm can be slow if we have many training examples
    and many dimensions  
    å¦‚æœæˆ‘ä»¬æœ‰å¾ˆå¤šè®­ç»ƒä¾‹å­å’Œè®¸å¤šç»´åº¦ï¼Œè¿è¡Œç®—æ³•å¯èƒ½ä¼šå¾ˆæ…¢

## 13. Uninformed Search

### 13.1 Asymptotic Analysis

- Benchmarking is one approach  
  åŸºå‡†æµ‹è¯•æ˜¯ä¸€ç§æ–¹æ³•
  - We run the algorithms and we measure speed (in seconds) and memory
    consumption (in bytes)  
    æˆ‘ä»¬è¿è¡Œè¿™äº›ç®—æ³•ï¼Œå¹¶æµ‹é‡é€Ÿåº¦ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰å’Œå†…å­˜æ¶ˆè€—ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰
  - Problem: this approach measures the performance of a specific
    program written in a particular language, on a given computer, with
    particular input data  
    é—®é¢˜ï¼šè¿™ç§æ–¹æ³•æµ‹é‡åœ¨ç‰¹å®šçš„è®¡ç®—æœºä¸Šç”¨ç‰¹å®šè¯­è¨€ç¼–å†™çš„ç‰¹å®šç¨‹åºçš„æ€§èƒ½
- Asymptotic analysis is the second approach:  
  æ¸è¿‘åˆ†ææ˜¯ç¬¬äºŒç§æ–¹æ³•ï¼š
  - It is a mathematical abstraction over both the exact number of
    operations (by ignoring constant factors) and exact content of the
    input (by considering the size of the input, only)  
    å®ƒæ˜¯å¯¹æ“ä½œçš„ç²¾ç¡®æ•°é‡ï¼ˆé€šè¿‡å¿½ç•¥å¸¸æ•°å› å­ï¼‰å’Œè¾“å…¥çš„ç²¾ç¡®å†…å®¹ï¼ˆä»…é€šè¿‡è€ƒè™‘è¾“å…¥çš„å¤§å°ï¼‰çš„ä¸€ç§æ•°å­¦æŠ½è±¡
  - It is independent of the particular implementation and input  
    å®ƒç‹¬ç«‹äºç‰¹å®šçš„å®ç°å’Œè¾“å…¥

- The first step in the analysis is to abstract over the input. In
  practice, we characterise the size of the input, which we call n  
  åˆ†æçš„ç¬¬ä¸€æ­¥æ˜¯å¯¹è¾“å…¥è¿›è¡ŒæŠ½è±¡ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬ è¡¨å¾è¾“å…¥çš„å¤§å°ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º n
- The second step is to abstract over the implementation. The idea is to
  find some measure that reflects the running time of the algorithm  
  ç¬¬äºŒæ­¥æ˜¯æŠ½è±¡çš„å®ç°ã€‚å…¶æƒ³æ³•æ˜¯ä¸ºäº†æ‰¾åˆ°ä¸€äº›åæ˜ ç®—æ³•è¿è¡Œæ—¶é—´çš„åº¦é‡æ–¹æ³•
- For asymptotic analysis, we typically use 3 notations:  
  å¯¹äºæ¸è¿‘åˆ†æï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨3ç§ç¬¦å·ï¼š
  - Big O notation: O(Â·)
  - Big Omega notation: Î©(Â·)
  - Big Theta notation: Î¸(Â·)

- Big O
  - We say that f(n) âˆˆ O(g(n)) when the following condition holds:  
    å½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼Œæˆ‘ä»¬è¯´ f(n) âˆˆ O(g(n))ï¼š  
    ![Asymtotic Analysis_1.png](Images/Asymtotic%20Analysis_1.png)
  - The above reads: â€œThere exists a positive constant k such that for
    all n>n<sub>0</sub>, |f(n)|â‰¤ kâ‹… g(n)â€  
    ä¸Šé¢å†™ç€ï¼šâ€œå­˜åœ¨ä¸€ä¸ªæ­£å¸¸æ•° kï¼Œä½¿å¾—å¯¹äºæ‰€æœ‰ n>n<sub>0</sub>, |f(n)|â‰¤ kâ‹… g(n)â€
  - In simple terms, this is equivalent to saying that |f| is bounded
    above by a function g(up to a constant factor) asymptotically  
    ç®€å•æ¥è¯´ï¼Œè¿™ç›¸å½“äºè¯´ |f|æœ‰ç•Œä»¥ä¸Š ç”±å‡½æ•° gï¼ˆç›´åˆ°ä¸€ä¸ªå¸¸æ•°å› å­ï¼‰æ¸è¿‘

- Big Theta and Big Omega
  - We say that f(n) âˆˆ Î©(g(n)) when the following condition holds:  
    å½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼Œæˆ‘ä»¬è¯´ f(n) âˆˆ Î©(g(n))  
    ![Asymtotic Analysis_2.png](Images/Asymtotic%20Analysis_2.png)
  - This is equivalent to saying that f is bounded below by g
    asymptotically  
    è¿™ç›¸å½“äºè¯´ f æ¸è¿‘åœ°è¢« g åŒ…å›´
  - We say that f(n) âˆˆ Î¸(g(n)) when the following condition holds:  
    å½“ä»¥ä¸‹æ¡ä»¶æˆç«‹æ—¶ï¼Œæˆ‘ä»¬è¯´ f(n) âˆˆ Î¸(g(n))  
    ![Asymtotic Analysis_3.png](Images/Asymtotic%20Analysis_3.png)
  - Or f is bounded both above and below by g asymptotically  
    æˆ–è€… f åœ¨ä¸Šé¢å’Œä¸‹é¢éƒ½ä»¥ g æ¸è¿‘ä¸ºç•Œ

- Summary
  - Asymptotic analysis is a powerful tool to describe the speed and
    memory consumption of an algorithm  
    æ¸è¿‘åˆ†ææ˜¯æè¿°ç®—æ³•çš„é€Ÿåº¦å’Œå†…å­˜æ¶ˆè€—çš„æœ‰åŠ›å·¥å…·
  - It is useful as it is independent of a particular implementation and
    input  
    å®ƒæ˜¯æœ‰ç”¨çš„ï¼Œå› ä¸ºå®ƒç‹¬ç«‹äºç‰¹å®šçš„å®ç°å’Œè¾“å…¥
  - It is an approximation as the input n approaches infinity and over
    the number of steps required  
    å®ƒæ˜¯ä¸€ä¸ªè¿‘ä¼¼å€¼ï¼Œå› ä¸ºè¾“å…¥ n æ¥è¿‘æ— ç©·å¤§å¹¶ä¸”è¶…è¿‡æ‰€éœ€æ­¥éª¤æ•°
  - Convenient to compare algorithms, e.g., an O(n) algorithm is better
    than an O(n<sup>2</sup>) algorithm  
    ä¾¿äºæ¯”è¾ƒç®—æ³•ï¼Œä¾‹å¦‚ O(n) ç®—æ³•æ›´å¥½ æ¯” O(n<sup>2</sup>) ç®—æ³•

- An algorithm that works on a tree data structure stores a node for
  each element of the input at most once. The space complexity for this
  algorithm is therefore O(n).  
  ä¸€ç§é€‚ç”¨äºæ ‘æ•°æ®ç»“æ„çš„ç®—æ³•æœ€å¤šä¸ºè¾“å…¥çš„æ¯ä¸ªå…ƒç´ å­˜å‚¨ä¸€ä¸ªèŠ‚ç‚¹ã€‚å› æ­¤ï¼Œè¯¥ç®—æ³•çš„ç©ºé—´å¤æ‚åº¦ä¸º
  O(n)ã€‚
- The Big O notation provides an upper bound in the asymptotic limit.  
  å¤§ O è¡¨ç¤ºæ³•æä¾›äº†æ¸è¿‘æé™çš„ä¸Šé™
- For an algorithm that performs 2n+n<sup>2</sup> operations, the time
  complexity is O(n<sup>2</sup>).  
  å¯¹äºæ‰§è¡Œ 2n+n<sup>2</sup> æ¬¡æ“ä½œçš„ç®—æ³•ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º O(n<sup>2</sup>)
- The Big Theta notation provides an upper and lower bound in the
  asymptotic limit.  
  Big Theta è¡¨ç¤ºæ³•æä¾›äº†æ¸è¿‘æé™çš„ä¸Šé™å’Œä¸‹é™

- What is(are) the main advantage(s) in using asymptotic analysis rather
  than benchmarking?  
  ä½¿ç”¨æ¸è¿‘åˆ†æè€Œä¸æ˜¯åŸºå‡†æµ‹è¯•çš„ä¸»è¦ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
  - It is independent of any particular programming language.  
    å®ƒç‹¬ç«‹äºä»»ä½•ç‰¹å®šçš„ç¼–ç¨‹è¯­è¨€
  - It is independent of any particular data structures used to run the
    algorithm.  
    å®ƒç‹¬ç«‹äºç”¨äºè¿è¡Œç®—æ³•çš„ä»»ä½•ç‰¹å®šæ•°æ®ç»“æ„


### 13.2 Search Problem Formulation

- Problem-Solving Agents  
  è§£å†³é—®é¢˜çš„ä»£ç†
  - An agent is something that perceives and acts in an environment  
    ä»£ç†æ˜¯æŒ‡åœ¨ä¸€ä¸ªç¯å¢ƒä¸­è¿›è¡Œæ„ŸçŸ¥å’Œèµ·ä½œç”¨çš„ä¸œè¥¿
  - A problem-solving agent  
    è§£å†³é—®é¢˜çš„ä»£ç†
    - Uses atomic representations (each state of the world is perceived
      as indivisible)  
      ä½¿ç”¨åŸå­è¡¨ç¤ºæ³•ï¼ˆä¸–ç•Œä¸Šçš„æ¯ä¸ªçŠ¶æ€éƒ½è¢«è®¤ä¸ºæ˜¯ä¸å¯åˆ†å‰²çš„ï¼‰
    - Requires a precise definition of the problem and its goal/solution  
      éœ€è¦å¯¹é—®é¢˜åŠå…¶ç›®æ ‡/è§£å†³æ–¹æ¡ˆçš„ç²¾ç¡®å®šä¹‰

- Problem formulation is the process of deciding what actions and states
  to consider, given a goal  
  é—®é¢˜è¡¨è¿°æ˜¯å†³å®šåœ¨ç»™å®šç›®æ ‡ä¸‹è¦è€ƒè™‘ä»€ä¹ˆè¡ŒåŠ¨å’ŒçŠ¶æ€çš„è¿‡ç¨‹
- To this end, we make the following assumptions about the environment:  
  ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¯¹ç¯å¢ƒåšå‡ºäº†ä»¥ä¸‹å‡è®¾ï¼š
  - Observable, i.e., the agent knows the current state  
    å¯è§‚å¯Ÿçš„ï¼Œå³ä»£ç†çŸ¥é“å½“å‰çŠ¶æ€
  - Discrete, i.e., there are only finitely many actions at any state  
    ç¦»æ•£çš„ï¼Œå³åœ¨ä»»ä½•çŠ¶æ€ä¸‹åªæœ‰æœ‰é™å¤šçš„åŠ¨ä½œ
  - Known, i.e., the agent knows which states are reached by each action  
    å·²çŸ¥çš„ï¼Œå³ï¼Œä»£ç†çŸ¥é“æ¯ä¸ªåŠ¨ä½œéƒ½è¾¾åˆ°äº†å“ªäº›çŠ¶æ€
  - Deterministic, i.e., each action has exactly one outcome  
    ç¡®å®šæ€§çš„ï¼Œå³æ¯ä¸ªåŠ¨ä½œéƒ½æœ‰ä¸€ä¸ªç»“æœ
- Under these assumptions, the solution to any problem is a fixed
  sequence of actions  
  åœ¨è¿™äº›å‡è®¾ä¸‹ï¼Œä»»ä½•é—®é¢˜çš„è§£å†³æ–¹æ¡ˆéƒ½æ˜¯ä¸€ä¸ªå›ºå®šçš„è¡ŒåŠ¨åºåˆ—

- The agentâ€™s task is to find out how to act, now and in the future, in
  order to reach a goal state: namely to determine a sequence of actions  
  ä»£ç†çš„ä»»åŠ¡æ˜¯æ‰¾å‡ºç°åœ¨å’Œå°†æ¥å¦‚ä½•è¡ŒåŠ¨ï¼Œä»¥è¾¾åˆ°ä¸€ä¸ªç›®æ ‡çŠ¶æ€ï¼šå³ç¡®å®šä¸€ç³»åˆ—çš„è¡ŒåŠ¨
- The process of looking for a sequence of actions is called search
  å¯»æ‰¾ä¸€ç³»åˆ—åŠ¨ä½œçš„è¿‡ç¨‹è¢«ç§°ä¸ºæœç´¢
- A solution to a search problem is the sequence of actions from the
  initial state to the goal state  
  æœç´¢é—®é¢˜çš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä»åˆå§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„åŠ¨ä½œåºåˆ—

- A problem is defined formally by five components:  
  ä¸€ä¸ªé—®é¢˜çš„æ­£å¼å®šä¹‰ä¸ºä»¥ä¸‹äº”ä¸ªç»„æˆéƒ¨åˆ†ï¼š
  - Initial state, i.e., the state that the agent starts in  
    åˆå§‹çŠ¶æ€ï¼Œå³ä»£ç†å¼€å§‹æ—¶çš„çŠ¶æ€
  - Actions, i.e., a description of all possible actions that can be
    executed in a given state s  
    æ“ä½œï¼Œå³å¯¹åœ¨ç»™å®šçŠ¶æ€ä¸‹å¯ä»¥æ‰§è¡Œçš„æ‰€æœ‰å¯èƒ½æ“ä½œçš„æè¿°
  - Transition model, i.e., the states resulting from executing each
    action a from every state s (a description of what each action does)  
    è½¬æ¢æ¨¡å‹ï¼Œå³ä»æ¯ä¸ªçŠ¶æ€sä¸­æ‰§è¡Œæ¯ä¸ªåŠ¨ä½œaæ‰€äº§ç”Ÿçš„çŠ¶æ€ï¼ˆå¯¹æ¯ä¸ªåŠ¨ä½œæ‰§è¡Œä»€ä¹ˆçš„æè¿°ï¼‰
  - Goal test to determine if a state is a goal state  
    ç›®æ ‡æµ‹è¯•ï¼Œä»¥ç¡®å®šä¸€ä¸ªçŠ¶æ€æ˜¯å¦ä¸ºç›®æ ‡çŠ¶æ€
  - Path cost function that assigns a value (cost) to each path  
    ä¸ºæ¯ä¸ªè·¯å¾„åˆ†é…ä¸€ä¸ªå€¼ï¼ˆæˆæœ¬ï¼‰çš„è·¯å¾„æˆæœ¬å‡½æ•°
- The first three components considered together define the state space
  of the problem, in the form of a directed graph or network  
  å‰ä¸‰ä¸ªåˆ†é‡ä¸€èµ·è€ƒè™‘ï¼Œä»¥æœ‰å‘å›¾æˆ–ç½‘ç»œçš„å½¢å¼å®šä¹‰äº†é—®é¢˜çš„çŠ¶æ€ç©ºé—´
- A path in the state space is a sequence of states connected by a
  sequence of actions  
  çŠ¶æ€ç©ºé—´ä¸­çš„è·¯å¾„æ˜¯ç”±ä¸€ç³»åˆ—åŠ¨ä½œè¿æ¥çš„çŠ¶æ€åºåˆ—

![Search Problem Formulation_1.png](Images/Search%20Problem%20Formulation_1.png)  
![Search Problem Formulation_2.png](Images/Search%20Problem%20Formulation_2.png)  
![Search Problem Formulation_3.png](Images/Search%20Problem%20Formulation_3.png)  
![Search Problem Formulation_4.png](Images/Search%20Problem%20Formulation_4.png)

- A problem-solving agent is an agent that is able to search for a
  solution in a given problem  
  è§£å†³é—®é¢˜çš„ä»£ç†æ˜¯æŒ‡èƒ½å¤Ÿåœ¨ç»™å®šçš„é—®é¢˜ä¸­å¯»æ‰¾è§£å†³æ–¹æ¡ˆçš„ä»£ç†
- Problem formulation, namely the process of deciding what actions and
  states to consider, given a goal  
  é—®é¢˜åˆ¶å®šï¼Œå³å†³å®šåœ¨ç»™å®šç›®æ ‡æ—¶è€ƒè™‘ä»€ä¹ˆè¡ŒåŠ¨å’ŒçŠ¶æ€çš„è¿‡ç¨‹

- A solution of a given search problem is a sequence of actions that
  takes us from the initial state to the goal state.  
  ç»™å®šæœç´¢é—®é¢˜çš„è§£å†³æ–¹æ¡ˆæ˜¯ä¸€ç³»åˆ—å°†æˆ‘ä»¬ä»åˆå§‹çŠ¶æ€å¸¦åˆ°ç›®æ ‡çŠ¶æ€çš„åŠ¨ä½œ
- A goal state is just a state to show us what a solved task looks like.  
  ç›®æ ‡çŠ¶æ€åªæ˜¯å‘æˆ‘ä»¬å±•ç¤ºå·²è§£å†³ä»»åŠ¡æ˜¯ä»€ä¹ˆæ ·å­çš„çŠ¶æ€
- The cost function evaluates the cost of the solution that takes us
  from the initial state to a goal state, i.e., the cost of the path
  from the initial state to a goal state.  
  æˆæœ¬å‡½æ•°è¯„ä¼°å°†æˆ‘ä»¬ä»åˆå§‹çŠ¶æ€å¸¦åˆ°ç›®æ ‡çŠ¶æ€çš„è§£å†³æ–¹æ¡ˆçš„æˆæœ¬ï¼Œå³ä»åˆå§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€çš„è·¯å¾„æˆæœ¬
- The problem formulation (initial state, goal state(s), possible
  actions and their effects on states, and cost function) is the only
  thing that the search algorithm needs as the input for uninformed
  search algorithms.  
  é—®é¢˜è¡¨è¿°ï¼ˆåˆå§‹çŠ¶æ€ã€ç›®æ ‡çŠ¶æ€ã€å¯èƒ½çš„åŠ¨ä½œåŠå…¶å¯¹çŠ¶æ€çš„å½±å“ä»¥åŠæˆæœ¬å‡½æ•°ï¼‰æ˜¯æœç´¢ç®—æ³•å”¯ä¸€éœ€è¦ä½œä¸ºä¸çŸ¥æƒ…æœç´¢ç®—æ³•çš„è¾“å…¥çš„ä¸œè¥¿

### 13.3 Breadth-First Search

- A solution is an action sequence from an initial state to a goal state  
  ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯ä¸€ä¸ªä»ä¸€ä¸ªåˆå§‹çŠ¶æ€åˆ°ä¸€ä¸ªç›®æ ‡çŠ¶æ€çš„åŠ¨ä½œåºåˆ—
- Possible action sequences form a search tree with initial state at the
  root; actions are the branches and nodes correspond to the state space  
  å¯èƒ½çš„åŠ¨ä½œåºåˆ—å½¢æˆä¸€ä¸ªåœ¨æ ¹å¤„æœ‰åˆå§‹çŠ¶æ€çš„æœç´¢æ ‘ï¼›åŠ¨ä½œæ˜¯ä¸çŠ¶æ€ç©ºé—´å¯¹åº”çš„åˆ†æ”¯å’ŒèŠ‚ç‚¹
- The idea is to expand the current state by applying each possible
  action: this generates a new set of states  
  å…¶æƒ³æ³•æ˜¯é€šè¿‡åº”ç”¨æ¯ä¸€ä¸ªå¯èƒ½çš„åŠ¨ä½œæ¥æ‰©å±•å½“å‰çŠ¶æ€ï¼šè¿™å°†ç”Ÿæˆä¸€ç»„æ–°çš„çŠ¶æ€

- Uninformed search (also called blind search) means that the strategies
  have no additional information about states beyond that provided in
  the problem definition  
  æ— çŸ¥æœç´¢ï¼ˆä¹Ÿç§°ä¸ºç›²æœç´¢ï¼‰æ„å‘³ç€é™¤äº†é—®é¢˜å®šä¹‰ä¸­æä¾›çš„ä¿¡æ¯ä¹‹å¤–ï¼Œç­–ç•¥æ²¡æœ‰å…³äºçŠ¶æ€çš„é¢å¤–ä¿¡æ¯
- Uninformed search strategies can only generate successors and
  distinguish a goal state from a non-goal state  
  ä¸çŸ¥æƒ…çš„æœç´¢ç­–ç•¥åªèƒ½ç”Ÿæˆåç»§è€…ï¼Œå¹¶åŒºåˆ†ç›®æ ‡çŠ¶æ€å’Œéç›®æ ‡çŠ¶æ€
- The key difference between two uninformed search strategies is the
  order in which nodes are expanded  
  ä¸¤ç§ä¸çŸ¥æƒ…çš„æœç´¢ç­–ç•¥ä¹‹é—´çš„å…³é”®åŒºåˆ«æ˜¯èŠ‚ç‚¹è¢«æ‰©å±•çš„é¡ºåº

- Breadth-First search is one of the most common search strategies:  
  å¹¿åº¦-ä¼˜å…ˆæœç´¢æ˜¯æœ€å¸¸è§çš„æœç´¢ç­–ç•¥ä¹‹ä¸€ï¼š
  - The root node is expanded first  
    é¦–å…ˆå±•å¼€æ ¹èŠ‚ç‚¹
  - Then, all the successors of the root node are expanded  
    ç„¶åï¼Œå±•å¼€æ ¹èŠ‚ç‚¹çš„æ‰€æœ‰åç»§èŠ‚ç‚¹
  - Then, the successors of each of these nodes  
    ç„¶åï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„åç»§è€…
- In general, the frontier nodes that are expanded belong to a given
  depth of the tree  
  ä¸€èˆ¬æ¥è¯´ï¼Œè¢«æ‰©å±•çš„è¾¹ç•ŒèŠ‚ç‚¹å±äºæ ‘çš„ç»™å®šæ·±åº¦
- This is equivalent to expanding the shallowest unexpanded node in the
  frontier; simply use a queue (FIFO) for expansion  
  è¿™ç›¸å½“äºåœ¨è¾¹ç•Œä¸­æ‰©å±•æœ€æµ…çš„æœªæ‰©å±•èŠ‚ç‚¹ï¼›åªéœ€ä½¿ç”¨ä¸€ä¸ªé˜Ÿåˆ—(FIFO)æ¥è¿›è¡Œæ‰©å±•

- We can evaluate the performance of an algorithm based on the
  following:  
  æˆ‘ä»¬å¯ä»¥æ ¹æ®ä»¥ä¸‹æ–¹æ³•æ¥è¯„ä¼°ä¸€ä¸ªç®—æ³•çš„æ€§èƒ½ï¼š
  - Completeness, i.e., whether the algorithm is guaranteed to find a
    solution if there is one  
    å®Œæ•´æ€§ï¼Œå³å¦‚æœæœ‰è§£ï¼Œç®—æ³•æ˜¯å¦ä¿è¯æ‰¾åˆ°è§£
  - Optimality, i.e., whether the strategy is able to find the optimal
    solution  
    æœ€ä¼˜æ€§ï¼Œå³è¯¥ç­–ç•¥æ˜¯å¦èƒ½å¤Ÿæ‰¾åˆ°æœ€ä¼˜è§£
  - Time complexity, i.e., the time the algorithm takes to find a
    solution  
    æ—¶é—´å¤æ‚åº¦ï¼Œå³ç®—æ³•æ‰¾åˆ°è§£å†³æ–¹æ¡ˆæ‰€éœ€çš„æ—¶é—´
  - Space complexity, i.e., the memory used to perform the search  
    ç©ºé—´å¤æ‚æ€§ï¼Œå³ç”¨äºæ‰§è¡Œæœç´¢çš„å†…å­˜
- To measure the performance, the size of the space graph is typically
  used, i.e., |V|+ |â„°|, the set of vertices and set of edges,
  respectively  
  ä¸ºäº†è¡¡é‡æ€§èƒ½ï¼Œç©ºé—´å›¾çš„å¤§å°é€šå¸¸æ˜¯ ä½¿ç”¨ï¼Œå³|V|+ |â„°|ï¼Œåˆ†åˆ«æ˜¯é¡¶ç‚¹é›†å’Œè¾¹é›†

- In AI, we use an implicit representation of the graph via the initial
  state, actions and transition model (also the graph could be infinite)  
  åœ¨äººå·¥æ™ºèƒ½ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆå§‹çŠ¶æ€ã€åŠ¨ä½œå’Œè¿‡æ¸¡æ¨¡å‹ï¼ˆå›¾ä¹Ÿå¯ä»¥æ˜¯æ— é™çš„ï¼‰æ¥ä½¿ç”¨å›¾çš„éšå¼è¡¨ç¤º
- Therefore, the following three quantities are used  
  å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä»¥ä¸‹ä¸‰ä¸ªé‡
  - Branching factor, the maximum number of successors of each node: b  
    åˆ†æ”¯å› å­ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„æœ€å¤§åç»§æ•°ï¼šb
  - Depth of the shallowest goal node (number of steps from the root): d  
    æœ€æµ…ç›®æ ‡èŠ‚ç‚¹çš„æ·±åº¦ï¼ˆè·æ ¹çš„æ­¥æ•°ï¼‰ï¼šd
  - The maximum length of any path in the state space: m  
    çŠ¶æ€ç©ºé—´ä¸­ä»»æ„è·¯å¾„çš„æœ€å¤§é•¿åº¦ï¼šm

- Let us evaluate the performance of the breadth-first search algorithm  
  è®©æˆ‘ä»¬æ¥è¯„ä¼°å®½åº¦ä¼˜å…ˆæœç´¢ç®—æ³•çš„æ€§èƒ½
  - Completeness: if the goal node is at some finite depth d then the
    BFS algorithm is complete as it will find it (given that b is
    finite)  
    å®Œæ•´æ€§ï¼šå¦‚æœç›®æ ‡èŠ‚ç‚¹åœ¨æŸä¸ªæœ‰é™æ·±åº¦ d å¤„ï¼Œåˆ™ BFSç®—æ³•æ˜¯å®Œæ•´çš„ï¼Œå› ä¸ºå®ƒä¼šæ‰¾åˆ°å®ƒï¼ˆå‡è®¾
    b æ˜¯æœ‰é™çš„ï¼‰
  - Optimality: BFS is optimal if the path cost is a nondecreasing
    function of the depth of the node (e.g., all actions have the same
    cost)  
    æœ€ä¼˜æ€§ï¼šå¦‚æœè·¯å¾„ä»£ä»·æ˜¯èŠ‚ç‚¹æ·±åº¦çš„éé€’å‡å‡½æ•°ï¼ˆä¾‹å¦‚ï¼Œæ‰€æœ‰çš„åŠ¨ä½œéƒ½å…·æœ‰ç›¸åŒçš„ä»£ä»·ï¼‰ï¼Œåˆ™BFSæ˜¯æœ€ä¼˜çš„
  - Time complexity: O(b<sup>d</sup>), assuming a uniform tree where
    each node has b successors, we generate b+ b<sup>2</sup> + â‹¯ +
    b<sup>d</sup> = O(b<sup>d</sup>)  
    æ—¶é—´å¤æ‚åº¦ï¼šO(b<sup>d</sup>)ï¼Œå‡è®¾ä¸€æ£µç»Ÿä¸€æ ‘ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹æœ‰bä¸ªåç»§è€…ï¼Œæˆ‘ä»¬ç”Ÿæˆb+
    b<sup>2</sup> +â‹¯ + b<sup>d</sup > = O(b<sup>d</sup>)
  - Space complexity: O(b<sup>d</sup>), if we store all expanded nodes,
    we have O(b<sup>d-1</sup>) explored nodes in memory and
    O(b<sup>d</sup>) in the frontier  
    ç©ºé—´å¤æ‚åº¦ï¼šO(b<sup>d</sup>)ï¼Œå¦‚æœæˆ‘ä»¬å­˜å‚¨æ‰€æœ‰æ‰©å±•èŠ‚ç‚¹ï¼Œæˆ‘ä»¬åœ¨å†…å­˜ä¸­æœ‰
    O(b<sup>d-1</sup>) ä¸ªæ¢ç´¢èŠ‚ç‚¹å’Œ O(b<sup> d</sup>) åœ¨è¾¹å¢ƒ

- Summary
  - Uninformed tree search strategies have no additional information  
    ä¸çŸ¥æƒ…çš„æ ‘æœç´¢ç­–ç•¥æ²¡æœ‰é¢å¤–çš„ä¿¡æ¯
  - Breadth-First Search is a search algorithm that expands the nodes in
    the frontier starting from the shallowest, similar to a queue (FIFO)  
    å¹¿åº¦ä¼˜å…ˆæœç´¢æ˜¯ä¸€ç§æœç´¢ç®—æ³•ï¼Œå®ƒä»æœ€æµ…çš„èŠ‚ç‚¹å¼€å§‹æ‰©å±•è¾¹ç•Œä¸­çš„èŠ‚ç‚¹ï¼Œç±»ä¼¼äºé˜Ÿåˆ—(FIFO)
  - This algorithm is complete (for finite b, optimal (if the path cost
    is nondecreasing), but it has high time and space complexity
    O(b<sup>d</sup>)  
    è¿™ä¸ªç®—æ³•æ˜¯å®Œå¤‡çš„ï¼ˆå¯¹äºæœ‰é™çš„bï¼Œæœ€ä¼˜çš„ï¼ˆå¦‚æœè·¯å¾„æˆæœ¬æ˜¯éé€’å‡çš„ï¼‰ï¼Œä½†æ˜¯å®ƒçš„æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦é«˜O(b<sup>d</sup>)

![Breath-first Search_1.png](Images/Breath-first%20Search_1.png)

### 13.4 Depth-First Search

- Depth-First search is another common search strategy:  
  æ·±åº¦ä¼˜å…ˆæœç´¢æ˜¯å¦ä¸€ç§å¸¸è§çš„æœç´¢ç­–ç•¥ï¼š
  - The root node is expanded first  
    é¦–å…ˆå±•å¼€æ ¹èŠ‚ç‚¹
  - Then, the first (or one at random) successor of the root node is
    expanded  
    ç„¶åï¼Œå±•å¼€æ ¹èŠ‚ç‚¹çš„ç¬¬ä¸€ä¸ªï¼ˆæˆ–éšæœºçš„ä¸€ä¸ªï¼‰åç»§è€…
  - Then, the deepest node in the current frontier is expanded  
    ç„¶åï¼Œæ‰©å±•å½“å‰è¾¹ç•Œä¸­æœ€æ·±çš„èŠ‚ç‚¹
- This is equivalent to expanding the deepest unexpanded node in the
  frontier; simply use a stack (LIFO) for expansion  
  è¿™ç›¸å½“äºåœ¨è¾¹ç•Œä¸­æ‰©å±•æœ€æ·±çš„æœªæ‰©å±•èŠ‚ç‚¹ï¼›åªéœ€ä½¿ç”¨ä¸€ä¸ªå †æ ˆ(LIFO)æ¥è¿›è¡Œæ‰©å±•
- Basically, the most recently generated node is chosen for expansion  
  åŸºæœ¬ä¸Šï¼Œé€‰æ‹©æœ€è¿‘ç”Ÿæˆçš„èŠ‚ç‚¹è¿›è¡Œæ‰©å±•

- Let us evaluate the performance of the depth-first search algorithm  
  è®©æˆ‘ä»¬æ¥è¯„ä¼°æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•çš„æ€§èƒ½
  - Completeness: DFS is not complete if the search space is infinite or
    if we do not check infinite loops; it is complete if the search
    space is finite  
    å®Œæ•´æ€§ï¼šå¦‚æœæœç´¢ç©ºé—´æ˜¯æ— é™çš„ï¼Œæˆ–è€…æˆ‘ä»¬ä¸æ£€æŸ¥æ— é™çš„å¾ªç¯ï¼Œé‚£ä¹ˆDFSå°±ä¸å®Œæ•´äº†ï¼›å¦‚æœæœç´¢ç©ºé—´æ˜¯æœ‰é™çš„ï¼Œé‚£ä¹ˆå®ƒæ˜¯å®Œæ•´çš„
  - Optimality: DFS is not optimal as it can expand a left subtree when
    the goal node is in the first level of the right subtree  
    æœ€ä¼˜æ€§ï¼šDFSä¸æ˜¯æœ€ä¼˜çš„ï¼Œå› ä¸ºå½“ç›®æ ‡èŠ‚ç‚¹åœ¨å³å­æ ‘çš„ç¬¬ä¸€å±‚æ—¶ï¼Œå®ƒå¯ä»¥å±•å¼€ä¸€ä¸ªå·¦å­æ ‘
  - Time complexity: O(b<sup>m</sup>), as it depends on the maximum
    length of the path in the search space (in general m can be much
    larger than d)  
    æ—¶é—´å¤æ‚åº¦ï¼šO(b<sup>m</sup>)ï¼Œå› ä¸ºå®ƒå–å†³äºæœç´¢ç©ºé—´ä¸­è·¯å¾„çš„æœ€å¤§é•¿åº¦ï¼ˆé€šå¸¸ m
    å¯ä»¥è¿œå¤§äº dï¼‰
  - Space complexity: O(b<sup>m</sup>), as we store all the nodes from
    each path from the root node to the leaf node  
    ç©ºé—´å¤æ‚åº¦ï¼šO(b<sup>m</sup>)ï¼Œå› ä¸ºæˆ‘ä»¬å­˜å‚¨ä»æ ¹èŠ‚ç‚¹åˆ°å¶èŠ‚ç‚¹çš„æ¯æ¡è·¯å¾„çš„æ‰€æœ‰èŠ‚ç‚¹

- Summary
  - Depth-First Search is a search algorithm that expands the nodes in
    the frontier starting from the deepest, similar to a stack (LIFO)  
    æ·±åº¦ä¼˜å…ˆæœç´¢æ˜¯ä¸€ç§æœç´¢ç®—æ³•ï¼Œå®ƒä»æœ€æ·±çš„æ·±åº¦å¤„å¼€å§‹æ‰©å±•è¾¹ç•Œä¸­çš„èŠ‚ç‚¹ï¼Œç±»ä¼¼äºå †æ ˆ(LIFO)
  - This algorithm is complete (for finite search space), but not
    optimal; also it has high time complexity and space complexity
    O(b<sup>m</sup>)  
    è¿™ä¸ªç®—æ³•æ˜¯å®Œæ•´çš„ï¼ˆå¯¹äºæœ‰é™çš„æœç´¢ç©ºé—´ï¼‰ï¼Œä½†ä¸æ˜¯æœ€ä¼˜çš„ï¼›æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦éƒ½å¾ˆé«˜
    O(b<sup>m</sup>)

![Depth Search_1.png](Images/Depth%20Search_1.png)

### 13.5 Variations of Depth-First Search

- Depth-First Search comes with several issues  
  æ·±åº¦ä¼˜å…ˆæœç´¢æœ‰å‡ ä¸ªé—®é¢˜
  - Not optimal  
    ä¸æ˜¯æœ€ä½³çš„
  - High time complexity  
    é«˜æ—¶é—´å¤æ‚åº¦
  - High space complexity  
    ç©ºé—´å¤æ‚åº¦é«˜
- DFS with less memory usage (saving space complexity)  
  DFSå¯ä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼ˆèŠ‚çœç©ºé—´å¤æ‚æ€§ï¼‰
  - This would reduce the space complexity to O(bm)  
    è¿™ä¼šå°†ç©ºé—´å¤æ‚åº¦é™ä½åˆ° O(bm)
  - We need to store a single path along with the siblings for each node
    on the path  
    æˆ‘ä»¬éœ€è¦ä¸ºè·¯å¾„ä¸Šçš„æ¯ä¸ªèŠ‚ç‚¹å­˜å‚¨å•ä¸ªè·¯å¾„ä»¥åŠå…„å¼Ÿè·¯å¾„
  - Recall that b is the branching factor and m is the maximum depth of
    the search tree  
    å›æƒ³ä¸€ä¸‹ï¼Œb æ˜¯åˆ†æ”¯å› å­ï¼Œm æ˜¯æœ€å¤§å€¼æœç´¢æ ‘çš„æ·±åº¦
- Depth-Limited Search  
  æ·±åº¦æœ‰é™çš„æœç´¢
  - The issue related to depth-first search in infinite state spaces can
    be mitigated by providing a depth limit â„“  
    é€šè¿‡æä¾›æ·±åº¦é™åˆ¶â„“ï¼Œå¯ä»¥ç¼“è§£æ— é™çŠ¶æ€ç©ºé—´ä¸­æ·±åº¦ä¼˜å…ˆæœç´¢çš„é—®é¢˜
  - This adds an additional source of incompleteness if we choose â„“ < d
    namely the shallowest goal is beyond the depth limit  
    å¦‚æœæˆ‘ä»¬é€‰æ‹©â„“<dï¼Œè¿™å°±å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„ä¸å®Œæ•´çš„æ¥æºï¼Œå³æœ€æµ…çš„ç›®æ ‡è¶…å‡ºäº†æ·±åº¦é™åˆ¶
  - This approach is nonoptimal also in the case â„“ > d  
    è¿™ç§æ–¹æ³•åœ¨â„“>dçš„æƒ…å†µä¸‹ä¹Ÿæ˜¯éæœ€ä¼˜çš„
  - Time complexity is O(b<sup>â„“</sup>)  
    æ—¶é—´å¤æ‚åº¦ä¸º O(b<sup>â„“</sup>)

![Variations of Deptho-First Search_1.png](Images/Variations%20of%20Deptho-First%20Search_1.png)

- Summary
  - Depth-First Search can be improved in terms of its time and space
    complexity through some modifications  
    æ·±åº¦ä¼˜å…ˆæœç´¢å¯ä»¥é€šè¿‡ä¸€äº›ä¿®æ”¹æ¥æé«˜å…¶æ—¶é—´å’Œç©ºé—´çš„å¤æ‚æ€§
  - Depth-First Search with less memory usage only keeps in memory the
    current path and the siblings of the nodes  
    æ·±åº¦-ä¼˜å…ˆæœç´¢ä½¿ç”¨è¾ƒå°‘çš„å†…å­˜ï¼Œåªä¿ç•™åœ¨å†…å­˜ä¸­çš„å½“å‰è·¯å¾„å’ŒèŠ‚ç‚¹çš„å…„å¼Ÿå§å¦¹
  - Depth-Limited Search is another variation, where a depth limit is
    specified; this adds an additional source of incompleteness  
    æ·±åº¦æœ‰é™æœç´¢æ˜¯å¦ä¸€ç§å˜ä½“ï¼Œå…¶ä¸­æŒ‡å®šäº†æ·±åº¦é™åˆ¶ï¼›è¿™å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„ä¸å®Œæ•´æ€§æ¥æº

## 14. Informed Search

### 14.1 Informed Search

- Informed search strategies use problem-specific knowledge beyond the
  definition of the problem itself  
  çŸ¥æƒ…æœç´¢ç­–ç•¥ä½¿ç”¨è¶…å‡ºé—®é¢˜æœ¬èº«å®šä¹‰ä¹‹å¤–çš„ç‰¹å®šé—®é¢˜çš„çŸ¥è¯†
- Informed search strategies can find solutions more efficiently
  compared to uninformed search  
  ä¸æ— çŸ¥æœç´¢ç›¸æ¯”ï¼ŒçŸ¥æƒ…æœç´¢ç­–ç•¥å¯ä»¥æ›´æœ‰æ•ˆåœ°æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ

- The general approach, called best-first search, is to determine which
  node to expand based on an evaluation function  
  ä¸€èˆ¬çš„æ–¹æ³•ç§°ä¸ºæœ€ä½³ä¼˜å…ˆæœç´¢ï¼Œæ˜¯æ ¹æ®æ±‚å€¼å‡½æ•°ç¡®å®šè¦æ‰©å±•å“ªä¸ªèŠ‚ç‚¹  
  f(n):node â†’ cost estimate
- This function acts as a cost estimate: the node with the lowest cost
  is the one that is expanded next  
  è¿™ä¸ªå‡½æ•°ä½œä¸ºä¸€ä¸ªæˆæœ¬ä¼°è®¡ï¼šæˆæœ¬æœ€ä½çš„èŠ‚ç‚¹æ˜¯ä¸‹ä¸€ä¸ªæ‰©å±•çš„èŠ‚ç‚¹  
  ![Informed Search_1.png](Images/Informed%20Search_1.png)

- The evaluation function f(n) for most best-first algorithms includes a
  **heuristic** function as a component:  
  å¤§å¤šæ•°æœ€ä½³ä¼˜å…ˆç®—æ³•çš„è¯„ä¼°å‡½æ•° f(n) åŒ…æ‹¬ å¯å‘å¼å‡½æ•°ä½œä¸ºä¸€ä¸ªç»„ä»¶ï¼š  
  â„(n)= estimated cost of the cheapest path from node n to a goal node  
  â„(n)= ä»èŠ‚ç‚¹ n åˆ°ç›®æ ‡èŠ‚ç‚¹çš„æœ€ä¾¿å®œè·¯å¾„çš„ä¼°è®¡æˆæœ¬
- Heuristic functions are the most common form in which new knowledge is
  given to the search algorithm. If n is a goal node, then â„(n) = 0  
  å¯å‘å¼å‡½æ•°æ˜¯æ–°çŸ¥è¯†æœ€å¸¸è§çš„å½¢å¼ è¢«èµ‹äºˆæœç´¢ç®—æ³•ã€‚å¦‚æœ n æ˜¯ç›®æ ‡èŠ‚ç‚¹ï¼Œåˆ™ â„(n) = 0
- A heuristic can be a rule of thumb, common knowledge; it is quick to
  compute, but not guaranteed to work (nor to yield optimal solutions)  
  å¯å‘å¼å¯ä»¥æ˜¯ç»éªŒæ³•åˆ™ï¼Œå¸¸è¯†ï¼›å®ƒè®¡ç®—é€Ÿåº¦å¿«ï¼Œä½†ä¸èƒ½ä¿è¯å·¥ä½œï¼ˆä¹Ÿä¸èƒ½äº§ç”Ÿæœ€ä¼˜è§£ï¼‰

### 14.2 A\* Search

- The most widely known informed search strategy is A\*  
  æœ€å¹¿ä¸ºäººçŸ¥çš„çŸ¥æƒ…æœç´¢ç­–ç•¥æ˜¯A\*
- This search strategy evaluates nodes using the following cost function  
  æ­¤æœç´¢ç­–ç•¥ä½¿ç”¨ä»¥ä¸‹æˆæœ¬å‡½æ•°æ¥è¯„ä¼°èŠ‚ç‚¹  
  f(n) = g(n) + h(n)  
  where g(n) is the cost to reach the node and h(n) is the heuristic
  from the node to the goal  
  å…¶ä¸­ g(n) æ˜¯åˆ°è¾¾èŠ‚ç‚¹çš„æˆæœ¬ï¼Œh(n) æ˜¯ä»èŠ‚ç‚¹åˆ°ç›®æ ‡çš„å¯å‘å¼
- This is equivalent to the cost of the cheapest solution through node n  
  è¿™ç›¸å½“äºé€šè¿‡èŠ‚ç‚¹nè·å¾—æœ€ä¾¿å®œçš„è§£å†³æ–¹æ¡ˆçš„æˆæœ¬

- A\* search algorithm:  
  A\*æœç´¢ç®—æ³•
  - Expand the node in the frontier with smallest cost f(n) = g(n) +
    h(n)  
    ä»¥æœ€å°çš„ä»£ä»·f(n)=g(n)+h(n)å±•å¼€è¾¹ç•ŒèŠ‚ç‚¹
  - Do not add children in the frontier if the node is already in the
    frontier or in the list of visited nodes (to avoid loopy paths)  
    å¦‚æœèŠ‚ç‚¹å·²ç»åœ¨è¾¹ç•Œä¸­æˆ–å·²è®¿é—®èŠ‚ç‚¹åˆ—è¡¨ä¸­ï¼Œåˆ™ä¸è¦åœ¨è¾¹ç•Œä¸­æ·»åŠ å­èŠ‚ç‚¹ï¼ˆä»¥é¿å…å¾ªç¯è·¯å¾„ï¼‰
  - If the state of a given child is in the frontier  
    å¦‚æœä¸€ä¸ªç»™å®šçš„å­©å­çš„çŠ¶æ€å¤„äºè¾¹ç•ŒçŠ¶æ€
    - If the frontier node has a larger g(n), place the child into the
      frontier and remove the node with larger g(n) from the frontier  
      å¦‚æœè¾¹ç•ŒèŠ‚ç‚¹å…·æœ‰è¾ƒå¤§çš„g(n)ï¼Œåˆ™å°†å­èŠ‚ç‚¹æ”¾å…¥è¾¹ç•Œä¸­ï¼Œå¹¶å°†g(n)è¾ƒå¤§çš„èŠ‚ç‚¹ä»è¾¹ç•Œä¸­ç§»é™¤
  - Stop when a goal node is visited  
    åœ¨è®¿é—®ç›®æ ‡èŠ‚ç‚¹æ—¶åœæ­¢

- The A\* search is complete and optimal if â„(n) is consistent
- A heuristic is said to be consistent (or monotone), if the estimate is
  always no greater than the estimated distance from any neighbouring
  vertex to the goal, plus the cost of reaching that neighbour  
  å¦‚æœä¼°è®¡æ€»æ˜¯ä¸å¤§äºä»ä»»ä½•ç›¸é‚»é¡¶ç‚¹åˆ°ç›®æ ‡çš„ä¼°è®¡è·ç¦»ï¼ŒåŠ ä¸Šåˆ°è¾¾è¯¥é‚»å±…çš„æˆæœ¬ï¼Œåˆ™ç§°ä¸ºå¯å‘å¼æ˜¯ä¸€è‡´çš„ï¼ˆæˆ–å•è°ƒçš„ï¼‰
  h(n) â‰¤ cost(n,n') + h(n')

- The number of states for the A\* search is exponential in the length
  of the solution, namely for constant step costs: O(b<sup>âˆˆd</sup>)  
  A\*æœç´¢çš„çŠ¶æ€æ•°åœ¨è§£çš„é•¿åº¦ä¸Šå‘ˆæŒ‡æ•°çº§å¢é•¿ï¼Œå³å¯¹äºå¸¸æ•°çš„æ­¥é•¿ä»£ä»·ï¼šO(b<sup>âˆˆd</sup>)
- When h/* is the actual cost from root node to goal node,
  ![A Search_1.png](Images/A%20Search_1.png) is the relative error  
  å½“â„âˆ—æ˜¯ä»æ ¹èŠ‚ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å®é™…æˆæœ¬æ—¶ï¼Œ![A Search_1.png](Images/A%20Search_1.png)æ˜¯ç›¸å¯¹è¯¯å·®
- Space is the main issue with A\*, as it keeps all generated nodes in
  memory, therefore A\* is not suitable for many large-scale problems  
  ç©ºé—´æ˜¯A\*çš„ä¸»è¦é—®é¢˜ï¼Œå› ä¸ºå®ƒå°†æ‰€æœ‰ç”Ÿæˆçš„èŠ‚ç‚¹éƒ½ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œå› æ­¤A\*ä¸é€‚ç”¨äºè®¸å¤šå¤§è§„æ¨¡çš„é—®é¢˜

- Completeness: if the heuristic â„(n) is consistent, then the A\*
  algorithm is complete  
  å®Œæ•´æ€§ï¼šå¦‚æœå¯å‘å¼çš„â„(n)æ˜¯ä¸€è‡´çš„ï¼Œé‚£ä¹ˆA*ç®—æ³•æ˜¯å®Œæ•´çš„
- Optimality: if the heuristic â„(n) is consistent, A\* is optimal  
  æœ€ä¼˜æ€§ï¼šå¦‚æœå¯å‘å¼ â„(n) æ˜¯ä¸€è‡´çš„ï¼Œåˆ™ A\* æ˜¯æœ€ä¼˜çš„
- Time complexity: O(b<sup>âˆˆd</sup>), where âˆˆ is the relative error of
  the heuristic  
  æ—¶é—´å¤æ‚åº¦ï¼šO(b<sup>âˆˆd</sup>)ï¼Œå…¶ä¸­ âˆˆ æ˜¯å¯å‘å¼çš„ç›¸å¯¹è¯¯å·®
- Space complexity: O(b<sup>âˆˆd</sup>), since we keep in memory all
  expanded nodes and all nodes in the frontier  
  ç©ºé—´å¤æ‚åº¦ï¼šO(b<sup>âˆˆd</sup>)ï¼Œå› ä¸ºæˆ‘ä»¬å°†æ‰€æœ‰æ‰©å±•èŠ‚ç‚¹éƒ½ä¿å­˜åœ¨å†…å­˜ä¸­
  å’Œè¾¹ç•Œä¸­çš„æ‰€æœ‰èŠ‚ç‚¹

### 14.3 Summary

- A\* is complete and optimal, given a consistent heuristic
  A\*æ˜¯å®Œæ•´çš„å’Œæœ€ä¼˜çš„ï¼Œç»™å®šä¸€ä¸ªä¸€è‡´çš„å¯å‘å¼
- However, A\* has typically high time/space complexity, regardless of
  the heuristic chosen  
  ç„¶è€Œï¼ŒA\*é€šå¸¸å…·æœ‰è¾ƒé«˜çš„æ—¶é—´/ç©ºé—´å¤æ‚åº¦ï¼Œæ— è®ºé€‰æ‹©ä»€ä¹ˆå¯å‘å¼æ–¹æ³•
- Heuristics have a considerable impact on the performance of informed
  search algorithms, and they can drastically reduce the time and space
  complexity in comparison to uninformed search algorithms  
  å¯å‘å¼ç®—æ³•å¯¹çŸ¥æƒ…çš„æœç´¢ç®—æ³•çš„æ€§èƒ½æœ‰ç›¸å½“å¤§çš„å½±å“ï¼Œä¸ä¸çŸ¥æƒ…çš„æœç´¢ç®—æ³•ç›¸æ¯”ï¼Œå®ƒä»¬å¯ä»¥å¤§å¤§é™ä½æ—¶é—´å’Œç©ºé—´çš„å¤æ‚æ€§

- A\* is only complete, optimal and optimally efficient when the
  heuristic is consistent.  
  åªæœ‰å½“å¯å‘å¼ä¸€è‡´æ—¶ï¼ŒA\* æ‰æ˜¯å®Œæ•´çš„ã€æœ€ä¼˜çš„å’Œæœ€ä¼˜æ•ˆç‡çš„
- Any consistent heuristic guarantees the A\* algorithm is optimally
  efficient.  
  ä»»ä½•ä¸€è‡´çš„å¯å‘å¼éƒ½å¯ä»¥ä¿è¯ A\* ç®—æ³•æ˜¯æœ€æœ‰æ•ˆçš„


## 15. Introduction to Optimisation

### 15.1 Optimisation Problems

- Optimisation problems: to find a solution that minimises/ maximises
  one or more pre-defined objective functions.  
  ä¼˜åŒ–é—®é¢˜ï¼šæ‰¾åˆ°ä¸€ä¸ªæœ€å°åŒ–æˆ–æœ€å¤§åŒ–ä¸€ä¸ªæˆ–å¤šä¸ªé¢„å®šä¹‰çš„ç›®æ ‡å‡½æ•°çš„è§£å†³æ–¹æ¡ˆã€‚
- Maximisation / minimisation problems  
  æœ€å¤§åŒ–/æœ€å°åŒ–é—®é¢˜
- There may be some constraints that must or should be satisfied for a
  given solution to be feasible  
  å¯¹äºç»™å®šçš„è§£å†³æ–¹æ¡ˆå¯è¡Œï¼Œå¯èƒ½å¿…é¡»æˆ–åº”è¯¥æ»¡è¶³ä¸€äº›çº¦æŸ

- Optimisation Algorithms from Artificial Intelligence  
  åŸºäºäººå·¥æ™ºèƒ½ä¸­çš„ä¼˜åŒ–ç®—æ³•
  - Solutions do not correspond to paths built step by step from an
    initial to a goal state. è§£å†³æ–¹æ¡ˆå¹¶ä¸å¯¹åº”äºä»åˆå§‹çŠ¶æ€åˆ°ç›®æ ‡çŠ¶æ€é€æ­¥æ„å»ºçš„è·¯å¾„
  - Instead, the algorithms typically maintain whole candidate solutions
    from the beginning.  
    ç›¸åï¼Œè¿™äº›ç®—æ³•é€šå¸¸ä»ä¸€å¼€å§‹å°±ä¿æŒæ•´ä¸ªå€™é€‰è§£å†³æ–¹æ¡ˆã€‚
  - Candidate solutions may be feasible or infeasible  
    å€™é€‰çš„è§£å†³æ–¹æ¡ˆå¯èƒ½æ˜¯å¯è¡Œçš„æˆ–ä¸å¯è¡Œçš„

- Search and Optimisation  
  æœç´¢å’Œä¼˜åŒ–
  - In search, we are interested in searching for a goal state  
    åœ¨æœç´¢è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯æœç´¢ä¸€ä¸ªç›®æ ‡çŠ¶æ€
  - In optimisation, we are interested in searching for an optimal
    solution.  
    åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯å¯»æ‰¾ä¸€ä¸ªæœ€ä¼˜è§£
  - As many search problems have a cost associated to actions, they can
    also be formulated as optimisation problems  
    ç”±äºè®¸å¤šæœç´¢é—®é¢˜éƒ½æœ‰ä¸æ“ä½œç›¸å…³çš„æˆæœ¬ï¼Œå› æ­¤å®ƒä»¬ä¹Ÿå¯ä»¥è¢«è¡¨è¿°ä¸ºä¼˜åŒ–é—®é¢˜
  - Similarly, optimisation problems can frequently be formulated as
    search problems associated to a cost function  
    ç±»ä¼¼åœ°ï¼Œä¼˜åŒ–é—®é¢˜é€šå¸¸å¯ä»¥è¡¨è¿°ä¸ºä¸ä»£ä»·å‡½æ•°ç›¸å…³çš„æœç´¢é—®é¢˜
  - Many search algorithms will â€œsearchâ€ for optimal solutions (see A\*
    as an example).  
    è®¸å¤šæœç´¢ç®—æ³•ä¼šâ€œæœç´¢â€æœ€ä¼˜è§£å†³æ–¹æ¡ˆ(ä»¥A\*ä¸ºä¾‹)
  - Optimisation algorithms may also be used to solve search problems if
    they can be associated to an appropriate function to be optimised  
    ä¼˜åŒ–ç®—æ³•ä¹Ÿå¯ä»¥ç”¨äºè§£å†³æœç´¢é—®é¢˜ï¼Œå¦‚æœå®ƒä»¬å¯ä»¥å…³è”åˆ°ä¸€ä¸ªé€‚å½“çš„å‡½æ•°æ¥è¿›è¡Œä¼˜åŒ–

### 15.2 Artificial Intelligence Optimisation Algorithms

- Advantages
  - Usually more space efficient, frequently requiring the same amount
    of space from the beginning to the end of the optimisation process  
    é€šå¸¸ç©ºé—´æ•ˆç‡æ›´é«˜ï¼Œä»ä¼˜åŒ–è¿‡ç¨‹çš„å¼€å§‹åˆ°ç»“æŸé€šå¸¸éœ€è¦ç›¸åŒæ•°é‡çš„ç©ºé—´
    - They do not maintain alternative paths to solutions  
      ä»–ä»¬ä¸ç»´æŠ¤è·å¾—è§£å†³æ–¹æ¡ˆçš„æ›¿ä»£è·¯å¾„
    - Frequently able to find reasonable solutions for problems with
      large state spaces, for which the tree-based search algorithms are
      unsuitable  
      å¯¹äºåŸºäºæ ‘çš„æœç´¢ç®—æ³•ä¸é€‚åˆä½¿ç”¨çš„å¤§çŠ¶æ€ç©ºé—´é—®é¢˜ï¼Œç»å¸¸èƒ½å¤Ÿæ‰¾åˆ°åˆç†çš„è§£å†³æ–¹æ¡ˆ
  - Can potentially be more time efficient, depending on the algorithm  
    æ ¹æ®ç®—æ³•çš„ä¸åŒï¼Œæ—¶é—´å¯èƒ½ä¼šæ›´æœ‰æ•ˆ
  - Do not necessarily require problem-specific heuristics  
    ä¸ä¸€å®šéœ€è¦ç‰¹å®šäºé—®é¢˜çš„å¯å‘å¼æ–¹æ³•
- Weaknesses
  - Not guaranteed to retrieve the optimal solution in a reasonable
    amount of time  
    ä¸èƒ½ä¿è¯åœ¨åˆç†çš„æ—¶é—´å†…å¾—åˆ°æœ€ä¼˜è§£
  - Depending on the problem formulation and operators, not guaranteed
    to be complete either  
    æ ¹æ®é—®é¢˜çš„å…¬å¼å’Œç®—å­ï¼Œä¹Ÿä¸èƒ½ä¿è¯æ˜¯å®Œæ•´çš„
- Applicability
  - Can be used for any problem that can be formulated as an
    optimisation problem  
    å¯ä»¥ç”¨äºä»»ä½•å¯ä»¥è¡¨è¿°ä¸ºä¼˜åŒ–é—®é¢˜çš„é—®é¢˜

### 15.3 Learning vs Optimisation

- From an algorithmic perspective, learning can be seen as finding
  parameters that minimise a loss function  
  ä»ç®—æ³•çš„è§’åº¦æ¥çœ‹ï¼Œå­¦ä¹ å¯ä»¥è¢«çœ‹ä½œæ˜¯å¯»æ‰¾æœ€å°åŒ–æŸå¤±å‡½æ•°çš„å‚æ•°
- We can compute the loss based on the training set  
  æˆ‘ä»¬å¯ä»¥æ ¹æ®è®­ç»ƒé›†æ¥è®¡ç®—æŸå¤±

- From a problem perspective, the goal of machine learning is to create
  models able to generalise to unseen data  
  ä»é—®é¢˜çš„è§’åº¦æ¥çœ‹ï¼Œæœºå™¨å­¦ä¹ çš„ç›®æ ‡æ˜¯åˆ›å»ºèƒ½å¤Ÿæ¨å¹¿åˆ°ä¸å¯è§çš„æ•°æ®çš„æ¨¡å‹
  - In supervised learning, we want to minimise the expected loss, i.e.,
    the loss considering all possible examples, including those that we
    have not observed yet  
    åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›å°†é¢„æœŸçš„æŸå¤±æœ€å°åŒ–ï¼Œå³ï¼Œå°†æŸå¤±è€ƒè™‘åˆ°æ‰€æœ‰å¯èƒ½çš„ä¾‹å­ï¼ŒåŒ…æ‹¬é‚£äº›æˆ‘ä»¬è¿˜æ²¡æœ‰è§‚å¯Ÿåˆ°çš„ä¾‹å­
  - We cannot calculate the loss based on unseen data during training
    time  
    æˆ‘ä»¬ä¸èƒ½æ ¹æ®è®­ç»ƒæœŸé—´çœ‹ä¸è§çš„æ•°æ®æ¥è®¡ç®—æŸå¤±
  - So, learning can be essentially seen as trying to optimise a
    function that cannot be computed  
    å› æ­¤ï¼Œå­¦ä¹ æœ¬è´¨ä¸Šå¯ä»¥è¢«çœ‹ä½œæ˜¯è¯•å›¾ä¼˜åŒ–ä¸€ä¸ªæ— æ³•è®¡ç®—çš„å‡½æ•°
  - Therefore, our algorithms may calculate the loss based on the
    training set, and design a loss function that includes, e.g., a
    regularisation term, in an attempt to generalise well to unseen data  
    å› æ­¤ï¼Œæˆ‘ä»¬çš„ç®—æ³•å¯ä»¥æ ¹æ®è®­ç»ƒé›†è®¡ç®—æŸå¤±ï¼Œå¹¶è®¾è®¡ä¸€ä¸ªæŸå¤±å‡½æ•°ï¼Œå…¶ä¸­åŒ…æ‹¬ï¼Œä¾‹å¦‚ï¼Œä¸€ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œä»¥è¯•å›¾å¾ˆå¥½åœ°æ¨å¹¿åˆ°çœ‹ä¸è§çš„æ•°æ®

- From a problem perspective, optimisation usually really wants to
  minimise (or maximise) the value of a given (known) objective function  
  ä»é—®é¢˜çš„è§’åº¦æ¥çœ‹ï¼Œä¼˜åŒ–é€šå¸¸çœŸçš„æƒ³è¦æœ€å°åŒ–ï¼ˆæˆ–æœ€å¤§åŒ–ï¼‰ä¸€ä¸ªç»™å®šçš„ï¼ˆå·²çŸ¥çš„ï¼‰ç›®æ ‡å‡½æ•°çš„å€¼
- In that sense, learning and optimisation are different  
  ä»è¿™ä¸ªæ„ä¹‰ä¸Šè¯´ï¼Œå­¦ä¹ å’Œä¼˜åŒ–æ˜¯ä¸åŒçš„
- However, there will be some optimisation problems where we canâ€™t
  compute the exact function to be optimised, causing the distinction
  between learning and optimisation to become more blurry  
  ç„¶è€Œï¼Œå°†ä¼šæœ‰ä¸€äº›ä¼˜åŒ–é—®é¢˜ï¼Œæˆ‘ä»¬æ— æ³•è®¡ç®—å‡ºè¦ä¼˜åŒ–çš„ç²¾ç¡®å‡½æ•°ï¼Œä»è€Œå¯¼è‡´å­¦ä¹ å’Œä¼˜åŒ–ä¹‹é—´çš„åŒºåˆ«å˜å¾—æ›´åŠ æ¨¡ç³Š

- Summary
  - Optimisation problems are problems where we want to minimise (or
    maximise) one or more objective functions, possibly subject to
    certain constraints  
    ä¼˜åŒ–é—®é¢˜æ˜¯æŒ‡æˆ‘ä»¬æƒ³è¦æœ€å°åŒ–ï¼ˆæˆ–æœ€å¤§åŒ–ï¼‰ä¸€ä¸ªæˆ–å¤šä¸ªç›®æ ‡å‡½æ•°çš„é—®é¢˜ï¼Œå¯èƒ½ä¼šå—åˆ°ä¸€å®šçš„çº¦æŸ
  - Optimisation algorithms can often find good solutions in a
    reasonable amount of time, but are typically not guaranteed to find
    optimal solutions in a reasonable amount of time  
    ä¼˜åŒ–ç®—æ³•é€šå¸¸å¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…æ‰¾åˆ°å¥½çš„è§£ï¼Œä½†é€šå¸¸ä¸èƒ½ä¿è¯åœ¨åˆç†çš„æ—¶é—´å†…æ‰¾åˆ°æœ€ä¼˜è§£

- Optimisation algorithms can be used to build machine learning models
  if we formulate learning as an optimisation problem where the loss
  function calculated based on the training set is to be minimised  
  å¦‚æœæˆ‘ä»¬å°†å­¦ä¹ è¡¨è¿°ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œå…¶ä¸­åŸºäºè®­ç»ƒé›†è®¡ç®—çš„æŸå¤±å‡½æ•°å°†è¢«æœ€å°åŒ–ï¼Œåˆ™ä¼˜åŒ–ç®—æ³•å¯ç”¨äºæ„å»ºæœºå™¨å­¦ä¹ æ¨¡å‹
- Search and optimisation problems are closely related, because there is
  frequently a cost associated to the actions in search problems, and
  such cost should ideally be minimised  
  æœç´¢å’Œä¼˜åŒ–é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œå› ä¸ºæœç´¢é—®é¢˜ä¸­çš„åŠ¨ä½œç»å¸¸ä¼šäº§ç”Ÿæˆæœ¬ï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™ç§æˆæœ¬åº”è¯¥æœ€å°åŒ–
- In some search problems, we may be interested in finding a feasible
  solution to the problem, without necessarily attempting to optimise
  this solution.  
  åœ¨æŸäº›æœç´¢é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¯èƒ½å¯¹æ‰¾åˆ°é—®é¢˜çš„å¯è¡Œè§£å†³æ–¹æ¡ˆæ„Ÿå…´è¶£ï¼Œè€Œä¸å¿…å°è¯•ä¼˜åŒ–è¯¥è§£å†³æ–¹æ¡ˆ

## 16. Optimisation Problem Formulation

### 16.1 Formulating Optimisation Problems

- Design variables represent a candidate solution  
  è®¾è®¡å˜é‡ä»£è¡¨äº†ä¸€ä¸ªå€™é€‰çš„è§£å†³æ–¹æ¡ˆ
  - Design variables define the search space of candidate solutions  
    è®¾è®¡å˜é‡å®šä¹‰äº†å€™é€‰è§£çš„æœç´¢ç©ºé—´
- Objective function defines the quality (or cost) of a solution  
  ç›®æ ‡å‡½æ•°å®šä¹‰äº†è§£å†³æ–¹æ¡ˆçš„è´¨é‡ï¼ˆæˆ–æˆæœ¬ï¼‰
  - Function to be optimised (maximised or minimised)  
    éœ€è¦ä¼˜åŒ–çš„åŠŸèƒ½ï¼ˆæœ€å¤§åŒ–æˆ–æœ€å°åŒ–ï¼‰
- Solutions must satisfy certain constraints, which define solution
  feasibility  
  è§£å†³æ–¹æ¡ˆå¿…é¡»æ»¡è¶³ä¸€å®šçš„çº¦æŸæ¡ä»¶ï¼Œè¿™å°±å®šä¹‰äº†è§£å†³æ–¹æ¡ˆçš„å¯è¡Œæ€§
  - Candidate solutions may be feasible or infeasible  
    å€™é€‰çš„è§£å†³æ–¹æ¡ˆå¯èƒ½æ˜¯å¯è¡Œçš„æˆ–ä¸å¯è¡Œçš„

![Optimisation Problem Formulation_1.png](Images/Optimisation%20Problem%20Formulation_1.png)

### 16.2 Summary

- We can formulate an optimisation problem by specifying  
  æˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šæ¥åˆ¶å®šä¸€ä¸ªä¼˜åŒ–é—®é¢˜
  - Design variables  
    è®¾è®¡å˜æ•°
  - Objective functions  
    ç›®æ ‡åŠŸèƒ½
  - Constraints  
    çº¦æŸ

- Design Variable
  - The design variable is correctly formulated. As we have assumed that
    cities 1 and N will always be the city of origin and the city of
    destination, these two cities do not need to be present in the
    design variable. The design variable just needs to have the sequence
    of cities travelled by in between cities 1 and N. There is just one
    assumption here in that this problem formulation would not allow
    solutions where we travel straight from the city of origin to the
    city of destination, without any cities in between.  
    è®¾è®¡å˜é‡çš„å…¬å¼æ˜¯æ­£ç¡®çš„ã€‚ç”±äºæˆ‘ä»¬å‡è®¾åŸå¸‚ 1 å’Œ N
    å§‹ç»ˆæ˜¯å§‹å‘åŸå¸‚å’Œç›®çš„åœ°åŸå¸‚ï¼Œå› æ­¤è¿™ä¸¤ä¸ªåŸå¸‚ä¸éœ€è¦å‡ºç°åœ¨è®¾è®¡å˜é‡ä¸­ã€‚è®¾è®¡å˜é‡åªéœ€è¦å…·æœ‰åŸå¸‚
    1 å’Œ N
    ä¹‹é—´ç»è¿‡çš„åŸå¸‚åºåˆ—ã€‚è¿™é‡Œåªæœ‰ä¸€ä¸ªå‡è®¾ï¼Œå³è¿™ä¸ªé—®é¢˜è¡¨è¿°ä¸å…è®¸æˆ‘ä»¬ç›´æ¥ä»èµ·ç‚¹åŸå¸‚åˆ°ç›®çš„åœ°åŸå¸‚çš„è§£å†³æ–¹æ¡ˆï¼Œä¸­é—´æ²¡æœ‰ä»»ä½•åŸå¸‚

- Objective Function
  - The objective function is correctly formulated, given the design
    variable. In particular, it appropriately sums the distance between
    city 1 and the first city in the design variable, the distances
    between consecutive cities in the design variable, and the distance
    between the last city in the design variable and the city of
    destination  
    ç»™å®šè®¾è®¡å˜é‡ï¼Œç›®æ ‡å‡½æ•°æ˜¯æ­£ç¡®åˆ¶å®šã€‚ç‰¹åˆ«æ˜¯ï¼Œå®ƒé€‚å½“åœ°æ€»ç»“äº†åŸå¸‚1ä¸è®¾è®¡å˜é‡ä¸­ç¬¬ä¸€ä¸ªåŸå¸‚ä¹‹é—´çš„è·ç¦»ï¼Œè®¾è®¡å˜é‡ä¸­è¿ç»­åŸå¸‚ä¹‹é—´çš„è·ç¦»ï¼Œä»¥åŠè®¾è®¡å˜é‡ä¸­æœ€åä¸€ä¸ªåŸå¸‚ä¸ç›®çš„åœ°åŸå¸‚ä¹‹é—´çš„è·ç¦»

- Dealing with Contraints
  - The contraints handling is not entirely correct, given the
    formulation of the design variable and objective function. This is
    because it does not check the existence of the direct path between
    city 1 and x1 and the existance of the direct path between city
    x<sub>size(x)</sub> and city N. In particular, h<sub>1</sub>(x) will
    be equal to 0 even when D<sub>1,x1</sub> = -1 or
    D<sub>xsize(X),N</sub> = -1, innapropriately considering the
    solution as feasible despite the inexistence of such direct paths.  
    è€ƒè™‘åˆ°è®¾è®¡å˜é‡å’Œç›®æ ‡å‡½æ•°çš„å…¬å¼åŒ–ï¼Œçº¦æŸå¤„ç†å¹¶ä¸å®Œå…¨æ­£ç¡®ã€‚è¿™æ˜¯å› ä¸ºå®ƒæ²¡æœ‰æ£€æŸ¥åŸå¸‚ 1 å’Œ
    x1 ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›´æ¥è·¯å¾„ï¼Œä»¥åŠåŸå¸‚ x<sub>size(x)</sub> å’ŒåŸå¸‚ N
    ä¹‹é—´æ˜¯å¦å­˜åœ¨ç›´æ¥è·¯å¾„ã€‚ç‰¹åˆ«æ˜¯ï¼Œh<sub>å³ä½¿å½“ D<sub>1,x1</sub> = -1 æˆ–
    D<sub>xsize(X),N</sub> = -1 æ—¶ï¼Œ1</sub>(x) ä¹Ÿå°†ç­‰äº
    0ï¼Œä¸æ°å½“åœ°è€ƒè™‘å°½ç®¡ä¸å­˜åœ¨è¿™ç§ç›´æ¥è·¯å¾„ï¼Œä½†è¯¥è§£å†³æ–¹æ¡ˆæ˜¯å¯è¡Œçš„

![Optimisation Problem Formulation_3.png](Images/Optimisation%20Problem%20Formulation_3.png)
![Optimisation Problem Formulation_2.png](Images/Optimisation%20Problem%20Formulation_2.png)

![Optimisation Problem Formulation_4.png](Images/Optimisation%20Problem%20Formulation_4.png)
![Optimisation Problem Formulation_5.png](Images/Optimisation%20Problem%20Formulation_5.png)
