{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Computation Exercise 3: Perceptron\n",
    "In this exercise, you will learn the following\n",
    "* data generation with the random library\n",
    "* define a linear classification model\n",
    "* python class\n",
    "* train and test a perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first need to import some necessary libraries\n",
    "* numpy provides a high-performance multidimensional array object, and tools for working with these arrays. \n",
    "* random implements pseudo-random number generators\n",
    "* matplotlib is a plotting library \n",
    "* sklearn.metrics provides method to compute the performance measure of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "We will generate a dataset for binary classification with the output label being either $+1$ or $-1$. This is achieved by a function `generate_data`.\n",
    "\n",
    "**Input**: `no_points` is the number of examples in the dataset\n",
    "\n",
    "**Output**: the dataset for binary classification. `X` is a nx2 matrix and `Y` is a nx1 vector, where n is the number of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(no_points):\n",
    "    X = np.zeros(shape=(no_points, 2))\n",
    "    Y = np.zeros(shape=no_points)\n",
    "    for ii in range(no_points):\n",
    "        X[ii, 0] = random.randint(0,20)\n",
    "        X[ii, 1] = random.randint(0,20)\n",
    "        if X[ii, 0]+X[ii, 1] > 20:\n",
    "            Y[ii] = 1 \n",
    "        else:\n",
    "            Y[ii] = -1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use `X = np.zeros(shape=(no_points, 2))` to generate a nx2 **zero** matrix X, and `Y = np.zeros(shape=no_points)` to generate a nx1 **zero** vector Y. Then we use a `for` loop to set the value of X and Y.\n",
    "\n",
    "* `X[ii, 0] = random.randint(0,20)`: the **first** feature of the `ii`-th example is randomly generated from the set {0,1,2,...,19}.\n",
    "* `X[ii, 1] = random.randint(0,20)`: the **second** feature of the `ii`-th example is randomly generated from the set {0,1,2,...,19}.\n",
    "\n",
    "We say $x^{(ii)}$ is a positive example if $x^{(ii)}_1+x^{(ii)}_2>20$, and a negative example otherwise. Then, we generate a **linearly separable** dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class \n",
    "\n",
    "Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. The class definitions begin with a `class` keyword, followed by the class name and a colon. \n",
    "\n",
    "All classes have a function called __init__(), which is always executed when the class is being initiated. \n",
    "\n",
    "`Example`: Create a class named Person, use the __init__() function to assign values for name and age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create new object instances (instantiation) of that class. The procedure to create an object is similar to a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "print(p1.name)\n",
    "print(p1.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we create an object p1, and assign the name attribute with \"John\", the age attribute with 36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create some methods for the class. Here let us create a method in the Person class (Insert a function that prints a greeting, and execute it on the p1 object:):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    \n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "  def myfunc(self):\n",
    "    print(\"Hello my name is \" + self.name)\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "p1.myfunc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `self` parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class.\n",
    "\n",
    "More details about class in python can be found \n",
    "[**here**](https://docs.python.org/3.5/tutorial/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Algorithm\n",
    "### Perceptron\n",
    "Recall a perceptron takes the form\n",
    "$$\\mathbf{x}\\mapsto \\text{sgn}(\\mathbf{w}^\\top\\mathbf{x}+b),$$\n",
    "where $\\mathbf{w}$ is the weight vector and $b$ is the bias. Here $\\text{sgn}(a)$ returns the sign of $a$.  Then it predicts $\\mathbf{x}$ to be a positive example if $\\mathbf{w}^\\top\\mathbf{x}+b>0$ and negative otherwise. According to the prediction scheme, this model misclassifies an example $(\\mathbf{x},y)$ if $y(\\mathbf{w}^\\top\\mathbf{x}+b)\\leq0$.\n",
    "\n",
    "### Perceptron Algorithm\n",
    "The perceptron algorithm tries to find $\\mathbf{w}$ and $b$. The basic idea is to traverse the dataset and update the model if it encouters a misclassified example. Suppose $(\\mathbf{x},y)$ is a misclassified example, then it updates the model by\n",
    "$$\n",
    "\\mathbf{w}\\gets \\mathbf{w}+y\\mathbf{x}\\quad b\\gets b+y.\n",
    "$$\n",
    "It is then clear that\n",
    "$$\n",
    "y(b+y+(\\mathbf{w}+y\\mathbf{x})^\\top\\mathbf{x})=yb+y\\mathbf{w}^\\top\\mathbf{x}+y^2+y^2\\mathbf{x}^\\top\\mathbf{x}>\n",
    "y(b+\\mathbf{w}^\\top\\mathbf{x}).\n",
    "$$\n",
    "That is, after an update the perceptron is more likely to classify correctly the example $(\\mathbf{x},y)$.\n",
    "\n",
    "We define a class `perceptron` to implement the *perceptron* algorithm. \n",
    "* `__init__()` is an initialization method. It allows for customized initialization of objects. It has two additional arguments: b is the bias and max_iter is the maximal number of iterations.\n",
    "* `train(self, X, Y)` is the perceptron algorithm to train a perceptron based on the input data matrix X (nxd, each row represents an example) and the output label vector Y (nx1).\n",
    "* `classify_element(self, x_elem)` returns the predicted label of the perceptron on a single example with the input `x_elem`\n",
    "* `classify(self, X)` returns the predicted labels of the perceptron on a set of examples with the input matrix `X`\n",
    "\n",
    "We request you to complete the following construction of the class `Perceptron`. In particular, we request you to complete the functions `train` , `classify_element` and `classify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \"\"\"\n",
    "    Class for performing Perceptron.\n",
    "    X is the input array with n rows (no_examples) and d columns (no_features)\n",
    "    Y is a vector containing elements which indicate the class \n",
    "        (1 for positive class, -1 for negative class)\n",
    "    w is the weight vector (d dimensional vector)\n",
    "    b is the bias value\n",
    "    \"\"\"\n",
    "    def __init__(self, b = 0, max_iter = 1000):\n",
    "        # we initialize an instance\n",
    "        self.max_iter = max_iter\n",
    "        self.w = []\n",
    "        self.b = 0\n",
    "        self.no_examples = 0\n",
    "        self.no_features = 0\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        '''\n",
    "        This function applies the perceptron algorithm to train a model w based on X and Y.\n",
    "        It changes both w and b of the class.\n",
    "        '''\n",
    "        # we set the number of examples and the number of features according to the matrix X\n",
    "        self.no_examples, self.no_features = np.shape(X)  \n",
    "        # we initialize the weight vector as the zero vector\n",
    "        self.w = np.zeros(self.no_features)\n",
    "        \n",
    "        # we only run a limited number of iterations\n",
    "        for ii in range(0, self.max_iter):\n",
    "            # at the begining of each iteration, we set the w_updated to be false (meaning we have not yet found misclassified example)\n",
    "            w_updated = False\n",
    "            # we traverse all the training examples\n",
    "            for jj in range(0, self.no_examples):\n",
    "                # To do: Insert your code to finish the update of the model by the perceptron algorithm\n",
    "                \n",
    "                \n",
    "            # if we do not find any misclassified example, we can return the model\n",
    "            if not w_updated:\n",
    "                print(\"Convergence reached in %i iterations.\" % ii)\n",
    "                break\n",
    "        # after finishing the iterations we can still find a misclassified example\n",
    "        if w_updated:\n",
    "            print(\n",
    "            \"\"\"\n",
    "            WARNING: convergence not reached in %i iterations.\n",
    "            Either dataset is not linearly separable, \n",
    "            or max_iter should be increased\n",
    "            \"\"\" % self.max_iter\n",
    "                )\n",
    "    # To do: insert your code to complete the definition of the function classify_element\n",
    "    def classify_element(self, x_elem):\n",
    "        '''\n",
    "        This function returns the predicted label of the perceptron on an input x_elem\n",
    "        You may require to use np.sign() function, which returns the sign of a number\n",
    "        Input:\n",
    "            x_elem: an input feature vector\n",
    "        Output:\n",
    "            return the predictred label of the model (indicated by w and b) on x_elem\n",
    "        '''\n",
    "        return \n",
    "    \n",
    "    # To do: insert your code to complete the definition of the function classify on a data matrix (n examples)\n",
    "    def classify(self, X):\n",
    "        '''\n",
    "        This function returns the predicted labels of the perceptron on an input matrix X\n",
    "        Input:\n",
    "            X: a data matrix with n rows (no_examples) and d columns (no_features)\n",
    "        Output:\n",
    "            return the vector. i-th entry is the predicted label on the i-th example\n",
    "        '''\n",
    "        \n",
    "        # we return the output vector\n",
    "        return predicted_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "### Data Generation\n",
    "We first generate a dataset with $100$ examples by using the function `generate_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X, Y = generate_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the dataset\n",
    "We visualise the dataset using a `scatter` plot using the scatter function in the `matplotlib.pylot` module.  To this aim, we use **list comprehension** to find the indices for positive and negative examples.\n",
    "\n",
    "List comprehension offers a shorter syntax when you want to create a new list based on the values of an existing list.\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "newlist = \\[*expression* for *item* in *iterable* if condition == True\\]\n",
    "* First is the expression we’d like to carry out. *expression* inside the square brackets.\n",
    "* Second is the object that the expression will work on. *item* inside the square brackets.\n",
    "* Third, we need an iterable list of objects to build our new list from. *iterable* inside the square brackets.\n",
    "* *condition* is like a filter that only accepts the items that valuate to True.\n",
    "\n",
    "More details can be found at [**list comprehension**](https://www.w3schools.com/python/python_lists_comprehension.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO Do: Insert your code to find the indices for positive examples\n",
    "idx_pos = \n",
    "# TO Do: Insert your code to find the indices for negative examples\n",
    "idx_neg = \n",
    "# make a scatter plot\n",
    "plt.scatter(X[idx_pos, 0], X[idx_pos, 1], color='blue')\n",
    "plt.scatter(X[idx_neg, 0], X[idx_neg, 1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "We then train the model by the perceptron algorithm on the dataset X, Y.\n",
    "* p is an **instance** of the class `perceptron`\n",
    "* p.train(X, Y) applies the train algorithm to (X,Y) and sets the weight vector and bias in the instance p.\n",
    "* `accuracy_score`  return the fraction of correctly classified samples. The syntax is \n",
    "`accuracy_score(y_true, y_pred)`\n",
    "The details can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance p\n",
    "p = Perceptron()\n",
    "# applies the train algorithm to (X,Y) and sets the weight vector and bias\n",
    "p.train(X, Y)\n",
    "# To Do: Insert your code to get the predicted output on the training set\n",
    "predicted_Y = \n",
    "# TO Do: Insert your code to get the accuracy on the training set\n",
    "acc_tr = \n",
    "print(acc_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "We evaluate the performance of the algorithm on a test dataset X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first generate a new dataset\n",
    "X_test, Y_test = generate_data(100)\n",
    "# To Do: Insert your code to get the predicted output on the test set\n",
    "predicted_Y_test = \n",
    "# TO Do: Insert your code to get the accuracy on the test set\n",
    "acc = \n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visulation of the perceptron\n",
    "\n",
    "Note that the hyperplane is the points $\\mathbf{x}$ such that \n",
    "$$\n",
    "\\mathbf{w}^\\top \\mathbf{x}+b=0\\Longleftrightarrow w_1x_1+w_2x_2+b=0.\n",
    "$$\n",
    "If $w_2\\neq0$, this means\n",
    "$$\n",
    "x_2 = (-b - w_1x_1) / w_2.\n",
    "$$\n",
    "We now plot the hyperplane. To this aim, we need to generate points in the hyperplane. The idea is to first generate the first coordinate of these points and then determine the second coordinates according to the above equation. \n",
    "\n",
    "We first use the `arange` function to generate points in the region $(0,20)$.\n",
    "The command `numpy.arange(start, stop, step, dtype)` creates the instance of ndarray with evenly spaced values and returns the reference to it.\n",
    "* start: start of an interval\n",
    "* stop: end of the interval. The interval does not contain a stop value, except when a step is not an integer and floating-\n",
    "* step: spacing between values.\n",
    "* dtype: the type of the output array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get an array of the first feature\n",
    "x1 = np.arange(0, 20, 0.1)\n",
    "# bias\n",
    "b = p.b\n",
    "# weight vector\n",
    "w = p.w\n",
    "# we now use list comprehension to generate the array of the second feature\n",
    "# To do: generate the second features for the hyperplane, i.e., (X1[i], X2[i]) is an point in the hyperplane for the perceptron\n",
    "x2 = \n",
    "plt.scatter(X[idx_pos, 0], X[idx_pos, 1], color='blue')\n",
    "plt.scatter(X[idx_neg, 0], X[idx_neg, 1], color='red')\n",
    "# plot the hyperplane corresponding to the perceptron\n",
    "plt.plot(x1, x2, color=\"black\", linewidth=2.5, linestyle=\"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the perceptron found by the algorithm sepearates well the positive examples from negative examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
