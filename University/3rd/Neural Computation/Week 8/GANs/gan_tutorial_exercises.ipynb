{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Computation - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Generative Adversarial Networks (GANs)\n",
    "\n",
    "**Aims of this tutorial**:\n",
    "- Implement and train a Generative Adversarial Network (GAN) in Pytorch.\n",
    "- Generate new data by drawing samples from GAN.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Familiar with python, numpy, and basic PyTorch.\n",
    "- Familiar with MNIST and Multi-Layer-Perceptrons (MLPs).\n",
    "\n",
    "\n",
    "**Notes**:\n",
    "- Docs for Pytorch's functions you will need:  \n",
    "https://pytorch.org/docs/stable/tensors.html  \n",
    "https://pytorch.org/docs/stable/nn.html  \n",
    "- Some helper functions for loading and plotting data are given in `./utils` folder. They will be used out of the box below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary: Loading and refreshing MNIST\n",
    "\n",
    "Loading and inspecting MNIST data. Same as previous tutorial..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# The below is for auto-reloading external modules after they are changed, such as those in ./utils.\n",
    "# Issue: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from utils.data_utils import get_mnist # Helper function. Use it out of the box.\n",
    "\n",
    "# Constants\n",
    "DATA_DIR = './data/mnist' # Location we will keep the data.\n",
    "SEED = 111111\n",
    "\n",
    "# If datasets are not at specified location, they will be downloaded.\n",
    "train_imgs, train_lbls = get_mnist(data_dir=DATA_DIR, train=True, download=True)\n",
    "test_imgs, test_lbls = get_mnist(data_dir=DATA_DIR, train=False, download=True)\n",
    "\n",
    "print(\"[train_imgs] Type: \", type(train_imgs), \"|| Shape:\", train_imgs.shape, \"|| Data type: \", train_imgs.dtype )\n",
    "print(\"[train_lbls] Type: \", type(train_lbls), \"|| Shape:\", train_lbls.shape, \"|| Data type: \", train_lbls.dtype )\n",
    "print('Class labels in train = ', np.unique(train_lbls))\n",
    "\n",
    "print(\"[test_imgs] Type: \", type(test_imgs), \"|| Shape:\", test_imgs.shape, \" || Data type: \", test_imgs.dtype )\n",
    "print(\"[test_lbls] Type: \", type(test_lbls), \"|| Shape:\", test_lbls.shape, \" || Data type: \", test_lbls.dtype )\n",
    "print('Class labels in test = ', np.unique(test_lbls))\n",
    "\n",
    "N_tr_imgs = train_imgs.shape[0] # N hereafter. Number of training images in database.\n",
    "H_height = train_imgs.shape[1] # H hereafter\n",
    "W_width = train_imgs.shape[2] # W hereafter\n",
    "C_classes = len(np.unique(train_lbls)) # C hereafter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that data have been loaded in *numpy arrays*.    \n",
    "Arrays with images have **shape ( N = number of images, H = height, W = width )**.  \n",
    "Arrays with labels have **shape ( N = number of images)**, holding one integer per image, the digit's class.\n",
    "\n",
    "MNIST comprises of a **train set (N_tr = 60000) images** and a **test set (N_te = 10000) images**.  \n",
    "We will use the train set for unsupervised learning. The test set will only be used for evaluating generalisation of classifiers towards the end of the tutorial.\n",
    "\n",
    "Lets plot a few image in one collage to have a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from utils.plotting import plot_grid_of_images # Helper functions, use out of the box.\n",
    "plot_grid_of_images(train_imgs[0:100], n_imgs_per_row=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the intensities in the images take **values from 0 to 255**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary: Data pre-processing\n",
    "\n",
    "A first step in almost all pipelines is to pre-process the data, to make them more appropriate for a model.\n",
    "\n",
    "Below, we will perform 3 points:  \n",
    "a) Change the labels from an integer representation to a **one-hot representation** of the **C=10 classes**.\\\n",
    "b) Re-scale the **intensities** in the images, from the range \\[0,255\\], to be instead in the range \\[-1,+1\\].\\\n",
    "c) **Vectorise the 2D images into 1D vectors for the MLP**, which only gets vectors as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Change representation of labels to one-hot vectors of length C=10.\n",
    "train_lbls_onehot = np.zeros(shape=(train_lbls.shape[0], C_classes ) )\n",
    "train_lbls_onehot[ np.arange(train_lbls_onehot.shape[0]), train_lbls ] = 1\n",
    "test_lbls_onehot = np.zeros(shape=(test_lbls.shape[0], C_classes ) )\n",
    "test_lbls_onehot[ np.arange(test_lbls_onehot.shape[0]), test_lbls ] = 1\n",
    "print(\"BEFORE: [train_lbls]        Type: \", type(train_lbls), \"|| Shape:\", train_lbls.shape, \" || Data type: \", train_lbls.dtype )\n",
    "print(\"AFTER : [train_lbls_onehot] Type: \", type(train_lbls_onehot), \"|| Shape:\", train_lbls_onehot.shape, \" || Data type: \", train_lbls_onehot.dtype )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) Re-scale image intensities, from [0,255] to [-1, +1].\n",
    "# This commonly facilitates learning:\n",
    "# A zero-centered signal with small magnitude allows avoiding exploding/vanishing problems easier.\n",
    "from utils.data_utils import normalize_int_whole_database # Helper function. Use out of the box.\n",
    "train_imgs = normalize_int_whole_database(train_imgs, norm_type=\"minus_1_to_1\")\n",
    "test_imgs = normalize_int_whole_database(test_imgs, norm_type=\"minus_1_to_1\")\n",
    "\n",
    "# Lets plot one image.\n",
    "from utils.plotting import plot_image, plot_images # Helper function, use out of the box.\n",
    "index = 0  # Try any, up to 60000\n",
    "print(\"Plotting image of index: [\", index, \"]\")\n",
    "print(\"Class label for this image is: \", train_lbls[index])\n",
    "print(\"One-hot label representation: [\", train_lbls_onehot[index], \"]\")\n",
    "plot_image(train_imgs[index])\n",
    "# Notice the magnitude of intensities. Black is now negative and white is positive float.\n",
    "# Compare with intensities of figure further above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c) Flatten the images, from 2D matrices to 1D vectors. MLPs take feature-vectors as input, not 2D images.\n",
    "train_imgs_flat = train_imgs.reshape([train_imgs.shape[0], -1]) # Preserve 1st dim (S = num Samples), flatten others.\n",
    "test_imgs_flat = test_imgs.reshape([test_imgs.shape[0], -1])\n",
    "print(\"Shape of numpy array holding the training database:\")\n",
    "print(\"Original : [N, H, W] = [\", train_imgs.shape , \"]\")\n",
    "print(\"Flattened: [N, H*W]  = [\", train_imgs_flat.shape , \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implementing a GAN\n",
    "\n",
    "In this task, you are called to implement the architecture and losses of a Generative Adversarial Network.\n",
    "Make necessary modifications where requested, to create the below architecture:\n",
    "\n",
    "![title](./documentation/gan_arch.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "class Network():\n",
    "    \n",
    "    def backward_pass(self, loss):\n",
    "        # Performs back propagation and computes gradients\n",
    "        # With PyTorch, we do not need to compute gradients analytically for parameters were requires_grads=True, \n",
    "        # Calling loss.backward(), torch's Autograd automatically computes grads of loss wrt each parameter p,...\n",
    "        # ... and **puts them in p.grad**. Return them in a list.\n",
    "        loss.backward()\n",
    "        grads = [param.grad for param in self.params]\n",
    "        return grads\n",
    "    \n",
    "class Generator(Network):\n",
    "    def __init__(self, rng, D_z, D_hid1, D_hid2, D_data):\n",
    "        self.D_z = D_z  # Keep track of it, we may need it.\n",
    "        # Initialize weight matrices\n",
    "        # Dimensions of parameter tensors are (number of neurons + 1) per layer, to account for +1 bias.\n",
    "        # First 2 hidden layers\n",
    "        w1_init = rng.normal(loc=0.0, scale=np.sqrt(2./(D_z * D_hid1)), size=(D_z + 1, D_hid1))\n",
    "        w2_init = rng.normal(loc=0.0, scale=np.sqrt(2./(D_hid1 * D_hid2)), size=(D_hid1 + 1, D_hid2))\n",
    "        # -- Output layer, predicting p(real|x)\n",
    "        wout_init = rng.normal(loc=0.0, scale=np.sqrt(2./(D_hid2 * D_data)), size=(D_hid2 + 1, D_data))\n",
    "\n",
    "        \n",
    "        # Pytorch tensors, parameters of the model\n",
    "        # Use the above numpy arrays as of random floats as initialization for the Pytorch weights.\n",
    "        w1 = torch.tensor(w1_init, dtype=torch.float, requires_grad=True)\n",
    "        w2 = torch.tensor(w2_init, dtype=torch.float, requires_grad=True)\n",
    "        wout = torch.tensor(wout_init, dtype=torch.float, requires_grad=True)\n",
    "        \n",
    "        # Keep track of all trainable parameters:\n",
    "        self.params = [w1, w2, wout]\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_z):\n",
    "        # z_codes: numpy array or pytorch tensor, shape [N, dimensionality of data]\n",
    "        [w1, w2, wout] = self.params\n",
    "        # make numpy to pytorch tensor\n",
    "        batch_z_t = torch.tensor(batch_z, dtype=torch.float) if type(batch_z) is np.ndarray else batch_z\n",
    "        # add 1 element for bias\n",
    "        unary_feature_for_bias = torch.ones(size=(batch_z_t.shape[0], 1))  # [N, 1] column vector.\n",
    "        \n",
    "        # ========== TODO: Fill in the gaps ========\n",
    "        # hidden layer:\n",
    "        z_ext = torch.cat((batch_z_t, unary_feature_for_bias), dim=1)\n",
    "        h1_preact = z_ext.??????(w1) # <--------------------\n",
    "        h1_act = lrelu(h1_preact)  \n",
    "        # l2\n",
    "        h1_ext = torch.cat((h1_act, unary_feature_for_bias), dim=1)\n",
    "        h2_preact = h1_ext.mm(??????) # <------------- \n",
    "        h2_act = lrelu(h2_preact)\n",
    "        # output layer.\n",
    "        h2_ext = torch.cat((h2_act, unary_feature_for_bias), dim=1)\n",
    "        hout_preact = ?????.mm(?????)  # <-----------\n",
    "        hout_act = torch.??????(hout_preact)  # Choose output activation function for G. See what used in VAE \n",
    "        # ==========================================\n",
    "        \n",
    "        # Output\n",
    "        x_generated = hout_act  # [N_samples, dimensionality of data]\n",
    "        \n",
    "        return x_generated\n",
    "                        \n",
    "        \n",
    "class Discriminator(Network):\n",
    "    def __init__(self, rng, D_data, D_hid1, D_hid2):\n",
    "        # Initialize weight matrices\n",
    "        # Dimensions of parameter tensors are (number of neurons + 1) per layer, to account for +1 bias.\n",
    "        # -- 2 hidden layers\n",
    "        w1_init = rng.normal(loc=0.0, scale=np.sqrt(2. / (D_data * D_hid1)), size=(D_data + 1, D_hid1))\n",
    "        w2_init = rng.normal(loc=0.0, scale=np.sqrt(2. / (D_hid1 * D_hid2)), size=(D_hid1 + 1, D_hid2))\n",
    "        # -- Output layer, predicting p(real|x)\n",
    "        wout_init = rng.normal(loc=0.0, scale=np.sqrt(2. / D_hid2), size=(D_hid2 + 1, 1))\n",
    "        \n",
    "        # Pytorch tensors, parameters of the model\n",
    "        # Use the above numpy arrays as of random floats as initialization for the Pytorch weights.\n",
    "        w1 = torch.tensor(w1_init, dtype=torch.float, requires_grad=True)\n",
    "        w2 = torch.tensor(w2_init, dtype=torch.float, requires_grad=True)\n",
    "        wout = torch.tensor(wout_init, dtype=torch.float, requires_grad=True)\n",
    "        \n",
    "        # Keep track of all trainable parameters:\n",
    "        self.params = [w1, w2, wout]\n",
    "        \n",
    "        \n",
    "    def forward(self, batch_x):\n",
    "        # z_codes: numpy array or pytorch tensor, shape [N, dimensionality of data]\n",
    "        [w1, w2, wout] = self.params\n",
    "        # make numpy to pytorch tensor\n",
    "        batch_x_t = torch.tensor(batch_x, dtype=torch.float) if type(batch_x) is np.ndarray else batch_x\n",
    "        # Add 1 element or bias\n",
    "        unary_feature_for_bias = torch.ones(size=(batch_x_t.shape[0], 1)) # [N, 1] column vector.\n",
    "        \n",
    "        # ========== TODO: Fill in the gaps ========\n",
    "        # hidden layer:\n",
    "        x_ext = torch.cat((batch_x_t, unary_feature_for_bias), dim=1)\n",
    "        h1_preact = x_ext.mm(??????)   #<-----------------\n",
    "        h1_act = lrelu(h1_preact)\n",
    "        # layer 2\n",
    "        h1_ext = torch.cat((h1_act, unary_feature_for_bias), dim=1)\n",
    "        h2_preact = h1_ext.mm(??????)  # <---------------\n",
    "        h2_act = lrelu(h2_preact)\n",
    "        # output layer.\n",
    "        h2_ext = torch.cat((h2_act, unary_feature_for_bias), dim=1)\n",
    "        hout_preact = h2_ext.mm(wout)\n",
    "        hout_act = torch.??????(hout_preact)  # Choose output layer activation function for D. See lecture slides. \n",
    "        # ===========================================\n",
    "        \n",
    "        # Output\n",
    "        p_real = hout_act\n",
    "        \n",
    "        return p_real\n",
    "    \n",
    "\n",
    "def generator_loss_practical(p_generated_x_is_real):\n",
    "    # mu: Tensor, [number of samples]. Predicted probability D(G(z)) that fake data are real. \n",
    "    \n",
    "    ######## TODO: Complete the gap ###########\n",
    "    loss_per_sample = - torch.????(p_generated_x_is_real)  # <------- See slides for the \"practical\" loss commonly used.\n",
    "    ###########################################\n",
    "    expected_loss = torch.mean(loss_per_sample, dim=0)  # Expectation of loss: Mean over samples (axis=0).\n",
    "    return expected_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(p_real_x_is_real, p_generated_x_is_real):\n",
    "    # p_real_x_is_real: [N] Predicted probability D(x) for x~training_data that real data are real. \n",
    "    # p_generated_x_is_real: [N]. Predicted probability D(x) for x=G(z) where z~N(0,I) that fake data are real.\n",
    "    \n",
    "    ######## TODO: Complete the calculation of Reconstruction loss for each sample ###########\n",
    "    loss_per_real_x = - torch.??????(p_real_x_is_real)  # <---------------\n",
    "    exp_loss_reals = torch.mean(loss_per_real_x)\n",
    "    \n",
    "    loss_per_fake_x = - torch.log(1 - ????????)  # <--------------\n",
    "    exp_loss_fakes = torch.mean(loss_per_fake_x)\n",
    "    ##########################################################################################\n",
    "    \n",
    "    total_loss = exp_loss_reals + exp_loss_fakes  # Expectation of loss: Mean over samples (axis=0).\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this task is completed correctly, you should be able to run the cell and get no errors. Though no output will be given yet. We will use this in the next task, and then we will find out if everything went well :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement unsupervised training of a GAN\n",
    "\n",
    "Below you are given the main training routine for training GANs. This is an implementation of the same Algorithm that was given in the Lecture slides.\n",
    "\n",
    "In the below code, each training iteration of the whole GAN consists of two stages:\\\\\n",
    "**First**, the Discriminator D is trained for a few steps (1 in this implementation, as commonly done). This is done by contrusting two batches, on consisting of real and one of fake examples. The fake examples were created by the Generator G, by decoding randomly sampled z taken from the prior p(z), here a multi-variant gaussian N(0,I). The discriminator processes both batches, and calculates 2 parts for its loss, one for the real and one for the fake examples. The discriminator is then updated by backprop.\\\\\n",
    "**Second**, the Generator is updated. This is done by creating a batch of generated samples with G. The batch is given to the discriminator, and the \"practical\" version of G's loss is computed, as a function of the predicted probabilities of D that the input batch is real. Then, G is updated by backprop to minimize this loss (minimize accuracy of D).\n",
    "\n",
    "The process is repeated for the chosen amount of steps.\n",
    "\n",
    "Fill in the blanks in the code. You can consult the corresponding Lecture slides with the pseudo-algorithm for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_train_progress_GAN, plot_grids_of_images  # Use out of the box\n",
    "\n",
    "\n",
    "def get_batch_reals(train_imgs, train_lbls, batch_size, rng):\n",
    "    # train_imgs: Images. Numpy array of shape [N, H * W]\n",
    "    # train_lbls: Labels of images. None, or Numpy array of shape [N, C_classes], one hot label for each image.\n",
    "    # batch_size: integer. Size that the batch should have.\n",
    "    \n",
    "    indices = range(0, batch_size)  # Remove this line after you fill-in and un-comment the below. \n",
    "    indices = rng.randint(low=0, high=train_imgs.shape[0], size=batch_size, dtype='int32')\n",
    "    \n",
    "    train_imgs_batch = train_imgs[indices]\n",
    "    if train_lbls is not None:  # Enables function to be used both for supervised and unsupervised learning\n",
    "        train_lbls_batch = train_lbls[indices]\n",
    "    else:\n",
    "        train_lbls_batch = None\n",
    "    return [train_imgs_batch, train_lbls_batch]\n",
    "\n",
    "\n",
    "\n",
    "def unsupervised_training_GAN(generator,\n",
    "                              discriminator,\n",
    "                              loss_func_g,\n",
    "                              loss_func_d,\n",
    "                              rng,\n",
    "                              train_imgs_all,\n",
    "                              batch_size_g,\n",
    "                              batch_size_d_fakes,\n",
    "                              batch_size_d_reals,\n",
    "                              learning_rate_g,\n",
    "                              learning_rate_d,\n",
    "                              total_iters_g,\n",
    "                              inner_iters_d,\n",
    "                              iters_per_gen_plot=-1):\n",
    "    # generator: Instance of a Generator.\n",
    "    # discriminator: Instance of a Discriminator.\n",
    "    # loss_func_g: Loss functions of G\n",
    "    # loss_func_d: Loss functions of D\n",
    "    # rng: numpy random number generator\n",
    "    # train_imgs_all: All the training images. Numpy array, shape [N_tr, H, W]\n",
    "    # batch_size_g: Size of the batch for G when it is its turn to get updated.\n",
    "    # batch_size_d_fakes: Size of batch of fake samples for D when it is its turn to get updated.\n",
    "    # batch_size_d_reals: Size of batch of real samples for D when it is its turn to get updated.\n",
    "    # learning_rate_g: Learning rate for G.\n",
    "    # learning_rate_d: learning rate for D.\n",
    "    # total_iters_g: how many SGD iterations to perform for G in total (outer loop).\n",
    "    # inner_iters_d: how many SGD iterations to perform for D before every 1 SGD iteration of G.\n",
    "    # iters_per_gen_plot: Integer. Every that many iterations the model generates few examples and we plot them.\n",
    "    loss_g_to_plot = []\n",
    "    loss_d_to_plot = []\n",
    "    loss_g_mom_to_plot = []\n",
    "    loss_d_mom_to_plot = []\n",
    "    loss_g_mom = None\n",
    "    loss_d_mom = None\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.params, lr=learning_rate_g, betas=[0.5, 0.999], eps=1e-07, weight_decay=0)  # Will use PyTorch's Adam optimizer out of the box\n",
    "    optimizer_d = optim.Adam(discriminator.params, lr=learning_rate_d, betas=[0.5, 0.99], eps=1e-07, weight_decay=0)  # Will use PyTorch's Adam optimizer out of the box\n",
    "    \n",
    "    for t in range(total_iters_g):\n",
    "        \n",
    "        for k in range(inner_iters_d):\n",
    "            #======== Train Discriminator for inner_iters_d SGD iterations... =========\n",
    "            \n",
    "            ################## TODO: Fill in the gaps #######################\n",
    "            # Generate Fake samples with G\n",
    "            z_batch = np.random.normal(loc=0., scale=1., size=[batch_size_d_fakes, generator.D_z])\n",
    "            x_gen_batch = generator.forward(?????????)  # <------------ ???????????\n",
    "            # Forward pass of fake samples through D\n",
    "            p_gen_x_are_real = ??????????.forward(x_gen_batch)  # <------------ ???????????\n",
    "            \n",
    "            # Forward pass of real samples through D\n",
    "            x_reals_batch, _ = get_batch_reals(train_imgs_all, None, batch_size_d_reals, rng)\n",
    "            p_real_x_are_real = ????????.forward(x_reals_batch)  # <------------ ???????????\n",
    "            \n",
    "            # Compute D loss:\n",
    "            loss_d = loss_func_d(p_real_x_are_real, ???????????)  # <--------------?????\n",
    "            ####################################################################\n",
    "            \n",
    "            # Backprop to D\n",
    "            optimizer_d.zero_grad()\n",
    "            _ = discriminator.backward_pass(loss_d)\n",
    "            optimizer_d.step()\n",
    "            \n",
    "        #============ Train Generator for 1 SGD iteration ============\n",
    "        \n",
    "        ########## TODO: Fill in the gaps ##################################\n",
    "        # Generate Fake samples with G\n",
    "        z_batch = np.random.normal(loc=0., scale=1., size=[batch_size_g, generator.D_z])\n",
    "        x_gen_batch = ???????????.forward(z_batch)  # <---------------------\n",
    "        # Forward pass of fake samples through D\n",
    "        p_gen_x_are_real = discriminator.forward(??????)  # <---------------\n",
    "        ####################################################################\n",
    "        \n",
    "        # Compute G loss:\n",
    "        loss_g = loss_func_g(p_gen_x_are_real)\n",
    "        \n",
    "        # Backprop to G\n",
    "        optimizer_g.zero_grad()\n",
    "        _ = generator.backward_pass(loss_g)\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # ==== Report training loss and accuracy ======\n",
    "        loss_g_np = loss_g if type(loss_g) is type(float) else loss_g.item()\n",
    "        loss_d_np = loss_d if type(loss_d) is type(float) else loss_d.item()\n",
    "        if t % 10 == 0:  # Print every 10 iterations\n",
    "            print(\"[iter:\", t, \"]: Loss G: {0:.2f}\".format(loss_g_np), \" Loss D: {0:.2f}\".format(loss_d_np))\n",
    "\n",
    "        loss_g_mom = loss_g_np if loss_g_mom is None else loss_g_mom * 0.9 + 0.1 * loss_g_np\n",
    "        loss_d_mom = loss_d_np if loss_d_mom is None else loss_d_mom * 0.9 + 0.1 * loss_d_np\n",
    "\n",
    "        loss_g_to_plot.append(loss_g_np)\n",
    "        loss_d_to_plot.append(loss_d_np)\n",
    "        loss_g_mom_to_plot.append(loss_g_mom)\n",
    "        loss_d_mom_to_plot.append(loss_d_mom)\n",
    "        \n",
    "        # =============== Every few iterations, plot loss ================#\n",
    "        if t == total_iters_g - 1 or t % iters_per_gen_plot == 0:\n",
    "            \n",
    "            ########## TODO: Fill in the gaps #############################\n",
    "            # Generate Fake samples with G\n",
    "            n_samples_to_gen = 100\n",
    "            z_plot = np.random.normal(loc=?????, scale=??????, size=[100, generator.D_z])  # <----------- N(0,I)\n",
    "            x_gen_plot = generator.forward(z_plot)\n",
    "            ###############################################################\n",
    "            \n",
    "            # Cast tensors to numpy arrays\n",
    "            x_gen_plot_np = x_gen_plot if type(x_gen_plot) is np.ndarray else x_gen_plot.detach().numpy()\n",
    "            # Generated images have vector shape. Reshape them to original image shape.\n",
    "            x_gen_plot_resh = x_gen_plot_np.reshape([n_samples_to_gen, H_height, W_width])\n",
    "            \n",
    "            train_imgs_resh = train_imgs_all.reshape([train_imgs_all.shape[0], H_height, W_width])\n",
    "            \n",
    "            # Plot a few generated images.\n",
    "            plot_grids_of_images([x_gen_plot_resh[0:100], train_imgs_resh[0:100]],\n",
    "                                  titles=[\"Generated\", \"Real\"],\n",
    "                                  n_imgs_per_row=10,\n",
    "                                  dynamically=True)\n",
    "            \n",
    "    # In the end of the process, plot loss.\n",
    "    plot_train_progress_GAN(loss_g_to_plot, loss_d_to_plot,\n",
    "                            loss_g_mom_to_plot, loss_d_mom_to_plot,\n",
    "                            iters_per_point=1, y_lims=[3., 3.])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling in the blanks, you should see no errors if you run the above cell. There will be no output yet. We will use the above code below, to actually create and train a GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Instantiate and Train your GAN\n",
    "\n",
    "The below code will instantiate a Generator and a Discriminator that you implemented above.\\\\\n",
    "It will then train the GAN with the training routine you implemented above.\n",
    "\n",
    "The code is complete. Run it, debug the previous sections if needed, and then observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network\n",
    "rng = np.random.RandomState(seed=SEED)\n",
    "generator = Generator(rng=rng,\n",
    "                      D_z=128,\n",
    "                      D_hid1=256,\n",
    "                      D_hid2=512,\n",
    "                      D_data=H_height*W_width)\n",
    "discriminator = Discriminator(rng=rng,\n",
    "                              D_data=H_height*W_width,\n",
    "                              D_hid1=256,\n",
    "                              D_hid2=512)\n",
    "\n",
    "# Start training\n",
    "unsupervised_training_GAN(generator,\n",
    "                          discriminator,\n",
    "                          loss_func_g=generator_loss_practical,\n",
    "                          loss_func_d=discriminator_loss,\n",
    "                          rng=rng,\n",
    "                          train_imgs_all=train_imgs_flat,\n",
    "                          batch_size_g=32,\n",
    "                          batch_size_d_fakes=64,\n",
    "                          batch_size_d_reals=64,\n",
    "                          learning_rate_g=1e-3,\n",
    "                          learning_rate_d=1e-3,\n",
    "                          total_iters_g=5000,\n",
    "                          inner_iters_d=1,\n",
    "                          iters_per_gen_plot=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above requires you to have completed both Task 1 and Task 2. If everything is completed correctly, you should see the model getting trained and the total training lossses of G and D printed every few iterations.\n",
    "\n",
    "In the end of training, after 5000 iterations, you will see 2 plots, one for G and one for D.\n",
    "You should also see printed side by side a set of random generated images, and some real images for comparison.\\\n",
    "\n",
    "Towards end of training, (some) generated images should start looking relatively realistic.\n",
    "\n",
    "The loss of D should decrease down to approx 1.0.\\\\\n",
    "\n",
    "**Question:**\n",
    "\n",
    "- The loss of G may not be monotonically decreasing, as we are used to, although it should clearly learn to produce better images during training. Why do you think this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Generate new images using your GAN\n",
    "\n",
    "After training, we can use the trained Generator to create new images. We simply sample z from the prior and decode it with the Generator (similar to a trained Decoder of a VAE).\n",
    "\n",
    "The code is complete, simply run it and observe the quality of the results. Hopefully some of them should look reasonable..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(generator, n_samples):\n",
    "    \n",
    "        # Generate Fake samples with G\n",
    "        z_plot = np.random.normal(loc=0., scale=1., size=[n_samples, generator.D_z])\n",
    "        x_gen_plot = generator.forward(z_plot)\n",
    "        # Cast tensors to numpy arrays\n",
    "        x_gen_plot_np = x_gen_plot if type(x_gen_plot) is np.ndarray else x_gen_plot.detach().numpy()\n",
    "\n",
    "        # Generated images have vector shape. Reshape them to original image shape.\n",
    "        x_gen_plot_resh = x_gen_plot_np.reshape([n_samples, H_height, W_width])\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            plot_image(x_gen_plot_resh[i])\n",
    "            \n",
    "synthesize(generator, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "- Not all generated images will look great, given how small our network is. Regardless, codes z from which part of the prior p(z)=N(0,I) do you think are the  most likely ones to give good results when decoded by the Generator? Why?\n",
    "\n",
    "**Further experimentation:**\n",
    "\n",
    "The GAN has **a lot** of hyper-parameters, because we now train 2 neural networks in parallel. Two learning rates, batch sizes, optimizers and their parameters, two architectures (depth, number of neurons, etc) and the choice of all these hyper-parameters needs to be adjusted to achieve good results. The GAN's performance is very sensitive to a good choice of these hyper-parameters. Feel free to experiment by changing the hyper-parameters to get a feel of the challenge in setting-up successful training of GANs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook:\n",
    "Copyright 2021, University of Birmingham  \n",
    "Tutorial for Neural Computation  \n",
    "For issues e-mail: k.kamnitsas@bham.ac.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
